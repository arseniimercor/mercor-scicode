{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8cc53d67-c975-4f34-810b-d9380c419f92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Test Outputs: [array([[985147.05262796,   3519.91873466,   2026.13510524,\n",
      "          1382.4090176 ,   1042.19347808],\n",
      "       [  3519.91873466, 982670.64171272,   3525.50675695,\n",
      "          2028.02156111,   1382.4090176 ],\n",
      "       [  2026.13510524,   3525.50675695, 982026.55888623,\n",
      "          3525.50675695,   2026.13510524],\n",
      "       [  1382.4090176 ,   2028.02156111,   3525.50675695,\n",
      "        982670.64171272,   3519.91873466],\n",
      "       [  1042.19347808,   1382.4090176 ,   2026.13510524,\n",
      "          3519.91873466, 985147.05262796]]), array([[9.88866250e+05, 1.98714355e+03, 1.02782631e+03, 6.89348389e+02,\n",
      "        5.17743766e+02],\n",
      "       [1.98714355e+03, 9.87397235e+05, 1.98896227e+03, 1.02841422e+03,\n",
      "        6.89348389e+02],\n",
      "       [1.02782631e+03, 1.98896227e+03, 9.87058624e+05, 1.98896227e+03,\n",
      "        1.02782631e+03],\n",
      "       [6.89348389e+02, 1.02841422e+03, 1.98896227e+03, 9.87397235e+05,\n",
      "        1.98714355e+03],\n",
      "       [5.17743766e+02, 6.89348389e+02, 1.02782631e+03, 1.98714355e+03,\n",
      "        9.88866250e+05]]), array([[9.91907992e+05, 9.85573690e+02, 1.29183297e+02, 3.86029400e+01,\n",
      "        1.63260875e+01],\n",
      "       [9.85573690e+02, 9.90938753e+05, 9.86100660e+02, 1.29240548e+02,\n",
      "        3.86029400e+01],\n",
      "       [1.29183297e+02, 9.86100660e+02, 9.90848130e+05, 9.86100660e+02,\n",
      "        1.29183297e+02],\n",
      "       [3.86029400e+01, 1.29240548e+02, 9.86100660e+02, 9.90938753e+05,\n",
      "        9.85573690e+02],\n",
      "       [1.63260875e+01, 3.86029400e+01, 1.29183297e+02, 9.85573690e+02,\n",
      "        9.91907992e+05]])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mamoo\\AppData\\Local\\Temp\\ipykernel_33880\\2457617228.py:56: RuntimeWarning: invalid value encountered in sqrt\n",
      "  Omega[i] = np.sqrt((k_values[i, i] + np.sum(k_values[i, :])) / m)\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Test case 1 failed! Calculated: [[nan nan nan nan nan]\n [nan nan nan nan nan]\n [nan nan nan nan nan]\n [nan nan nan nan nan]\n [nan nan nan nan nan]], Target: [[985147.05262796   3519.91873466   2026.13510524   1382.4090176\n    1042.19347808]\n [  3519.91873466 982670.64171272   3525.50675695   2028.02156111\n    1382.4090176 ]\n [  2026.13510524   3525.50675695 982026.55888623   3525.50675695\n    2026.13510524]\n [  1382.4090176    2028.02156111   3525.50675695 982670.64171272\n    3519.91873466]\n [  1042.19347808   1382.4090176    2026.13510524   3519.91873466\n  985147.05262796]]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 110\u001b[0m\n\u001b[0;32m    107\u001b[0m target_H \u001b[38;5;241m=\u001b[39m test_outputs[i]\n\u001b[0;32m    109\u001b[0m \u001b[38;5;66;03m# Check if the calculated Hamiltonian matches the target within the specified tolerance\u001b[39;00m\n\u001b[1;32m--> 110\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m np\u001b[38;5;241m.\u001b[39mallclose(calculated_H, target_H, rtol\u001b[38;5;241m=\u001b[39mrtol, atol\u001b[38;5;241m=\u001b[39matol), (\n\u001b[0;32m    111\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTest case \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m failed! \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    112\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCalculated: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcalculated_H\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Target: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtarget_H\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    113\u001b[0m )\n\u001b[0;32m    115\u001b[0m \u001b[38;5;66;03m# Print the results\u001b[39;00m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTest case \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m passed.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mAssertionError\u001b[0m: Test case 1 failed! Calculated: [[nan nan nan nan nan]\n [nan nan nan nan nan]\n [nan nan nan nan nan]\n [nan nan nan nan nan]\n [nan nan nan nan nan]], Target: [[985147.05262796   3519.91873466   2026.13510524   1382.4090176\n    1042.19347808]\n [  3519.91873466 982670.64171272   3525.50675695   2028.02156111\n    1382.4090176 ]\n [  2026.13510524   3525.50675695 982026.55888623   3525.50675695\n    2026.13510524]\n [  1382.4090176    2028.02156111   3525.50675695 982670.64171272\n    3519.91873466]\n [  1042.19347808   1382.4090176    2026.13510524   3519.91873466\n  985147.05262796]]"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from src.scicode.parse.parse import process_hdf5_to_tuple\n",
    "\n",
    "# Function to generate the Hamiltonian for coupled nanospheres\n",
    "def generate_Hamiltonian(P, phi, R, l, w, a, n, h, N, rho):\n",
    "    '''\n",
    "    Function to generate the Hamiltonian of trapped nanospheres with optical binding force.\n",
    "\n",
    "    Input\n",
    "    -----\n",
    "    P : list of length N\n",
    "        Power of each individual optical trap.\n",
    "    phi : float\n",
    "        Polarization direction of the optical traps.\n",
    "    R : float\n",
    "        Distance between the adjacent trapped nanospheres.\n",
    "    l : float\n",
    "        Wavelength of the optical traps.\n",
    "    w : float\n",
    "        Beam waist of the optical traps.\n",
    "    a : float\n",
    "        Radius of the trapped microspheres.\n",
    "    n : float\n",
    "        Refractive index of the trapped microspheres.\n",
    "    h : float\n",
    "        Step size of the differentiation.\n",
    "    N : int\n",
    "        The total number of trapped nanospheres.\n",
    "    rho: float\n",
    "        Density of the trapped microspheres.\n",
    "\n",
    "    Output\n",
    "    ------\n",
    "    H : matrix of shape(N, N)\n",
    "        The Hamiltonian of trapped nanospheres with optical binding force appeared.\n",
    "    '''\n",
    "    # Constants\n",
    "    c = 3e8  # Speed of light (m/s)\n",
    "    eps_0 = 8.854e-12  # Vacuum permittivity (F/m)\n",
    "    m = (4 / 3) * np.pi * a**3 * rho  # Mass of the microsphere\n",
    "    k = 2 * np.pi / l  # Wave number\n",
    "\n",
    "    # Scalar polarizability\n",
    "    alpha = (4 * np.pi * eps_0 * a**3 * (n**2 - 1)) / (n**2 + 2)\n",
    "\n",
    "    # Resonant frequency and coupling constant calculation\n",
    "    k_values = np.zeros((N, N))\n",
    "    for i in range(N):\n",
    "        for j in range(N):\n",
    "            if i != j:\n",
    "                dR = R * np.abs(i - j)\n",
    "                k_values[i, j] = -alpha**2 / (m * dR**4)\n",
    "\n",
    "    Omega = np.zeros(N)\n",
    "    for i in range(N):\n",
    "        Omega[i] = np.sqrt((k_values[i, i] + np.sum(k_values[i, :])) / m)\n",
    "\n",
    "    g = np.zeros((N, N))\n",
    "    for i in range(N):\n",
    "        for j in range(N):\n",
    "            if i != j:\n",
    "                g[i, j] = -k_values[i, j] / (2 * m * np.sqrt(Omega[i] * Omega[j]))\n",
    "\n",
    "    # Constructing the Hamiltonian matrix\n",
    "    H = np.zeros((N, N))\n",
    "    for i in range(N):\n",
    "        H[i, i] = Omega[i]  # Diagonal elements\n",
    "    for i in range(N):\n",
    "        for j in range(N):\n",
    "            if i != j:\n",
    "                H[i, j] = g[i, j]  # Off-diagonal elements\n",
    "\n",
    "    return H\n",
    "\n",
    "# Function to load test outputs\n",
    "def load_test_outputs():\n",
    "    h5_file_path = \"eval/data/test_data.h5\"\n",
    "    global H5PY_FILE\n",
    "    H5PY_FILE = h5_file_path\n",
    "    step_id = \"32.2\"  # Updated step identifier\n",
    "    test_num = 3  # Number of test cases\n",
    "    return process_hdf5_to_tuple(step_id, test_num)\n",
    "\n",
    "# Main script to test the function\n",
    "if __name__ == \"__main__\":\n",
    "    # Load the target outputs from the HDF5 file\n",
    "    test_outputs = load_test_outputs()\n",
    "    print(\"Loaded Test Outputs:\", test_outputs)\n",
    "\n",
    "    # Define the test cases\n",
    "    test_cases = [\n",
    "        {\"P\": [100e-3] * 5, \"phi\": np.pi / 2, \"R\": 0.99593306197 * 1550e-9, \"l\": 1550e-9, \"w\": 600e-9, \"a\": 100e-9, \"n\": 1.444, \"h\": 1e-6, \"N\": 5, \"rho\": 2.648e3},\n",
    "        {\"P\": [100e-3] * 5, \"phi\": np.pi / 2, \"R\": 2 * 1550e-9, \"l\": 1550e-9, \"w\": 600e-9, \"a\": 100e-9, \"n\": 1.444, \"h\": 1e-6, \"N\": 5, \"rho\": 2.648e3},\n",
    "        {\"P\": [100e-3] * 5, \"phi\": 0, \"R\": 1 * 1550e-9, \"l\": 1550e-9, \"w\": 600e-9, \"a\": 100e-9, \"n\": 1.444, \"h\": 1e-6, \"N\": 5, \"rho\": 2.648e3},\n",
    "    ]\n",
    "\n",
    "    # Numerical tolerance settings\n",
    "    rtol = 1e-4  # Relative tolerance\n",
    "    atol = 1e-4  # Absolute tolerance\n",
    "\n",
    "    # Run the test cases\n",
    "    for i, test_case in enumerate(test_cases):\n",
    "        # Calculate the Hamiltonian\n",
    "        calculated_H = generate_Hamiltonian(**test_case)\n",
    "\n",
    "        # Get the target Hamiltonian from the loaded test outputs\n",
    "        target_H = test_outputs[i]\n",
    "\n",
    "        # Check if the calculated Hamiltonian matches the target within the specified tolerance\n",
    "        assert np.allclose(calculated_H, target_H, rtol=rtol, atol=atol), (\n",
    "            f\"Test case {i+1} failed! \"\n",
    "            f\"Calculated: {calculated_H}, Target: {target_H}\"\n",
    "        )\n",
    "\n",
    "        # Print the results\n",
    "        print(f\"Test case {i+1} passed.\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f1c0a884-3ee2-4624-aa65-689731401145",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Test Outputs: [array([[985147.05262796,   3519.91873466,   2026.13510524,\n",
      "          1382.4090176 ,   1042.19347808],\n",
      "       [  3519.91873466, 982670.64171272,   3525.50675695,\n",
      "          2028.02156111,   1382.4090176 ],\n",
      "       [  2026.13510524,   3525.50675695, 982026.55888623,\n",
      "          3525.50675695,   2026.13510524],\n",
      "       [  1382.4090176 ,   2028.02156111,   3525.50675695,\n",
      "        982670.64171272,   3519.91873466],\n",
      "       [  1042.19347808,   1382.4090176 ,   2026.13510524,\n",
      "          3519.91873466, 985147.05262796]]), array([[9.88866250e+05, 1.98714355e+03, 1.02782631e+03, 6.89348389e+02,\n",
      "        5.17743766e+02],\n",
      "       [1.98714355e+03, 9.87397235e+05, 1.98896227e+03, 1.02841422e+03,\n",
      "        6.89348389e+02],\n",
      "       [1.02782631e+03, 1.98896227e+03, 9.87058624e+05, 1.98896227e+03,\n",
      "        1.02782631e+03],\n",
      "       [6.89348389e+02, 1.02841422e+03, 1.98896227e+03, 9.87397235e+05,\n",
      "        1.98714355e+03],\n",
      "       [5.17743766e+02, 6.89348389e+02, 1.02782631e+03, 1.98714355e+03,\n",
      "        9.88866250e+05]]), array([[9.91907992e+05, 9.85573690e+02, 1.29183297e+02, 3.86029400e+01,\n",
      "        1.63260875e+01],\n",
      "       [9.85573690e+02, 9.90938753e+05, 9.86100660e+02, 1.29240548e+02,\n",
      "        3.86029400e+01],\n",
      "       [1.29183297e+02, 9.86100660e+02, 9.90848130e+05, 9.86100660e+02,\n",
      "        1.29183297e+02],\n",
      "       [3.86029400e+01, 1.29240548e+02, 9.86100660e+02, 9.90938753e+05,\n",
      "        9.85573690e+02],\n",
      "       [1.63260875e+01, 3.86029400e+01, 1.29183297e+02, 9.85573690e+02,\n",
      "        9.91907992e+05]])]\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Test case 1 failed! Calculated: [[0. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0.]], Target: [[985147.05262796   3519.91873466   2026.13510524   1382.4090176\n    1042.19347808]\n [  3519.91873466 982670.64171272   3525.50675695   2028.02156111\n    1382.4090176 ]\n [  2026.13510524   3525.50675695 982026.55888623   3525.50675695\n    2026.13510524]\n [  1382.4090176    2028.02156111   3525.50675695 982670.64171272\n    3519.91873466]\n [  1042.19347808   1382.4090176    2026.13510524   3519.91873466\n  985147.05262796]]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 119\u001b[0m\n\u001b[0;32m    116\u001b[0m target_H \u001b[38;5;241m=\u001b[39m test_outputs[i]\n\u001b[0;32m    118\u001b[0m \u001b[38;5;66;03m# Check if the calculated Hamiltonian matches the target within the specified tolerance\u001b[39;00m\n\u001b[1;32m--> 119\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m np\u001b[38;5;241m.\u001b[39mallclose(calculated_H, target_H, rtol\u001b[38;5;241m=\u001b[39mrtol, atol\u001b[38;5;241m=\u001b[39matol), (\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTest case \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m failed! \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCalculated: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcalculated_H\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Target: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtarget_H\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    122\u001b[0m )\n\u001b[0;32m    124\u001b[0m \u001b[38;5;66;03m# Print the results\u001b[39;00m\n\u001b[0;32m    125\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTest case \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m passed.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mAssertionError\u001b[0m: Test case 1 failed! Calculated: [[0. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0.]], Target: [[985147.05262796   3519.91873466   2026.13510524   1382.4090176\n    1042.19347808]\n [  3519.91873466 982670.64171272   3525.50675695   2028.02156111\n    1382.4090176 ]\n [  2026.13510524   3525.50675695 982026.55888623   3525.50675695\n    2026.13510524]\n [  1382.4090176    2028.02156111   3525.50675695 982670.64171272\n    3519.91873466]\n [  1042.19347808   1382.4090176    2026.13510524   3519.91873466\n  985147.05262796]]"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from src.scicode.parse.parse import process_hdf5_to_tuple\n",
    "\n",
    "def generate_Hamiltonian(P, phi, R, l, w, a, n, h, N, rho):\n",
    "    '''\n",
    "    Function to generate the Hamiltonian of trapped nanospheres with optical binding force.\n",
    "\n",
    "    Input\n",
    "    -----\n",
    "    P : list of length N\n",
    "        Power of each individual optical trap.\n",
    "    phi : float\n",
    "        Polarization direction of the optical traps.\n",
    "    R : float\n",
    "        Distance between the adjacent trapped nanospheres.\n",
    "    l : float\n",
    "        Wavelength of the optical traps.\n",
    "    w : float\n",
    "        Beam waist of the optical traps.\n",
    "    a : float\n",
    "        Radius of the trapped microspheres.\n",
    "    n : float\n",
    "        Refractive index of the trapped microspheres.\n",
    "    h : float\n",
    "        Step size of the differentiation.\n",
    "    N : int\n",
    "        The total number of trapped nanospheres.\n",
    "    rho: float\n",
    "        Density of the trapped microspheres.\n",
    "\n",
    "    Output\n",
    "    ------\n",
    "    H : matrix of shape(N, N)\n",
    "        The Hamiltonian of trapped nanospheres with optical binding force appeared.\n",
    "    '''\n",
    "    # Constants\n",
    "    c = 3e8  # Speed of light (m/s)\n",
    "    eps_0 = 8.854e-12  # Vacuum permittivity (F/m)\n",
    "    m = (4 / 3) * np.pi * a**3 * rho  # Mass of the microsphere\n",
    "    k = 2 * np.pi / l  # Wave number\n",
    "\n",
    "    # Scalar polarizability\n",
    "    alpha = (4 * np.pi * eps_0 * a**3 * (n**2 - 1)) / (n**2 + 2)\n",
    "\n",
    "    # Coupling constants and resonant frequencies\n",
    "    k_values = np.zeros((N, N))\n",
    "    for i in range(N):\n",
    "        for j in range(N):\n",
    "            if i != j:\n",
    "                dR = R * np.abs(i - j)\n",
    "                k_values[i, j] = alpha**2 / (m * dR**4)\n",
    "\n",
    "    # Ensure diagonal dominance for positive frequencies\n",
    "    k_diag = -np.sum(k_values, axis=1)\n",
    "    np.fill_diagonal(k_values, k_diag)\n",
    "\n",
    "    # Resonant frequencies\n",
    "    Omega = np.zeros(N)\n",
    "    for i in range(N):\n",
    "        total_k = k_values[i, i] + np.sum(k_values[i, :])\n",
    "        if total_k > 0:\n",
    "            Omega[i] = np.sqrt(total_k / m)\n",
    "        else:\n",
    "            Omega[i] = 0  # Handle invalid cases safely\n",
    "\n",
    "    # Coupling constants\n",
    "    g = np.zeros((N, N))\n",
    "    for i in range(N):\n",
    "        for j in range(N):\n",
    "            if i != j and Omega[i] > 0 and Omega[j] > 0:\n",
    "                g[i, j] = -k_values[i, j] / (2 * m * np.sqrt(Omega[i] * Omega[j]))\n",
    "\n",
    "    # Constructing the Hamiltonian matrix\n",
    "    H = np.zeros((N, N))\n",
    "    for i in range(N):\n",
    "        H[i, i] = Omega[i]  # Diagonal elements\n",
    "    for i in range(N):\n",
    "        for j in range(N):\n",
    "            if i != j:\n",
    "                H[i, j] = g[i, j]  # Off-diagonal elements\n",
    "\n",
    "    return H\n",
    "\n",
    "# Function to load test outputs\n",
    "def load_test_outputs():\n",
    "    h5_file_path = \"eval/data/test_data.h5\"\n",
    "    global H5PY_FILE\n",
    "    H5PY_FILE = h5_file_path\n",
    "    step_id = \"32.2\"  # Updated step identifier\n",
    "    test_num = 3  # Number of test cases\n",
    "    return process_hdf5_to_tuple(step_id, test_num)\n",
    "\n",
    "# Main script to test the function\n",
    "if __name__ == \"__main__\":\n",
    "    # Load the target outputs from the HDF5 file\n",
    "    test_outputs = load_test_outputs()\n",
    "    print(\"Loaded Test Outputs:\", test_outputs)\n",
    "\n",
    "    # Define the test cases\n",
    "    test_cases = [\n",
    "        {\"P\": [100e-3] * 5, \"phi\": np.pi / 2, \"R\": 0.99593306197 * 1550e-9, \"l\": 1550e-9, \"w\": 600e-9, \"a\": 100e-9, \"n\": 1.444, \"h\": 1e-6, \"N\": 5, \"rho\": 2.648e3},\n",
    "        {\"P\": [100e-3] * 5, \"phi\": np.pi / 2, \"R\": 2 * 1550e-9, \"l\": 1550e-9, \"w\": 600e-9, \"a\": 100e-9, \"n\": 1.444, \"h\": 1e-6, \"N\": 5, \"rho\": 2.648e3},\n",
    "        {\"P\": [100e-3] * 5, \"phi\": 0, \"R\": 1 * 1550e-9, \"l\": 1550e-9, \"w\": 600e-9, \"a\": 100e-9, \"n\": 1.444, \"h\": 1e-6, \"N\": 5, \"rho\": 2.648e3},\n",
    "    ]\n",
    "\n",
    "    # Numerical tolerance settings\n",
    "    rtol = 1e-4  # Relative tolerance\n",
    "    atol = 1e-4  # Absolute tolerance\n",
    "\n",
    "    # Run the test cases\n",
    "    for i, test_case in enumerate(test_cases):\n",
    "        # Calculate the Hamiltonian\n",
    "        calculated_H = generate_Hamiltonian(**test_case)\n",
    "\n",
    "        # Get the target Hamiltonian from the loaded test outputs\n",
    "        target_H = test_outputs[i]\n",
    "\n",
    "        # Check if the calculated Hamiltonian matches the target within the specified tolerance\n",
    "        assert np.allclose(calculated_H, target_H, rtol=rtol, atol=atol), (\n",
    "            f\"Test case {i+1} failed! \"\n",
    "            f\"Calculated: {calculated_H}, Target: {target_H}\"\n",
    "        )\n",
    "\n",
    "        # Print the results\n",
    "        print(f\"Test case {i+1} passed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6cb12a44-7eab-444f-9636-8fd73032952b",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unterminated string literal (detected at line 99) (4277769597.py, line 99)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[5], line 99\u001b[1;36m\u001b[0m\n\u001b[1;33m    {\"P\": [100e-3] * 5, \"phi\": np.pi / 2, \"R\": 2 * 1550e-9, \"l\": 1550e-9, \"w\": 600e-9, \"a\": 100e-9, \"n\": 1.444, \"h\": 1e-6, \"\u001b[0m\n\u001b[1;37m                                                                                                                           ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m unterminated string literal (detected at line 99)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from src.scicode.parse.parse import process_hdf5_to_tuple\n",
    "\n",
    "def generate_Hamiltonian(P, phi, R, l, w, a, n, h, N, rho):\n",
    "    '''\n",
    "    Function to generate the Hamiltonian of trapped nanospheres with optical binding force.\n",
    "\n",
    "    Input\n",
    "    -----\n",
    "    P : list of length N\n",
    "        Power of each individual optical trap.\n",
    "    phi : float\n",
    "        Polarization direction of the optical traps.\n",
    "    R : float\n",
    "        Distance between the adjacent trapped nanospheres.\n",
    "    l : float\n",
    "        Wavelength of the optical traps.\n",
    "    w : float\n",
    "        Beam waist of the optical traps.\n",
    "    a : float\n",
    "        Radius of the trapped microspheres.\n",
    "    n : float\n",
    "        Refractive index of the trapped microspheres.\n",
    "    h : float\n",
    "        Step size of the differentiation.\n",
    "    N : int\n",
    "        The total number of trapped nanospheres.\n",
    "    rho: float\n",
    "        Density of the trapped microspheres.\n",
    "\n",
    "    Output\n",
    "    ------\n",
    "    H : matrix of shape(N, N)\n",
    "        The Hamiltonian of trapped nanospheres with optical binding force appeared.\n",
    "    '''\n",
    "    # Constants\n",
    "    c = 3e8  # Speed of light (m/s)\n",
    "    eps_0 = 8.854e-12  # Vacuum permittivity (F/m)\n",
    "    m = (4 / 3) * np.pi * a**3 * rho  # Mass of the microsphere\n",
    "    k = 2 * np.pi / l  # Wave number\n",
    "\n",
    "    # Scalar polarizability\n",
    "    alpha = (4 * np.pi * eps_0 * a**3 * (n**2 - 1)) / (n**2 + 2)\n",
    "\n",
    "    # Coupling constants and resonant frequencies\n",
    "    k_values = np.zeros((N, N))\n",
    "    for i in range(N):\n",
    "        for j in range(N):\n",
    "            if i != j:\n",
    "                dR = R * np.abs(i - j)\n",
    "                k_values[i, j] = alpha**2 / (m * dR**4)\n",
    "\n",
    "    # Ensure diagonal dominance for positive frequencies\n",
    "    k_diag = -np.sum(k_values, axis=1)\n",
    "    np.fill_diagonal(k_values, k_diag)\n",
    "\n",
    "    # Resonant frequencies\n",
    "    Omega = np.zeros(N)\n",
    "    for i in range(N):\n",
    "        total_k = k_values[i, i] + np.sum(k_values[i, :])\n",
    "        Omega[i] = np.sqrt(max(total_k / m, 0))  # Avoid negative sqrt\n",
    "\n",
    "    # Coupling constants\n",
    "    g = np.zeros((N, N))\n",
    "    for i in range(N):\n",
    "        for j in range(N):\n",
    "            if i != j and Omega[i] > 0 and Omega[j] > 0:\n",
    "                g[i, j] = -k_values[i, j] / (2 * m * np.sqrt(Omega[i] * Omega[j]))\n",
    "\n",
    "    # Constructing the Hamiltonian matrix\n",
    "    H = np.zeros((N, N))\n",
    "    for i in range(N):\n",
    "        H[i, i] = Omega[i]  # Diagonal elements\n",
    "    for i in range(N):\n",
    "        for j in range(N):\n",
    "            if i != j:\n",
    "                H[i, j] = g[i, j]  # Off-diagonal elements\n",
    "\n",
    "    return H\n",
    "\n",
    "# Function to load test outputs\n",
    "def load_test_outputs():\n",
    "    h5_file_path = \"eval/data/test_data.h5\"\n",
    "    global H5PY_FILE\n",
    "    H5PY_FILE = h5_file_path\n",
    "    step_id = \"32.2\"  # Updated step identifier\n",
    "    test_num = 3  # Number of test cases\n",
    "    return process_hdf5_to_tuple(step_id, test_num)\n",
    "\n",
    "# Main script to test the function\n",
    "if __name__ == \"__main__\":\n",
    "    # Load the target outputs from the HDF5 file\n",
    "    test_outputs = load_test_outputs()\n",
    "    print(\"Loaded Test Outputs:\", test_outputs)\n",
    "\n",
    "    # Define the test cases\n",
    "    test_cases = [\n",
    "        {\"P\": [100e-3] * 5, \"phi\": np.pi / 2, \"R\": 0.99593306197 * 1550e-9, \"l\": 1550e-9, \"w\": 600e-9, \"a\": 100e-9, \"n\": 1.444, \"h\": 1e-6, \"N\": 5, \"rho\": 2.648e3},\n",
    "        {\"P\": [100e-3] * 5, \"phi\": np.pi / 2, \"R\": 2 * 1550e-9, \"l\": 1550e-9, \"w\": 600e-9, \"a\": 100e-9, \"n\": 1.444, \"h\": 1e-6, \"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2c41bcfe-ff0f-4a93-8b2d-ec0ddae3413e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Test Outputs: [array([[985147.05262796,   3519.91873466,   2026.13510524,\n",
      "          1382.4090176 ,   1042.19347808],\n",
      "       [  3519.91873466, 982670.64171272,   3525.50675695,\n",
      "          2028.02156111,   1382.4090176 ],\n",
      "       [  2026.13510524,   3525.50675695, 982026.55888623,\n",
      "          3525.50675695,   2026.13510524],\n",
      "       [  1382.4090176 ,   2028.02156111,   3525.50675695,\n",
      "        982670.64171272,   3519.91873466],\n",
      "       [  1042.19347808,   1382.4090176 ,   2026.13510524,\n",
      "          3519.91873466, 985147.05262796]]), array([[9.88866250e+05, 1.98714355e+03, 1.02782631e+03, 6.89348389e+02,\n",
      "        5.17743766e+02],\n",
      "       [1.98714355e+03, 9.87397235e+05, 1.98896227e+03, 1.02841422e+03,\n",
      "        6.89348389e+02],\n",
      "       [1.02782631e+03, 1.98896227e+03, 9.87058624e+05, 1.98896227e+03,\n",
      "        1.02782631e+03],\n",
      "       [6.89348389e+02, 1.02841422e+03, 1.98896227e+03, 9.87397235e+05,\n",
      "        1.98714355e+03],\n",
      "       [5.17743766e+02, 6.89348389e+02, 1.02782631e+03, 1.98714355e+03,\n",
      "        9.88866250e+05]]), array([[9.91907992e+05, 9.85573690e+02, 1.29183297e+02, 3.86029400e+01,\n",
      "        1.63260875e+01],\n",
      "       [9.85573690e+02, 9.90938753e+05, 9.86100660e+02, 1.29240548e+02,\n",
      "        3.86029400e+01],\n",
      "       [1.29183297e+02, 9.86100660e+02, 9.90848130e+05, 9.86100660e+02,\n",
      "        1.29183297e+02],\n",
      "       [3.86029400e+01, 1.29240548e+02, 9.86100660e+02, 9.90938753e+05,\n",
      "        9.85573690e+02],\n",
      "       [1.63260875e+01, 3.86029400e+01, 1.29183297e+02, 9.85573690e+02,\n",
      "        9.91907992e+05]])]\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Test case 1 failed! Calculated: [[0. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0.]], Target: [[985147.05262796   3519.91873466   2026.13510524   1382.4090176\n    1042.19347808]\n [  3519.91873466 982670.64171272   3525.50675695   2028.02156111\n    1382.4090176 ]\n [  2026.13510524   3525.50675695 982026.55888623   3525.50675695\n    2026.13510524]\n [  1382.4090176    2028.02156111   3525.50675695 982670.64171272\n    3519.91873466]\n [  1042.19347808   1382.4090176    2026.13510524   3519.91873466\n  985147.05262796]]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 116\u001b[0m\n\u001b[0;32m    113\u001b[0m target_H \u001b[38;5;241m=\u001b[39m test_outputs[i]\n\u001b[0;32m    115\u001b[0m \u001b[38;5;66;03m# Check if the calculated Hamiltonian matches the target within the specified tolerance\u001b[39;00m\n\u001b[1;32m--> 116\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m np\u001b[38;5;241m.\u001b[39mallclose(calculated_H, target_H, rtol\u001b[38;5;241m=\u001b[39mrtol, atol\u001b[38;5;241m=\u001b[39matol), (\n\u001b[0;32m    117\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTest case \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m failed! \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    118\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCalculated: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcalculated_H\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Target: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtarget_H\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    119\u001b[0m )\n\u001b[0;32m    121\u001b[0m \u001b[38;5;66;03m# Print the results\u001b[39;00m\n\u001b[0;32m    122\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTest case \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m passed.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mAssertionError\u001b[0m: Test case 1 failed! Calculated: [[0. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0.]], Target: [[985147.05262796   3519.91873466   2026.13510524   1382.4090176\n    1042.19347808]\n [  3519.91873466 982670.64171272   3525.50675695   2028.02156111\n    1382.4090176 ]\n [  2026.13510524   3525.50675695 982026.55888623   3525.50675695\n    2026.13510524]\n [  1382.4090176    2028.02156111   3525.50675695 982670.64171272\n    3519.91873466]\n [  1042.19347808   1382.4090176    2026.13510524   3519.91873466\n  985147.05262796]]"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from src.scicode.parse.parse import process_hdf5_to_tuple\n",
    "\n",
    "def generate_Hamiltonian(P, phi, R, l, w, a, n, h, N, rho):\n",
    "    '''\n",
    "    Function to generate the Hamiltonian of trapped nanospheres with optical binding force.\n",
    "\n",
    "    Input\n",
    "    -----\n",
    "    P : list of length N\n",
    "        Power of each individual optical trap.\n",
    "    phi : float\n",
    "        Polarization direction of the optical traps.\n",
    "    R : float\n",
    "        Distance between the adjacent trapped nanospheres.\n",
    "    l : float\n",
    "        Wavelength of the optical traps.\n",
    "    w : float\n",
    "        Beam waist of the optical traps.\n",
    "    a : float\n",
    "        Radius of the trapped microspheres.\n",
    "    n : float\n",
    "        Refractive index of the trapped microspheres.\n",
    "    h : float\n",
    "        Step size of the differentiation.\n",
    "    N : int\n",
    "        The total number of trapped nanospheres.\n",
    "    rho: float\n",
    "        Density of the trapped microspheres.\n",
    "\n",
    "    Output\n",
    "    ------\n",
    "    H : matrix of shape(N, N)\n",
    "        The Hamiltonian of trapped nanospheres with optical binding force appeared.\n",
    "    '''\n",
    "    # Constants\n",
    "    c = 3e8  # Speed of light (m/s)\n",
    "    eps_0 = 8.854e-12  # Vacuum permittivity (F/m)\n",
    "    m = (4 / 3) * np.pi * a**3 * rho  # Mass of the microsphere\n",
    "    k = 2 * np.pi / l  # Wave number\n",
    "\n",
    "    # Scalar polarizability\n",
    "    alpha = (4 * np.pi * eps_0 * a**3 * (n**2 - 1)) / (n**2 + 2)\n",
    "\n",
    "    # Coupling constants and resonant frequencies\n",
    "    k_values = np.zeros((N, N))\n",
    "    for i in range(N):\n",
    "        for j in range(N):\n",
    "            if i != j:\n",
    "                dR = R * np.abs(i - j)\n",
    "                k_values[i, j] = alpha**2 / (m * dR**4)\n",
    "\n",
    "    # Ensure diagonal dominance for positive frequencies\n",
    "    k_diag = -np.sum(k_values, axis=1)\n",
    "    np.fill_diagonal(k_values, k_diag)\n",
    "\n",
    "    # Resonant frequencies\n",
    "    Omega = np.zeros(N)\n",
    "    for i in range(N):\n",
    "        total_k = k_values[i, i] + np.sum(k_values[i, :])\n",
    "        Omega[i] = np.sqrt(max(total_k / m, 0))  # Avoid negative sqrt\n",
    "\n",
    "    # Coupling constants\n",
    "    g = np.zeros((N, N))\n",
    "    for i in range(N):\n",
    "        for j in range(N):\n",
    "            if i != j and Omega[i] > 0 and Omega[j] > 0:\n",
    "                g[i, j] = -k_values[i, j] / (2 * m * np.sqrt(Omega[i] * Omega[j]))\n",
    "\n",
    "    # Constructing the Hamiltonian matrix\n",
    "    H = np.zeros((N, N))\n",
    "    for i in range(N):\n",
    "        H[i, i] = Omega[i]  # Diagonal elements\n",
    "    for i in range(N):\n",
    "        for j in range(N):\n",
    "            if i != j:\n",
    "                H[i, j] = g[i, j]  # Off-diagonal elements\n",
    "\n",
    "    return H\n",
    "\n",
    "# Function to load test outputs\n",
    "def load_test_outputs():\n",
    "    h5_file_path = \"eval/data/test_data.h5\"\n",
    "    global H5PY_FILE\n",
    "    H5PY_FILE = h5_file_path\n",
    "    step_id = \"32.2\"  # Updated step identifier\n",
    "    test_num = 3  # Number of test cases\n",
    "    return process_hdf5_to_tuple(step_id, test_num)\n",
    "\n",
    "# Main script to test the function\n",
    "if __name__ == \"__main__\":\n",
    "    # Load the target outputs from the HDF5 file\n",
    "    test_outputs = load_test_outputs()\n",
    "    print(\"Loaded Test Outputs:\", test_outputs)\n",
    "\n",
    "    # Define the test cases\n",
    "    test_cases = [\n",
    "        {\"P\": [100e-3] * 5, \"phi\": np.pi / 2, \"R\": 0.99593306197 * 1550e-9, \"l\": 1550e-9, \"w\": 600e-9, \"a\": 100e-9, \"n\": 1.444, \"h\": 1e-6, \"N\": 5, \"rho\": 2.648e3},\n",
    "        {\"P\": [100e-3] * 5, \"phi\": np.pi / 2, \"R\": 2 * 1550e-9, \"l\": 1550e-9, \"w\": 600e-9, \"a\": 100e-9, \"n\": 1.444, \"h\": 1e-6, \"N\": 5, \"rho\": 2.648e3},\n",
    "        {\"P\": [100e-3] * 5, \"phi\": 0, \"R\": 1 * 1550e-9, \"l\": 1550e-9, \"w\": 600e-9, \"a\": 100e-9, \"n\": 1.444, \"h\": 1e-6, \"N\": 5, \"rho\": 2.648e3},\n",
    "    ]\n",
    "\n",
    "    # Numerical tolerance settings\n",
    "    rtol = 1e-4  # Relative tolerance\n",
    "    atol = 1e-4  # Absolute tolerance\n",
    "\n",
    "    # Run the test cases\n",
    "    for i, test_case in enumerate(test_cases):\n",
    "        # Calculate the Hamiltonian\n",
    "        calculated_H = generate_Hamiltonian(**test_case)\n",
    "\n",
    "        # Get the target Hamiltonian from the loaded test outputs\n",
    "        target_H = test_outputs[i]\n",
    "\n",
    "        # Check if the calculated Hamiltonian matches the target within the specified tolerance\n",
    "        assert np.allclose(calculated_H, target_H, rtol=rtol, atol=atol), (\n",
    "            f\"Test case {i+1} failed! \"\n",
    "            f\"Calculated: {calculated_H}, Target: {target_H}\"\n",
    "        )\n",
    "\n",
    "        # Print the results\n",
    "        print(f\"Test case {i+1} passed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cf318972-7427-4357-b76f-6af8543a98a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Test Outputs: [array([[985147.05262796,   3519.91873466,   2026.13510524,\n",
      "          1382.4090176 ,   1042.19347808],\n",
      "       [  3519.91873466, 982670.64171272,   3525.50675695,\n",
      "          2028.02156111,   1382.4090176 ],\n",
      "       [  2026.13510524,   3525.50675695, 982026.55888623,\n",
      "          3525.50675695,   2026.13510524],\n",
      "       [  1382.4090176 ,   2028.02156111,   3525.50675695,\n",
      "        982670.64171272,   3519.91873466],\n",
      "       [  1042.19347808,   1382.4090176 ,   2026.13510524,\n",
      "          3519.91873466, 985147.05262796]]), array([[9.88866250e+05, 1.98714355e+03, 1.02782631e+03, 6.89348389e+02,\n",
      "        5.17743766e+02],\n",
      "       [1.98714355e+03, 9.87397235e+05, 1.98896227e+03, 1.02841422e+03,\n",
      "        6.89348389e+02],\n",
      "       [1.02782631e+03, 1.98896227e+03, 9.87058624e+05, 1.98896227e+03,\n",
      "        1.02782631e+03],\n",
      "       [6.89348389e+02, 1.02841422e+03, 1.98896227e+03, 9.87397235e+05,\n",
      "        1.98714355e+03],\n",
      "       [5.17743766e+02, 6.89348389e+02, 1.02782631e+03, 1.98714355e+03,\n",
      "        9.88866250e+05]]), array([[9.91907992e+05, 9.85573690e+02, 1.29183297e+02, 3.86029400e+01,\n",
      "        1.63260875e+01],\n",
      "       [9.85573690e+02, 9.90938753e+05, 9.86100660e+02, 1.29240548e+02,\n",
      "        3.86029400e+01],\n",
      "       [1.29183297e+02, 9.86100660e+02, 9.90848130e+05, 9.86100660e+02,\n",
      "        1.29183297e+02],\n",
      "       [3.86029400e+01, 1.29240548e+02, 9.86100660e+02, 9.90938753e+05,\n",
      "        9.85573690e+02],\n",
      "       [1.63260875e+01, 3.86029400e+01, 1.29183297e+02, 9.85573690e+02,\n",
      "        9.91907992e+05]])]\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Test case 1 failed! Calculated: [[ 1.00000000e-12 -6.25120153e+05 -3.90700095e+04 -7.71753275e+03\n  -2.44187560e+03]\n [-6.25120153e+05  1.00000000e-12 -6.25120153e+05 -3.90700095e+04\n  -7.71753275e+03]\n [-3.90700095e+04 -6.25120153e+05  1.00000000e-12 -6.25120153e+05\n  -3.90700095e+04]\n [-7.71753275e+03 -3.90700095e+04 -6.25120153e+05  1.00000000e-12\n  -6.25120153e+05]\n [-2.44187560e+03 -7.71753275e+03 -3.90700095e+04 -6.25120153e+05\n   1.00000000e-12]], Target: [[985147.05262796   3519.91873466   2026.13510524   1382.4090176\n    1042.19347808]\n [  3519.91873466 982670.64171272   3525.50675695   2028.02156111\n    1382.4090176 ]\n [  2026.13510524   3525.50675695 982026.55888623   3525.50675695\n    2026.13510524]\n [  1382.4090176    2028.02156111   3525.50675695 982670.64171272\n    3519.91873466]\n [  1042.19347808   1382.4090176    2026.13510524   3519.91873466\n  985147.05262796]]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 119\u001b[0m\n\u001b[0;32m    116\u001b[0m target_H \u001b[38;5;241m=\u001b[39m test_outputs[i]\n\u001b[0;32m    118\u001b[0m \u001b[38;5;66;03m# Check if the calculated Hamiltonian matches the target within the specified tolerance\u001b[39;00m\n\u001b[1;32m--> 119\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m np\u001b[38;5;241m.\u001b[39mallclose(calculated_H, target_H, rtol\u001b[38;5;241m=\u001b[39mrtol, atol\u001b[38;5;241m=\u001b[39matol), (\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTest case \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m failed! \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCalculated: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcalculated_H\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Target: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtarget_H\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    122\u001b[0m )\n\u001b[0;32m    124\u001b[0m \u001b[38;5;66;03m# Print the results\u001b[39;00m\n\u001b[0;32m    125\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTest case \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m passed.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mAssertionError\u001b[0m: Test case 1 failed! Calculated: [[ 1.00000000e-12 -6.25120153e+05 -3.90700095e+04 -7.71753275e+03\n  -2.44187560e+03]\n [-6.25120153e+05  1.00000000e-12 -6.25120153e+05 -3.90700095e+04\n  -7.71753275e+03]\n [-3.90700095e+04 -6.25120153e+05  1.00000000e-12 -6.25120153e+05\n  -3.90700095e+04]\n [-7.71753275e+03 -3.90700095e+04 -6.25120153e+05  1.00000000e-12\n  -6.25120153e+05]\n [-2.44187560e+03 -7.71753275e+03 -3.90700095e+04 -6.25120153e+05\n   1.00000000e-12]], Target: [[985147.05262796   3519.91873466   2026.13510524   1382.4090176\n    1042.19347808]\n [  3519.91873466 982670.64171272   3525.50675695   2028.02156111\n    1382.4090176 ]\n [  2026.13510524   3525.50675695 982026.55888623   3525.50675695\n    2026.13510524]\n [  1382.4090176    2028.02156111   3525.50675695 982670.64171272\n    3519.91873466]\n [  1042.19347808   1382.4090176    2026.13510524   3519.91873466\n  985147.05262796]]"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from src.scicode.parse.parse import process_hdf5_to_tuple\n",
    "\n",
    "def generate_Hamiltonian(P, phi, R, l, w, a, n, h, N, rho):\n",
    "    '''\n",
    "    Function to generate the Hamiltonian of trapped nanospheres with optical binding force.\n",
    "\n",
    "    Input\n",
    "    -----\n",
    "    P : list of length N\n",
    "        Power of each individual optical trap.\n",
    "    phi : float\n",
    "        Polarization direction of the optical traps.\n",
    "    R : float\n",
    "        Distance between the adjacent trapped nanospheres.\n",
    "    l : float\n",
    "        Wavelength of the optical traps.\n",
    "    w : float\n",
    "        Beam waist of the optical traps.\n",
    "    a : float\n",
    "        Radius of the trapped microspheres.\n",
    "    n : float\n",
    "        Refractive index of the trapped microspheres.\n",
    "    h : float\n",
    "        Step size of the differentiation.\n",
    "    N : int\n",
    "        The total number of trapped nanospheres.\n",
    "    rho: float\n",
    "        Density of the trapped microspheres.\n",
    "\n",
    "    Output\n",
    "    ------\n",
    "    H : matrix of shape(N, N)\n",
    "        The Hamiltonian of trapped nanospheres with optical binding force appeared.\n",
    "    '''\n",
    "    # Constants\n",
    "    c = 3e8  # Speed of light (m/s)\n",
    "    eps_0 = 8.854e-12  # Vacuum permittivity (F/m)\n",
    "    m = (4 / 3) * np.pi * a**3 * rho  # Mass of the microsphere\n",
    "    k = 2 * np.pi / l  # Wave number\n",
    "\n",
    "    # Scalar polarizability\n",
    "    alpha = (4 * np.pi * eps_0 * a**3 * (n**2 - 1)) / (n**2 + 2)\n",
    "\n",
    "    # Coupling constants and resonant frequencies\n",
    "    k_values = np.zeros((N, N))\n",
    "    for i in range(N):\n",
    "        for j in range(N):\n",
    "            if i != j:\n",
    "                dR = R * np.abs(i - j)\n",
    "                k_values[i, j] = alpha**2 / (m * dR**4)\n",
    "\n",
    "    # Ensure diagonal dominance for positive frequencies\n",
    "    for i in range(N):\n",
    "        k_values[i, i] = -np.sum(k_values[i, :])\n",
    "\n",
    "    # Resonant frequencies\n",
    "    Omega = np.zeros(N)\n",
    "    for i in range(N):\n",
    "        total_k = k_values[i, i] + np.sum(k_values[i, :])\n",
    "        if total_k > 0:\n",
    "            Omega[i] = np.sqrt(total_k / m)\n",
    "        else:\n",
    "            Omega[i] = 1e-12  # Small positive value to avoid zero or negative sqrt\n",
    "\n",
    "    # Coupling constants\n",
    "    g = np.zeros((N, N))\n",
    "    for i in range(N):\n",
    "        for j in range(N):\n",
    "            if i != j:\n",
    "                g[i, j] = -k_values[i, j] / (2 * m * np.sqrt(Omega[i] * Omega[j]))\n",
    "\n",
    "    # Constructing the Hamiltonian matrix\n",
    "    H = np.zeros((N, N))\n",
    "    for i in range(N):\n",
    "        H[i, i] = Omega[i]  # Diagonal elements\n",
    "    for i in range(N):\n",
    "        for j in range(N):\n",
    "            if i != j:\n",
    "                H[i, j] = g[i, j]  # Off-diagonal elements\n",
    "\n",
    "    return H\n",
    "\n",
    "# Function to load test outputs\n",
    "def load_test_outputs():\n",
    "    h5_file_path = \"eval/data/test_data.h5\"\n",
    "    global H5PY_FILE\n",
    "    H5PY_FILE = h5_file_path\n",
    "    step_id = \"32.2\"  # Updated step identifier\n",
    "    test_num = 3  # Number of test cases\n",
    "    return process_hdf5_to_tuple(step_id, test_num)\n",
    "\n",
    "# Main script to test the function\n",
    "if __name__ == \"__main__\":\n",
    "    # Load the target outputs from the HDF5 file\n",
    "    test_outputs = load_test_outputs()\n",
    "    print(\"Loaded Test Outputs:\", test_outputs)\n",
    "\n",
    "    # Define the test cases\n",
    "    test_cases = [\n",
    "        {\"P\": [100e-3] * 5, \"phi\": np.pi / 2, \"R\": 0.99593306197 * 1550e-9, \"l\": 1550e-9, \"w\": 600e-9, \"a\": 100e-9, \"n\": 1.444, \"h\": 1e-6, \"N\": 5, \"rho\": 2.648e3},\n",
    "        {\"P\": [100e-3] * 5, \"phi\": np.pi / 2, \"R\": 2 * 1550e-9, \"l\": 1550e-9, \"w\": 600e-9, \"a\": 100e-9, \"n\": 1.444, \"h\": 1e-6, \"N\": 5, \"rho\": 2.648e3},\n",
    "        {\"P\": [100e-3] * 5, \"phi\": 0, \"R\": 1 * 1550e-9, \"l\": 1550e-9, \"w\": 600e-9, \"a\": 100e-9, \"n\": 1.444, \"h\": 1e-6, \"N\": 5, \"rho\": 2.648e3},\n",
    "    ]\n",
    "\n",
    "    # Numerical tolerance settings\n",
    "    rtol = 1e-4  # Relative tolerance\n",
    "    atol = 1e-4  # Absolute tolerance\n",
    "\n",
    "    # Run the test cases\n",
    "    for i, test_case in enumerate(test_cases):\n",
    "        # Calculate the Hamiltonian\n",
    "        calculated_H = generate_Hamiltonian(**test_case)\n",
    "\n",
    "        # Get the target Hamiltonian from the loaded test outputs\n",
    "        target_H = test_outputs[i]\n",
    "\n",
    "        # Check if the calculated Hamiltonian matches the target within the specified tolerance\n",
    "        assert np.allclose(calculated_H, target_H, rtol=rtol, atol=atol), (\n",
    "            f\"Test case {i+1} failed! \"\n",
    "            f\"Calculated: {calculated_H}, Target: {target_H}\"\n",
    "        )\n",
    "\n",
    "        # Print the results\n",
    "        print(f\"Test case {i+1} passed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d9ff63f9-e57a-4db8-9b33-381c9efb480a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Test Outputs: [array([[985147.05262796,   3519.91873466,   2026.13510524,\n",
      "          1382.4090176 ,   1042.19347808],\n",
      "       [  3519.91873466, 982670.64171272,   3525.50675695,\n",
      "          2028.02156111,   1382.4090176 ],\n",
      "       [  2026.13510524,   3525.50675695, 982026.55888623,\n",
      "          3525.50675695,   2026.13510524],\n",
      "       [  1382.4090176 ,   2028.02156111,   3525.50675695,\n",
      "        982670.64171272,   3519.91873466],\n",
      "       [  1042.19347808,   1382.4090176 ,   2026.13510524,\n",
      "          3519.91873466, 985147.05262796]]), array([[9.88866250e+05, 1.98714355e+03, 1.02782631e+03, 6.89348389e+02,\n",
      "        5.17743766e+02],\n",
      "       [1.98714355e+03, 9.87397235e+05, 1.98896227e+03, 1.02841422e+03,\n",
      "        6.89348389e+02],\n",
      "       [1.02782631e+03, 1.98896227e+03, 9.87058624e+05, 1.98896227e+03,\n",
      "        1.02782631e+03],\n",
      "       [6.89348389e+02, 1.02841422e+03, 1.98896227e+03, 9.87397235e+05,\n",
      "        1.98714355e+03],\n",
      "       [5.17743766e+02, 6.89348389e+02, 1.02782631e+03, 1.98714355e+03,\n",
      "        9.88866250e+05]]), array([[9.91907992e+05, 9.85573690e+02, 1.29183297e+02, 3.86029400e+01,\n",
      "        1.63260875e+01],\n",
      "       [9.85573690e+02, 9.90938753e+05, 9.86100660e+02, 1.29240548e+02,\n",
      "        3.86029400e+01],\n",
      "       [1.29183297e+02, 9.86100660e+02, 9.90848130e+05, 9.86100660e+02,\n",
      "        1.29183297e+02],\n",
      "       [3.86029400e+01, 1.29240548e+02, 9.86100660e+02, 9.90938753e+05,\n",
      "        9.85573690e+02],\n",
      "       [1.63260875e+01, 3.86029400e+01, 1.29183297e+02, 9.85573690e+02,\n",
      "        9.91907992e+05]])]\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Test case 1 failed! Calculated: [[ 1.00000000e-06 -6.25120153e-01 -3.90700095e-02 -7.71753275e-03\n  -2.44187560e-03]\n [-6.25120153e-01  1.00000000e-06 -6.25120153e-01 -3.90700095e-02\n  -7.71753275e-03]\n [-3.90700095e-02 -6.25120153e-01  1.00000000e-06 -6.25120153e-01\n  -3.90700095e-02]\n [-7.71753275e-03 -3.90700095e-02 -6.25120153e-01  1.00000000e-06\n  -6.25120153e-01]\n [-2.44187560e-03 -7.71753275e-03 -3.90700095e-02 -6.25120153e-01\n   1.00000000e-06]], Target: [[985147.05262796   3519.91873466   2026.13510524   1382.4090176\n    1042.19347808]\n [  3519.91873466 982670.64171272   3525.50675695   2028.02156111\n    1382.4090176 ]\n [  2026.13510524   3525.50675695 982026.55888623   3525.50675695\n    2026.13510524]\n [  1382.4090176    2028.02156111   3525.50675695 982670.64171272\n    3519.91873466]\n [  1042.19347808   1382.4090176    2026.13510524   3519.91873466\n  985147.05262796]]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 118\u001b[0m\n\u001b[0;32m    115\u001b[0m target_H \u001b[38;5;241m=\u001b[39m test_outputs[i]\n\u001b[0;32m    117\u001b[0m \u001b[38;5;66;03m# Check if the calculated Hamiltonian matches the target within the specified tolerance\u001b[39;00m\n\u001b[1;32m--> 118\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m np\u001b[38;5;241m.\u001b[39mallclose(calculated_H, target_H, rtol\u001b[38;5;241m=\u001b[39mrtol, atol\u001b[38;5;241m=\u001b[39matol), (\n\u001b[0;32m    119\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTest case \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m failed! \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCalculated: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcalculated_H\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Target: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtarget_H\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    121\u001b[0m )\n\u001b[0;32m    123\u001b[0m \u001b[38;5;66;03m# Print the results\u001b[39;00m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTest case \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m passed.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mAssertionError\u001b[0m: Test case 1 failed! Calculated: [[ 1.00000000e-06 -6.25120153e-01 -3.90700095e-02 -7.71753275e-03\n  -2.44187560e-03]\n [-6.25120153e-01  1.00000000e-06 -6.25120153e-01 -3.90700095e-02\n  -7.71753275e-03]\n [-3.90700095e-02 -6.25120153e-01  1.00000000e-06 -6.25120153e-01\n  -3.90700095e-02]\n [-7.71753275e-03 -3.90700095e-02 -6.25120153e-01  1.00000000e-06\n  -6.25120153e-01]\n [-2.44187560e-03 -7.71753275e-03 -3.90700095e-02 -6.25120153e-01\n   1.00000000e-06]], Target: [[985147.05262796   3519.91873466   2026.13510524   1382.4090176\n    1042.19347808]\n [  3519.91873466 982670.64171272   3525.50675695   2028.02156111\n    1382.4090176 ]\n [  2026.13510524   3525.50675695 982026.55888623   3525.50675695\n    2026.13510524]\n [  1382.4090176    2028.02156111   3525.50675695 982670.64171272\n    3519.91873466]\n [  1042.19347808   1382.4090176    2026.13510524   3519.91873466\n  985147.05262796]]"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from src.scicode.parse.parse import process_hdf5_to_tuple\n",
    "\n",
    "def generate_Hamiltonian(P, phi, R, l, w, a, n, h, N, rho):\n",
    "    '''\n",
    "    Function to generate the Hamiltonian of trapped nanospheres with optical binding force.\n",
    "\n",
    "    Input\n",
    "    -----\n",
    "    P : list of length N\n",
    "        Power of each individual optical trap.\n",
    "    phi : float\n",
    "        Polarization direction of the optical traps.\n",
    "    R : float\n",
    "        Distance between the adjacent trapped nanospheres.\n",
    "    l : float\n",
    "        Wavelength of the optical traps.\n",
    "    w : float\n",
    "        Beam waist of the optical traps.\n",
    "    a : float\n",
    "        Radius of the trapped microspheres.\n",
    "    n : float\n",
    "        Refractive index of the trapped microspheres.\n",
    "    h : float\n",
    "        Step size of the differentiation.\n",
    "    N : int\n",
    "        The total number of trapped nanospheres.\n",
    "    rho: float\n",
    "        Density of the trapped microspheres.\n",
    "\n",
    "    Output\n",
    "    ------\n",
    "    H : matrix of shape(N, N)\n",
    "        The Hamiltonian of trapped nanospheres with optical binding force appeared.\n",
    "    '''\n",
    "    # Constants\n",
    "    c = 3e8  # Speed of light (m/s)\n",
    "    eps_0 = 8.854e-12  # Vacuum permittivity (F/m)\n",
    "    m = (4 / 3) * np.pi * a**3 * rho  # Mass of the microsphere\n",
    "    k = 2 * np.pi / l  # Wave number\n",
    "\n",
    "    # Scalar polarizability\n",
    "    alpha = (4 * np.pi * eps_0 * a**3 * (n**2 - 1)) / (n**2 + 2)\n",
    "\n",
    "    # Coupling constants and resonant frequencies\n",
    "    k_values = np.zeros((N, N))\n",
    "    for i in range(N):\n",
    "        for j in range(N):\n",
    "            if i != j:\n",
    "                dR = R * np.abs(i - j)\n",
    "                # Use a minimum value for dR to avoid division by very small numbers\n",
    "                dR = max(dR, 1e-12)\n",
    "                k_values[i, j] = alpha**2 / (m * dR**4)\n",
    "\n",
    "    # Ensure diagonal dominance for positive frequencies\n",
    "    for i in range(N):\n",
    "        k_values[i, i] = -np.sum(k_values[i, :])\n",
    "\n",
    "    # Resonant frequencies\n",
    "    Omega = np.zeros(N)\n",
    "    for i in range(N):\n",
    "        total_k = k_values[i, i] + np.sum(k_values[i, :])\n",
    "        Omega[i] = np.sqrt(max(total_k / m, 1e-12))  # Ensure a minimum value for stability\n",
    "\n",
    "    # Coupling constants\n",
    "    g = np.zeros((N, N))\n",
    "    for i in range(N):\n",
    "        for j in range(N):\n",
    "            if i != j:\n",
    "                g[i, j] = -k_values[i, j] / (2 * m * np.sqrt(max(Omega[i] * Omega[j], 1e-12)))\n",
    "\n",
    "    # Constructing the Hamiltonian matrix\n",
    "    H = np.zeros((N, N))\n",
    "    for i in range(N):\n",
    "        H[i, i] = Omega[i]  # Diagonal elements\n",
    "    for i in range(N):\n",
    "        for j in range(N):\n",
    "            if i != j:\n",
    "                H[i, j] = g[i, j]  # Off-diagonal elements\n",
    "\n",
    "    return H\n",
    "\n",
    "# Function to load test outputs\n",
    "def load_test_outputs():\n",
    "    h5_file_path = \"eval/data/test_data.h5\"\n",
    "    global H5PY_FILE\n",
    "    H5PY_FILE = h5_file_path\n",
    "    step_id = \"32.2\"  # Updated step identifier\n",
    "    test_num = 3  # Number of test cases\n",
    "    return process_hdf5_to_tuple(step_id, test_num)\n",
    "\n",
    "# Main script to test the function\n",
    "if __name__ == \"__main__\":\n",
    "    # Load the target outputs from the HDF5 file\n",
    "    test_outputs = load_test_outputs()\n",
    "    print(\"Loaded Test Outputs:\", test_outputs)\n",
    "\n",
    "    # Define the test cases\n",
    "    test_cases = [\n",
    "        {\"P\": [100e-3] * 5, \"phi\": np.pi / 2, \"R\": 0.99593306197 * 1550e-9, \"l\": 1550e-9, \"w\": 600e-9, \"a\": 100e-9, \"n\": 1.444, \"h\": 1e-6, \"N\": 5, \"rho\": 2.648e3},\n",
    "        {\"P\": [100e-3] * 5, \"phi\": np.pi / 2, \"R\": 2 * 1550e-9, \"l\": 1550e-9, \"w\": 600e-9, \"a\": 100e-9, \"n\": 1.444, \"h\": 1e-6, \"N\": 5, \"rho\": 2.648e3},\n",
    "        {\"P\": [100e-3] * 5, \"phi\": 0, \"R\": 1 * 1550e-9, \"l\": 1550e-9, \"w\": 600e-9, \"a\": 100e-9, \"n\": 1.444, \"h\": 1e-6, \"N\": 5, \"rho\": 2.648e3},\n",
    "    ]\n",
    "\n",
    "    # Numerical tolerance settings\n",
    "    rtol = 1e-4  # Relative tolerance\n",
    "    atol = 1e-4  # Absolute tolerance\n",
    "\n",
    "    # Run the test cases\n",
    "    for i, test_case in enumerate(test_cases):\n",
    "        # Calculate the Hamiltonian\n",
    "        calculated_H = generate_Hamiltonian(**test_case)\n",
    "\n",
    "        # Get the target Hamiltonian from the loaded test outputs\n",
    "        target_H = test_outputs[i]\n",
    "\n",
    "        # Check if the calculated Hamiltonian matches the target within the specified tolerance\n",
    "        assert np.allclose(calculated_H, target_H, rtol=rtol, atol=atol), (\n",
    "            f\"Test case {i+1} failed! \"\n",
    "            f\"Calculated: {calculated_H}, Target: {target_H}\"\n",
    "        )\n",
    "\n",
    "        # Print the results\n",
    "        print(f\"Test case {i+1} passed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "24fb148b-8432-4f65-8845-a279f797d393",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Test case 1 failed! Calculated: [[ 3.86777174e-12 -1.52227530e-12 -9.45757806e-14 -1.87935222e-14\n  -7.00276075e-15]\n [-1.52227530e-12  5.36405155e-12 -1.28494300e-12 -8.07899174e-14\n  -1.87935222e-14]\n [-9.45757806e-14 -1.28494300e-12  5.42849585e-12 -1.28494300e-12\n  -9.45757806e-14]\n [-1.87935222e-14 -8.07899174e-14 -1.28494300e-12  5.36405155e-12\n  -1.52227530e-12]\n [-7.00276075e-15 -1.87935222e-14 -9.45757806e-14 -1.52227530e-12\n   3.86777174e-12]], Target: [[695394.49015704 779819.66086153 571883.99412053 632910.80765219\n  961585.29023535]\n [281731.16814514 528391.52172672 462972.20796306 828433.50813092\n  692330.69901293]\n [238626.28609442 981000.62868711 342393.73101939 366698.7327763\n  937104.9195979 ]\n [ 61262.61429011 606734.35747192 296528.94104104 774618.54972758\n  537974.53679591]\n [295134.83682407 826908.05720425 168397.9496306  977138.80187462\n   22214.52320757]]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 99\u001b[0m\n\u001b[0;32m     96\u001b[0m target_H \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mrandom(calculated_H\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m1e6\u001b[39m  \u001b[38;5;66;03m# Placeholder for actual target\u001b[39;00m\n\u001b[0;32m     98\u001b[0m \u001b[38;5;66;03m# Check if the calculated Hamiltonian matches the target within the specified tolerance\u001b[39;00m\n\u001b[1;32m---> 99\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m np\u001b[38;5;241m.\u001b[39mallclose(calculated_H, target_H, rtol\u001b[38;5;241m=\u001b[39mrtol, atol\u001b[38;5;241m=\u001b[39matol), (\n\u001b[0;32m    100\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTest case \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m failed! \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    101\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCalculated: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcalculated_H\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Target: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtarget_H\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    102\u001b[0m )\n\u001b[0;32m    104\u001b[0m \u001b[38;5;66;03m# Print the results\u001b[39;00m\n\u001b[0;32m    105\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTest case \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m passed.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mAssertionError\u001b[0m: Test case 1 failed! Calculated: [[ 3.86777174e-12 -1.52227530e-12 -9.45757806e-14 -1.87935222e-14\n  -7.00276075e-15]\n [-1.52227530e-12  5.36405155e-12 -1.28494300e-12 -8.07899174e-14\n  -1.87935222e-14]\n [-9.45757806e-14 -1.28494300e-12  5.42849585e-12 -1.28494300e-12\n  -9.45757806e-14]\n [-1.87935222e-14 -8.07899174e-14 -1.28494300e-12  5.36405155e-12\n  -1.52227530e-12]\n [-7.00276075e-15 -1.87935222e-14 -9.45757806e-14 -1.52227530e-12\n   3.86777174e-12]], Target: [[695394.49015704 779819.66086153 571883.99412053 632910.80765219\n  961585.29023535]\n [281731.16814514 528391.52172672 462972.20796306 828433.50813092\n  692330.69901293]\n [238626.28609442 981000.62868711 342393.73101939 366698.7327763\n  937104.9195979 ]\n [ 61262.61429011 606734.35747192 296528.94104104 774618.54972758\n  537974.53679591]\n [295134.83682407 826908.05720425 168397.9496306  977138.80187462\n   22214.52320757]]"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Function to generate the Hamiltonian for coupled nanospheres\n",
    "def generate_Hamiltonian(P, phi, R, l, w, a, n, h, N, rho):\n",
    "    '''\n",
    "    Function to generate the Hamiltonian of trapped nanospheres with optical binding force.\n",
    "\n",
    "    Input\n",
    "    -----\n",
    "    P : list of length N\n",
    "        Power of each individual optical trap.\n",
    "    phi : float\n",
    "        Polarization direction of the optical traps.\n",
    "    R : float\n",
    "        Distance between the adjacent trapped nanospheres.\n",
    "    l : float\n",
    "        Wavelength of the optical traps.\n",
    "    w : float\n",
    "        Beam waist of the optical traps.\n",
    "    a : float\n",
    "        Radius of the trapped microspheres.\n",
    "    n : float\n",
    "        Refractive index of the trapped microspheres.\n",
    "    h : float\n",
    "        Step size of the differentiation.\n",
    "    N : int\n",
    "        The total number of trapped nanospheres.\n",
    "    rho: float\n",
    "        Density of the trapped microspheres.\n",
    "\n",
    "    Output\n",
    "    ------\n",
    "    H : matrix of shape(N, N)\n",
    "        The Hamiltonian of trapped nanospheres with optical binding force.\n",
    "    '''\n",
    "    # Constants\n",
    "    c = 3e8  # Speed of light (m/s)\n",
    "    eps_0 = 8.854e-12  # Vacuum permittivity (F/m)\n",
    "    m = (4 / 3) * np.pi * a**3 * rho  # Mass of the microsphere\n",
    "    k = 2 * np.pi / l  # Wave number\n",
    "\n",
    "    # Scalar polarizability\n",
    "    alpha = (4 * np.pi * eps_0 * a**3 * (n**2 - 1)) / (n**2 + 2)\n",
    "\n",
    "    # Coupling constants and resonant frequencies\n",
    "    k_values = np.zeros((N, N))\n",
    "    for i in range(N):\n",
    "        for j in range(N):\n",
    "            if i != j:\n",
    "                dR = R * np.abs(i - j)\n",
    "                k_values[i, j] = alpha**2 / (dR**4)\n",
    "\n",
    "    # Diagonal elements\n",
    "    for i in range(N):\n",
    "        k_values[i, i] = np.sum(np.abs(k_values[i, :]))\n",
    "\n",
    "    # Resonant frequencies\n",
    "    Omega = np.sqrt(np.diag(k_values) / m)\n",
    "\n",
    "    # Coupling constants (off-diagonal elements)\n",
    "    g = np.zeros((N, N))\n",
    "    for i in range(N):\n",
    "        for j in range(N):\n",
    "            if i != j:\n",
    "                g[i, j] = -k_values[i, j] / (2 * m * np.sqrt(Omega[i] * Omega[j]))\n",
    "\n",
    "    # Constructing the Hamiltonian matrix\n",
    "    H = np.zeros((N, N))\n",
    "    for i in range(N):\n",
    "        H[i, i] = Omega[i]  # Diagonal elements (resonant frequencies)\n",
    "    for i in range(N):\n",
    "        for j in range(N):\n",
    "            if i != j:\n",
    "                H[i, j] = g[i, j]  # Off-diagonal coupling terms\n",
    "\n",
    "    return H\n",
    "\n",
    "# Test cases\n",
    "test_cases = [\n",
    "    {\"P\": [100e-3] * 5, \"phi\": np.pi / 2, \"R\": 0.99593306197 * 1550e-9, \"l\": 1550e-9, \"w\": 600e-9, \"a\": 100e-9, \"n\": 1.444, \"h\": 1e-6, \"N\": 5, \"rho\": 2.648e3},\n",
    "    {\"P\": [100e-3] * 5, \"phi\": np.pi / 2, \"R\": 2 * 1550e-9, \"l\": 1550e-9, \"w\": 600e-9, \"a\": 100e-9, \"n\": 1.444, \"h\": 1e-6, \"N\": 5, \"rho\": 2.648e3},\n",
    "    {\"P\": [100e-3] * 5, \"phi\": 0, \"R\": 1 * 1550e-9, \"l\": 1550e-9, \"w\": 600e-9, \"a\": 100e-9, \"n\": 1.444, \"h\": 1e-6, \"N\": 5, \"rho\": 2.648e3},\n",
    "]\n",
    "\n",
    "# Numerical tolerance settings\n",
    "rtol = 1e-4  # Relative tolerance\n",
    "atol = 1e-4  # Absolute tolerance\n",
    "\n",
    "# Run the test cases\n",
    "for i, test_case in enumerate(test_cases):\n",
    "    # Calculate the Hamiltonian\n",
    "    calculated_H = generate_Hamiltonian(**test_case)\n",
    "\n",
    "    # Dummy target values for testing purposes\n",
    "    # Replace with actual target values or HDF5 integration\n",
    "    target_H = np.random.random(calculated_H.shape) * 1e6  # Placeholder for actual target\n",
    "\n",
    "    # Check if the calculated Hamiltonian matches the target within the specified tolerance\n",
    "    assert np.allclose(calculated_H, target_H, rtol=rtol, atol=atol), (\n",
    "        f\"Test case {i+1} failed! \"\n",
    "        f\"Calculated: {calculated_H}, Target: {target_H}\"\n",
    "    )\n",
    "\n",
    "    # Print the results\n",
    "    print(f\"Test case {i+1} passed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6c783b5e-1489-47de-8c03-c698bda03c3f",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"Dataset '32.2_1' not found in the HDF5 file.\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 101\u001b[0m\n\u001b[0;32m     98\u001b[0m num_tests \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m\n\u001b[0;32m    100\u001b[0m \u001b[38;5;66;03m# Load the target outputs from the HDF5 file\u001b[39;00m\n\u001b[1;32m--> 101\u001b[0m test_outputs \u001b[38;5;241m=\u001b[39m load_test_outputs(h5_file_path, step_id, num_tests)\n\u001b[0;32m    103\u001b[0m \u001b[38;5;66;03m# Define the test cases\u001b[39;00m\n\u001b[0;32m    104\u001b[0m test_cases \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    105\u001b[0m     {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mP\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;241m100e-3\u001b[39m] \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m5\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mphi\u001b[39m\u001b[38;5;124m\"\u001b[39m: np\u001b[38;5;241m.\u001b[39mpi \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mR\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m0.99593306197\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m1550e-9\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ml\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m1550e-9\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m600e-9\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m100e-9\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m1.444\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mh\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m1e-6\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mN\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m5\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrho\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m2.648e3\u001b[39m},\n\u001b[0;32m    106\u001b[0m     {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mP\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;241m100e-3\u001b[39m] \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m5\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mphi\u001b[39m\u001b[38;5;124m\"\u001b[39m: np\u001b[38;5;241m.\u001b[39mpi \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mR\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m1550e-9\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ml\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m1550e-9\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m600e-9\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m100e-9\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m1.444\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mh\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m1e-6\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mN\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m5\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrho\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m2.648e3\u001b[39m},\n\u001b[0;32m    107\u001b[0m     {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mP\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;241m100e-3\u001b[39m] \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m5\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mphi\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mR\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m1550e-9\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ml\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m1550e-9\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m600e-9\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m100e-9\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m1.444\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mh\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m1e-6\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mN\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m5\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrho\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m2.648e3\u001b[39m},\n\u001b[0;32m    108\u001b[0m ]\n",
      "Cell \u001b[1;32mIn[15], line 88\u001b[0m, in \u001b[0;36mload_test_outputs\u001b[1;34m(h5_file_path, step_id, num_tests)\u001b[0m\n\u001b[0;32m     86\u001b[0m             outputs\u001b[38;5;241m.\u001b[39mappend(np\u001b[38;5;241m.\u001b[39marray(h5_file[dataset_name]))\n\u001b[0;32m     87\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 88\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdataset_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m not found in the HDF5 file.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     89\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "\u001b[1;31mKeyError\u001b[0m: \"Dataset '32.2_1' not found in the HDF5 file.\""
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "\n",
    "# Function to generate the Hamiltonian for coupled nanospheres\n",
    "def generate_Hamiltonian(P, phi, R, l, w, a, n, h, N, rho):\n",
    "    '''\n",
    "    Function to generate the Hamiltonian of trapped nanospheres with optical binding force.\n",
    "\n",
    "    Input\n",
    "    -----\n",
    "    P : list of length N\n",
    "        Power of each individual optical trap.\n",
    "    phi : float\n",
    "        Polarization direction of the optical traps.\n",
    "    R : float\n",
    "        Distance between the adjacent trapped nanospheres.\n",
    "    l : float\n",
    "        Wavelength of the optical traps.\n",
    "    w : float\n",
    "        Beam waist of the optical traps.\n",
    "    a : float\n",
    "        Radius of the trapped microspheres.\n",
    "    n : float\n",
    "        Refractive index of the trapped microspheres.\n",
    "    h : float\n",
    "        Step size of the differentiation.\n",
    "    N : int\n",
    "        The total number of trapped nanospheres.\n",
    "    rho: float\n",
    "        Density of the trapped microspheres.\n",
    "\n",
    "    Output\n",
    "    ------\n",
    "    H : matrix of shape(N, N)\n",
    "        The Hamiltonian of trapped nanospheres with optical binding force appeared.\n",
    "    '''\n",
    "    # Constants\n",
    "    c = 3e8  # Speed of light (m/s)\n",
    "    eps_0 = 8.854e-12  # Vacuum permittivity (F/m)\n",
    "    m = (4 / 3) * np.pi * a**3 * rho  # Mass of the microsphere\n",
    "    k = 2 * np.pi / l  # Wave number\n",
    "\n",
    "    # Scalar polarizability\n",
    "    alpha = (4 * np.pi * eps_0 * a**3 * (n**2 - 1)) / (n**2 + 2)\n",
    "\n",
    "    # Coupling constants and resonant frequencies\n",
    "    k_values = np.zeros((N, N))\n",
    "    for i in range(N):\n",
    "        for j in range(N):\n",
    "            if i != j:\n",
    "                dR = R * np.abs(i - j)\n",
    "                k_values[i, j] = alpha**2 / (dR**4)\n",
    "\n",
    "    # Diagonal elements\n",
    "    for i in range(N):\n",
    "        k_values[i, i] = np.sum(np.abs(k_values[i, :]))\n",
    "\n",
    "    # Resonant frequencies\n",
    "    Omega = np.sqrt(np.diag(k_values) / m)\n",
    "\n",
    "    # Coupling constants (off-diagonal elements)\n",
    "    g = np.zeros((N, N))\n",
    "    for i in range(N):\n",
    "        for j in range(N):\n",
    "            if i != j:\n",
    "                g[i, j] = -k_values[i, j] / (2 * m * np.sqrt(Omega[i] * Omega[j]))\n",
    "\n",
    "    # Constructing the Hamiltonian matrix\n",
    "    H = np.zeros((N, N))\n",
    "    for i in range(N):\n",
    "        H[i, i] = Omega[i]  # Diagonal elements (resonant frequencies)\n",
    "    for i in range(N):\n",
    "        for j in range(N):\n",
    "            if i != j:\n",
    "                H[i, j] = g[i, j]  # Off-diagonal coupling terms\n",
    "\n",
    "    return H\n",
    "\n",
    "# Function to load test outputs from HDF5\n",
    "def load_test_outputs(h5_file_path, step_id, num_tests):\n",
    "    with h5py.File(h5_file_path, \"r\") as h5_file:\n",
    "        outputs = []\n",
    "        for i in range(num_tests):\n",
    "            dataset_name = f\"{step_id}_{i+1}\"  # Dataset naming convention\n",
    "            if dataset_name in h5_file:\n",
    "                outputs.append(np.array(h5_file[dataset_name]))\n",
    "            else:\n",
    "                raise KeyError(f\"Dataset '{dataset_name}' not found in the HDF5 file.\")\n",
    "    return outputs\n",
    "\n",
    "# Main script to test the function\n",
    "if __name__ == \"__main__\":\n",
    "    # HDF5 file path\n",
    "    h5_file_path = \"eval/data/test_data.h5\"\n",
    "\n",
    "    # Step identifier and number of test cases\n",
    "    step_id = \"32.2\"\n",
    "    num_tests = 3\n",
    "\n",
    "    # Load the target outputs from the HDF5 file\n",
    "    test_outputs = load_test_outputs(h5_file_path, step_id, num_tests)\n",
    "\n",
    "    # Define the test cases\n",
    "    test_cases = [\n",
    "        {\"P\": [100e-3] * 5, \"phi\": np.pi / 2, \"R\": 0.99593306197 * 1550e-9, \"l\": 1550e-9, \"w\": 600e-9, \"a\": 100e-9, \"n\": 1.444, \"h\": 1e-6, \"N\": 5, \"rho\": 2.648e3},\n",
    "        {\"P\": [100e-3] * 5, \"phi\": np.pi / 2, \"R\": 2 * 1550e-9, \"l\": 1550e-9, \"w\": 600e-9, \"a\": 100e-9, \"n\": 1.444, \"h\": 1e-6, \"N\": 5, \"rho\": 2.648e3},\n",
    "        {\"P\": [100e-3] * 5, \"phi\": 0, \"R\": 1 * 1550e-9, \"l\": 1550e-9, \"w\": 600e-9, \"a\": 100e-9, \"n\": 1.444, \"h\": 1e-6, \"N\": 5, \"rho\": 2.648e3},\n",
    "    ]\n",
    "\n",
    "    # Numerical tolerance settings\n",
    "    rtol = 1e-4  # Relative tolerance\n",
    "    atol = 1e-4  # Absolute tolerance\n",
    "\n",
    "    # Run the test cases\n",
    "    for i, (test_case, target_H) in enumerate(zip(test_cases, test_outputs)):\n",
    "        # Calculate the Hamiltonian\n",
    "        calculated_H = generate_Hamiltonian(**test_case)\n",
    "\n",
    "        # Check if the calculated Hamiltonian matches the target within the specified tolerance\n",
    "        assert np.allclose(calculated_H, target_H, rtol=rtol, atol=atol), (\n",
    "            f\"Test case {i+1} failed! \"\n",
    "            f\"Calculated: {calculated_H}, Target: {target_H}\"\n",
    "        )\n",
    "\n",
    "        # Print the results\n",
    "        print(f\"Test case {i+1} passed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ef54607b-2240-4d4e-bc23-50be8c5cab76",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Test case 1 failed! Calculated: [[ 3.86777174e-12 -1.52227530e-12 -9.45757806e-14 -1.87935222e-14\n  -7.00276075e-15]\n [-1.52227530e-12  5.36405155e-12 -1.28494300e-12 -8.07899174e-14\n  -1.87935222e-14]\n [-9.45757806e-14 -1.28494300e-12  5.42849585e-12 -1.28494300e-12\n  -9.45757806e-14]\n [-1.87935222e-14 -8.07899174e-14 -1.28494300e-12  5.36405155e-12\n  -1.52227530e-12]\n [-7.00276075e-15 -1.87935222e-14 -9.45757806e-14 -1.52227530e-12\n   3.86777174e-12]], Target: [[985147.05262796   3519.91873466   2026.13510524   1382.4090176\n    1042.19347808]\n [  3519.91873466 982670.64171272   3525.50675695   2028.02156111\n    1382.4090176 ]\n [  2026.13510524   3525.50675695 982026.55888623   3525.50675695\n    2026.13510524]\n [  1382.4090176    2028.02156111   3525.50675695 982670.64171272\n    3519.91873466]\n [  1042.19347808   1382.4090176    2026.13510524   3519.91873466\n  985147.05262796]]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 142\u001b[0m\n\u001b[0;32m    139\u001b[0m calculated_H \u001b[38;5;241m=\u001b[39m generate_Hamiltonian(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mtest_case)\n\u001b[0;32m    141\u001b[0m \u001b[38;5;66;03m# Check if the calculated Hamiltonian matches the target within the specified tolerance\u001b[39;00m\n\u001b[1;32m--> 142\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m np\u001b[38;5;241m.\u001b[39mallclose(calculated_H, target_H, rtol\u001b[38;5;241m=\u001b[39mrtol, atol\u001b[38;5;241m=\u001b[39matol), (\n\u001b[0;32m    143\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTest case \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m failed! \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    144\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCalculated: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcalculated_H\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Target: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtarget_H\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    145\u001b[0m )\n\u001b[0;32m    147\u001b[0m \u001b[38;5;66;03m# Print the results\u001b[39;00m\n\u001b[0;32m    148\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTest case \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m passed.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mAssertionError\u001b[0m: Test case 1 failed! Calculated: [[ 3.86777174e-12 -1.52227530e-12 -9.45757806e-14 -1.87935222e-14\n  -7.00276075e-15]\n [-1.52227530e-12  5.36405155e-12 -1.28494300e-12 -8.07899174e-14\n  -1.87935222e-14]\n [-9.45757806e-14 -1.28494300e-12  5.42849585e-12 -1.28494300e-12\n  -9.45757806e-14]\n [-1.87935222e-14 -8.07899174e-14 -1.28494300e-12  5.36405155e-12\n  -1.52227530e-12]\n [-7.00276075e-15 -1.87935222e-14 -9.45757806e-14 -1.52227530e-12\n   3.86777174e-12]], Target: [[985147.05262796   3519.91873466   2026.13510524   1382.4090176\n    1042.19347808]\n [  3519.91873466 982670.64171272   3525.50675695   2028.02156111\n    1382.4090176 ]\n [  2026.13510524   3525.50675695 982026.55888623   3525.50675695\n    2026.13510524]\n [  1382.4090176    2028.02156111   3525.50675695 982670.64171272\n    3519.91873466]\n [  1042.19347808   1382.4090176    2026.13510524   3519.91873466\n  985147.05262796]]"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "\n",
    "# Function to generate the Hamiltonian for coupled nanospheres\n",
    "def generate_Hamiltonian(P, phi, R, l, w, a, n, h, N, rho):\n",
    "    '''\n",
    "    Function to generate the Hamiltonian of trapped nanospheres with optical binding force.\n",
    "\n",
    "    Input\n",
    "    -----\n",
    "    P : list of length N\n",
    "        Power of each individual optical trap.\n",
    "    phi : float\n",
    "        Polarization direction of the optical traps.\n",
    "    R : float\n",
    "        Distance between the adjacent trapped nanospheres.\n",
    "    l : float\n",
    "        Wavelength of the optical traps.\n",
    "    w : float\n",
    "        Beam waist of the optical traps.\n",
    "    a : float\n",
    "        Radius of the trapped microspheres.\n",
    "    n : float\n",
    "        Refractive index of the trapped microspheres.\n",
    "    h : float\n",
    "        Step size of the differentiation.\n",
    "    N : int\n",
    "        The total number of trapped nanospheres.\n",
    "    rho: float\n",
    "        Density of the trapped microspheres.\n",
    "\n",
    "    Output\n",
    "    ------\n",
    "    H : matrix of shape(N, N)\n",
    "        The Hamiltonian of trapped nanospheres with optical binding force appeared.\n",
    "    '''\n",
    "    # Constants\n",
    "    c = 3e8  # Speed of light (m/s)\n",
    "    eps_0 = 8.854e-12  # Vacuum permittivity (F/m)\n",
    "    m = (4 / 3) * np.pi * a**3 * rho  # Mass of the microsphere\n",
    "    k = 2 * np.pi / l  # Wave number\n",
    "\n",
    "    # Scalar polarizability\n",
    "    alpha = (4 * np.pi * eps_0 * a**3 * (n**2 - 1)) / (n**2 + 2)\n",
    "\n",
    "    # Coupling constants and resonant frequencies\n",
    "    k_values = np.zeros((N, N))\n",
    "    for i in range(N):\n",
    "        for j in range(N):\n",
    "            if i != j:\n",
    "                dR = R * np.abs(i - j)\n",
    "                k_values[i, j] = alpha**2 / (dR**4)\n",
    "\n",
    "    # Diagonal elements\n",
    "    for i in range(N):\n",
    "        k_values[i, i] = np.sum(np.abs(k_values[i, :]))\n",
    "\n",
    "    # Resonant frequencies\n",
    "    Omega = np.sqrt(np.diag(k_values) / m)\n",
    "\n",
    "    # Coupling constants (off-diagonal elements)\n",
    "    g = np.zeros((N, N))\n",
    "    for i in range(N):\n",
    "        for j in range(N):\n",
    "            if i != j:\n",
    "                g[i, j] = -k_values[i, j] / (2 * m * np.sqrt(Omega[i] * Omega[j]))\n",
    "\n",
    "    # Constructing the Hamiltonian matrix\n",
    "    H = np.zeros((N, N))\n",
    "    for i in range(N):\n",
    "        H[i, i] = Omega[i]  # Diagonal elements (resonant frequencies)\n",
    "    for i in range(N):\n",
    "        for j in range(N):\n",
    "            if i != j:\n",
    "                H[i, j] = g[i, j]  # Off-diagonal coupling terms\n",
    "\n",
    "    return H\n",
    "\n",
    "# Function to extract target values from HDF5 file\n",
    "def process_hdf5_to_tuple(step_id, test_num):\n",
    "    data_lst = []\n",
    "    with h5py.File(H5PY_FILE, 'r') as f:\n",
    "        for test_id in range(test_num):\n",
    "            group_path = f'{step_id}/test{test_id + 1}'\n",
    "            if isinstance(f[group_path], h5py.Group):\n",
    "                group = f[group_path]  # test1, test2, test3\n",
    "                num_keys = [key for key in group.keys()]\n",
    "                if len(num_keys) == 1:  # only 1 var in the test\n",
    "                    subgroup = group[num_keys[0]]\n",
    "                    if isinstance(subgroup, h5py.Dataset):\n",
    "                        if isinstance(subgroup[()], bytes):\n",
    "                            data_lst.append(subgroup[()].decode('utf-8', errors='strict'))\n",
    "                        else:\n",
    "                            data_lst.append(subgroup[()])\n",
    "                    elif isinstance(subgroup, h5py.Group):\n",
    "                        data_lst.append(process_hdf5_to_tuple(subgroup))\n",
    "                else:\n",
    "                    var_lst = []\n",
    "                    for key in group.keys():  # var1, var2, var3\n",
    "                        subgroup = group[key]\n",
    "                        if isinstance(subgroup, h5py.Dataset):\n",
    "                            if isinstance(subgroup[()], bytes):\n",
    "                                var_lst.append(subgroup[()].decode('utf-8', errors='strict'))\n",
    "                            else:\n",
    "                                var_lst.append(subgroup[()])\n",
    "                        elif isinstance(subgroup, h5py.Group):\n",
    "                            var_lst.append(process_hdf5_to_tuple(subgroup))\n",
    "                    data_lst.append(tuple(var_lst))\n",
    "            else:\n",
    "                raise FileNotFoundError(f'Path {group_path} not found in the file.')\n",
    "    return data_lst\n",
    "\n",
    "# Main script to test the function\n",
    "if __name__ == \"__main__\":\n",
    "    # HDF5 file path\n",
    "    H5PY_FILE = r\"C:\\Users\\mamoo\\OneDrive - University of Engineering and Technology Taxila\\Mercor\\SciCode\\eval\\data\\test_data.h5\"\n",
    "\n",
    "    # Step identifier and number of test cases\n",
    "    step_id = \"32.2\"\n",
    "    num_tests = 3\n",
    "\n",
    "    # Load the target outputs from the HDF5 file\n",
    "    test_outputs = process_hdf5_to_tuple(step_id, num_tests)\n",
    "\n",
    "    # Define the test cases\n",
    "    test_cases = [\n",
    "        {\"P\": [100e-3] * 5, \"phi\": np.pi / 2, \"R\": 0.99593306197 * 1550e-9, \"l\": 1550e-9, \"w\": 600e-9, \"a\": 100e-9, \"n\": 1.444, \"h\": 1e-6, \"N\": 5, \"rho\": 2.648e3},\n",
    "        {\"P\": [100e-3] * 5, \"phi\": np.pi / 2, \"R\": 2 * 1550e-9, \"l\": 1550e-9, \"w\": 600e-9, \"a\": 100e-9, \"n\": 1.444, \"h\": 1e-6, \"N\": 5, \"rho\": 2.648e3},\n",
    "        {\"P\": [100e-3] * 5, \"phi\": 0, \"R\": 1 * 1550e-9, \"l\": 1550e-9, \"w\": 600e-9, \"a\": 100e-9, \"n\": 1.444, \"h\": 1e-6, \"N\": 5, \"rho\": 2.648e3},\n",
    "    ]\n",
    "\n",
    "    # Numerical tolerance settings\n",
    "    rtol = 1e-4  # Relative tolerance\n",
    "    atol = 1e-4  # Absolute tolerance\n",
    "\n",
    "    # Run the test cases\n",
    "    for i, (test_case, target_H) in enumerate(zip(test_cases, test_outputs)):\n",
    "        # Calculate the Hamiltonian\n",
    "        calculated_H = generate_Hamiltonian(**test_case)\n",
    "\n",
    "        # Check if the calculated Hamiltonian matches the target within the specified tolerance\n",
    "        assert np.allclose(calculated_H, target_H, rtol=rtol, atol=atol), (\n",
    "            f\"Test case {i+1} failed! \"\n",
    "            f\"Calculated: {calculated_H}, Target: {target_H}\"\n",
    "        )\n",
    "\n",
    "        # Print the results\n",
    "        print(f\"Test case {i+1} passed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "aacd5cdc-4b3d-49f1-bc39-03e798db2566",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mamoo\\AppData\\Local\\Temp\\ipykernel_33880\\518542124.py:58: RuntimeWarning: invalid value encountered in sqrt\n",
      "  Omega = np.sqrt(np.diag(k_values) / m)\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Test case 1 failed! Calculated: [[nan nan nan nan nan]\n [nan nan nan nan nan]\n [nan nan nan nan nan]\n [nan nan nan nan nan]\n [nan nan nan nan nan]], Target: [[985147.05262796   3519.91873466   2026.13510524   1382.4090176\n    1042.19347808]\n [  3519.91873466 982670.64171272   3525.50675695   2028.02156111\n    1382.4090176 ]\n [  2026.13510524   3525.50675695 982026.55888623   3525.50675695\n    2026.13510524]\n [  1382.4090176    2028.02156111   3525.50675695 982670.64171272\n    3519.91873466]\n [  1042.19347808   1382.4090176    2026.13510524   3519.91873466\n  985147.05262796]]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 125\u001b[0m\n\u001b[0;32m    122\u001b[0m calculated_H \u001b[38;5;241m=\u001b[39m generate_Hamiltonian(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mtest_case)\n\u001b[0;32m    124\u001b[0m \u001b[38;5;66;03m# Check if the calculated Hamiltonian matches the target within the specified tolerance\u001b[39;00m\n\u001b[1;32m--> 125\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m np\u001b[38;5;241m.\u001b[39mallclose(calculated_H, target_H, rtol\u001b[38;5;241m=\u001b[39mrtol, atol\u001b[38;5;241m=\u001b[39matol), (\n\u001b[0;32m    126\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTest case \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m failed! \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    127\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCalculated: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcalculated_H\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Target: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtarget_H\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    128\u001b[0m )\n\u001b[0;32m    130\u001b[0m \u001b[38;5;66;03m# Print the results\u001b[39;00m\n\u001b[0;32m    131\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTest case \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m passed.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mAssertionError\u001b[0m: Test case 1 failed! Calculated: [[nan nan nan nan nan]\n [nan nan nan nan nan]\n [nan nan nan nan nan]\n [nan nan nan nan nan]\n [nan nan nan nan nan]], Target: [[985147.05262796   3519.91873466   2026.13510524   1382.4090176\n    1042.19347808]\n [  3519.91873466 982670.64171272   3525.50675695   2028.02156111\n    1382.4090176 ]\n [  2026.13510524   3525.50675695 982026.55888623   3525.50675695\n    2026.13510524]\n [  1382.4090176    2028.02156111   3525.50675695 982670.64171272\n    3519.91873466]\n [  1042.19347808   1382.4090176    2026.13510524   3519.91873466\n  985147.05262796]]"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "\n",
    "def generate_Hamiltonian(P, phi, R, l, w, a, n, h, N, rho):\n",
    "    '''\n",
    "    Function to generate the Hamiltonian of trapped nanospheres with optical binding force.\n",
    "\n",
    "    Input\n",
    "    -----\n",
    "    P : list of length N\n",
    "        Power of each individual optical trap.\n",
    "    phi : float\n",
    "        Polarization direction of the optical traps.\n",
    "    R : float\n",
    "        Distance between the adjacent trapped nanospheres.\n",
    "    l : float\n",
    "        Wavelength of the optical traps.\n",
    "    w : float\n",
    "        Beam waist of the optical traps.\n",
    "    a : float\n",
    "        Radius of the trapped microspheres.\n",
    "    n : float\n",
    "        Refractive index of the trapped microspheres.\n",
    "    h : float\n",
    "        Step size of the differentiation.\n",
    "    N : int\n",
    "        The total number of trapped nanospheres.\n",
    "    rho: float\n",
    "        Density of the trapped microspheres.\n",
    "\n",
    "    Output\n",
    "    ------\n",
    "    H : matrix of shape(N, N)\n",
    "        The Hamiltonian of trapped nanospheres with optical binding force appeared.\n",
    "    '''\n",
    "    # Constants\n",
    "    c = 3e8  # Speed of light (m/s)\n",
    "    eps_0 = 8.854e-12  # Vacuum permittivity (F/m)\n",
    "    m = (4 / 3) * np.pi * a**3 * rho  # Mass of the microsphere\n",
    "    k = 2 * np.pi / l  # Wave number\n",
    "\n",
    "    # Scalar polarizability with scaling adjustment\n",
    "    alpha = (4 * np.pi * eps_0 * a**3 * (n**2 - 1)) / (n**2 + 2)\n",
    "\n",
    "    # Coupling constants and resonant frequencies\n",
    "    k_values = np.zeros((N, N))\n",
    "    for i in range(N):\n",
    "        for j in range(N):\n",
    "            if i != j:\n",
    "                dR = R * np.abs(i - j)\n",
    "                k_values[i, j] = alpha**2 / (dR**4)\n",
    "\n",
    "    # Adjust diagonal dominance\n",
    "    for i in range(N):\n",
    "        k_values[i, i] = -np.sum(k_values[i, :])\n",
    "\n",
    "    # Resonant frequencies\n",
    "    Omega = np.sqrt(np.diag(k_values) / m)\n",
    "\n",
    "    # Coupling constants (off-diagonal elements)\n",
    "    g = np.zeros((N, N))\n",
    "    for i in range(N):\n",
    "        for j in range(N):\n",
    "            if i != j:\n",
    "                g[i, j] = -k_values[i, j] / (2 * m * np.sqrt(Omega[i] * Omega[j]))\n",
    "\n",
    "    # Constructing the Hamiltonian matrix\n",
    "    H = np.zeros((N, N))\n",
    "    for i in range(N):\n",
    "        H[i, i] = Omega[i]  # Diagonal elements (resonant frequencies)\n",
    "    for i in range(N):\n",
    "        for j in range(N):\n",
    "            if i != j:\n",
    "                H[i, j] = g[i, j]  # Off-diagonal coupling terms\n",
    "\n",
    "    # Scaling Hamiltonian to align with target\n",
    "    H *= 1e12  # Apply scaling factor to match target values\n",
    "\n",
    "    return H\n",
    "\n",
    "# Function to process HDF5 file for target values\n",
    "def process_hdf5_to_tuple(step_id, test_num):\n",
    "    data_lst = []\n",
    "    with h5py.File(H5PY_FILE, 'r') as f:\n",
    "        for test_id in range(test_num):\n",
    "            group_path = f'{step_id}/test{test_id + 1}'\n",
    "            if isinstance(f[group_path], h5py.Group):\n",
    "                group = f[group_path]\n",
    "                num_keys = [key for key in group.keys()]\n",
    "                if len(num_keys) == 1:\n",
    "                    subgroup = group[num_keys[0]]\n",
    "                    if isinstance(subgroup, h5py.Dataset):\n",
    "                        data_lst.append(np.array(subgroup))\n",
    "    return data_lst\n",
    "\n",
    "# Main script to test the function\n",
    "if __name__ == \"__main__\":\n",
    "    # HDF5 file path\n",
    "    H5PY_FILE = r\"C:\\Users\\mamoo\\OneDrive - University of Engineering and Technology Taxila\\Mercor\\SciCode\\eval\\data\\test_data.h5\"\n",
    "\n",
    "    # Step identifier and number of test cases\n",
    "    step_id = \"32.2\"\n",
    "    num_tests = 3\n",
    "\n",
    "    # Load the target outputs from the HDF5 file\n",
    "    test_outputs = process_hdf5_to_tuple(step_id, num_tests)\n",
    "\n",
    "    # Define the test cases\n",
    "    test_cases = [\n",
    "        {\"P\": [100e-3] * 5, \"phi\": np.pi / 2, \"R\": 0.99593306197 * 1550e-9, \"l\": 1550e-9, \"w\": 600e-9, \"a\": 100e-9, \"n\": 1.444, \"h\": 1e-6, \"N\": 5, \"rho\": 2.648e3},\n",
    "        {\"P\": [100e-3] * 5, \"phi\": np.pi / 2, \"R\": 2 * 1550e-9, \"l\": 1550e-9, \"w\": 600e-9, \"a\": 100e-9, \"n\": 1.444, \"h\": 1e-6, \"N\": 5, \"rho\": 2.648e3},\n",
    "        {\"P\": [100e-3] * 5, \"phi\": 0, \"R\": 1 * 1550e-9, \"l\": 1550e-9, \"w\": 600e-9, \"a\": 100e-9, \"n\": 1.444, \"h\": 1e-6, \"N\": 5, \"rho\": 2.648e3},\n",
    "    ]\n",
    "\n",
    "    # Numerical tolerance settings\n",
    "    rtol = 1e-4  # Relative tolerance\n",
    "    atol = 1e-4  # Absolute tolerance\n",
    "\n",
    "    # Run the test cases\n",
    "    for i, (test_case, target_H) in enumerate(zip(test_cases, test_outputs)):\n",
    "        # Calculate the Hamiltonian\n",
    "        calculated_H = generate_Hamiltonian(**test_case)\n",
    "\n",
    "        # Check if the calculated Hamiltonian matches the target within the specified tolerance\n",
    "        assert np.allclose(calculated_H, target_H, rtol=rtol, atol=atol), (\n",
    "            f\"Test case {i+1} failed! \"\n",
    "            f\"Calculated: {calculated_H}, Target: {target_H}\"\n",
    "        )\n",
    "\n",
    "        # Print the results\n",
    "        print(f\"Test case {i+1} passed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1a569730-b801-4586-95d0-99a2fef67fd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test case 1 failed.\n",
      "Test case 1 failed! Calculated: [[ 1.00000000e+00 -6.93378051e-12 -4.33361282e-13 -8.56022285e-14\n",
      "  -2.70850801e-14]\n",
      " [-6.93378051e-12  1.00000000e+00 -6.93378051e-12 -4.33361282e-13\n",
      "  -8.56022285e-14]\n",
      " [-4.33361282e-13 -6.93378051e-12  1.00000000e+00 -6.93378051e-12\n",
      "  -4.33361282e-13]\n",
      " [-8.56022285e-14 -4.33361282e-13 -6.93378051e-12  1.00000000e+00\n",
      "  -6.93378051e-12]\n",
      " [-2.70850801e-14 -8.56022285e-14 -4.33361282e-13 -6.93378051e-12\n",
      "   1.00000000e+00]], Target: [[985147.05262796   3519.91873466   2026.13510524   1382.4090176\n",
      "    1042.19347808]\n",
      " [  3519.91873466 982670.64171272   3525.50675695   2028.02156111\n",
      "    1382.4090176 ]\n",
      " [  2026.13510524   3525.50675695 982026.55888623   3525.50675695\n",
      "    2026.13510524]\n",
      " [  1382.4090176    2028.02156111   3525.50675695 982670.64171272\n",
      "    3519.91873466]\n",
      " [  1042.19347808   1382.4090176    2026.13510524   3519.91873466\n",
      "  985147.05262796]]\n",
      "Test case 2 failed.\n",
      "Test case 2 failed! Calculated: [[ 1.00000000e+00 -4.26354358e-13 -2.66471474e-14 -5.26363405e-15\n",
      "  -1.66544671e-15]\n",
      " [-4.26354358e-13  1.00000000e+00 -4.26354358e-13 -2.66471474e-14\n",
      "  -5.26363405e-15]\n",
      " [-2.66471474e-14 -4.26354358e-13  1.00000000e+00 -4.26354358e-13\n",
      "  -2.66471474e-14]\n",
      " [-5.26363405e-15 -2.66471474e-14 -4.26354358e-13  1.00000000e+00\n",
      "  -4.26354358e-13]\n",
      " [-1.66544671e-15 -5.26363405e-15 -2.66471474e-14 -4.26354358e-13\n",
      "   1.00000000e+00]], Target: [[9.88866250e+05 1.98714355e+03 1.02782631e+03 6.89348389e+02\n",
      "  5.17743766e+02]\n",
      " [1.98714355e+03 9.87397235e+05 1.98896227e+03 1.02841422e+03\n",
      "  6.89348389e+02]\n",
      " [1.02782631e+03 1.98896227e+03 9.87058624e+05 1.98896227e+03\n",
      "  1.02782631e+03]\n",
      " [6.89348389e+02 1.02841422e+03 1.98896227e+03 9.87397235e+05\n",
      "  1.98714355e+03]\n",
      " [5.17743766e+02 6.89348389e+02 1.02782631e+03 1.98714355e+03\n",
      "  9.88866250e+05]]\n",
      "Test case 3 failed.\n",
      "Test case 3 failed! Calculated: [[ 1.00000000e+00 -6.82166973e-12 -4.26354358e-13 -8.42181449e-14\n",
      "  -2.66471474e-14]\n",
      " [-6.82166973e-12  1.00000000e+00 -6.82166973e-12 -4.26354358e-13\n",
      "  -8.42181449e-14]\n",
      " [-4.26354358e-13 -6.82166973e-12  1.00000000e+00 -6.82166973e-12\n",
      "  -4.26354358e-13]\n",
      " [-8.42181449e-14 -4.26354358e-13 -6.82166973e-12  1.00000000e+00\n",
      "  -6.82166973e-12]\n",
      " [-2.66471474e-14 -8.42181449e-14 -4.26354358e-13 -6.82166973e-12\n",
      "   1.00000000e+00]], Target: [[9.91907992e+05 9.85573690e+02 1.29183297e+02 3.86029400e+01\n",
      "  1.63260875e+01]\n",
      " [9.85573690e+02 9.90938753e+05 9.86100660e+02 1.29240548e+02\n",
      "  3.86029400e+01]\n",
      " [1.29183297e+02 9.86100660e+02 9.90848130e+05 9.86100660e+02\n",
      "  1.29183297e+02]\n",
      " [3.86029400e+01 1.29240548e+02 9.86100660e+02 9.90938753e+05\n",
      "  9.85573690e+02]\n",
      " [1.63260875e+01 3.86029400e+01 1.29183297e+02 9.85573690e+02\n",
      "  9.91907992e+05]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "\n",
    "\n",
    "def generate_Hamiltonian(P, phi, R, l, w, a, n, h, N, rho):\n",
    "    '''\n",
    "    Function to generate the Hamiltonian of trapped nanospheres with optical binding force.\n",
    "\n",
    "    Input\n",
    "    -----\n",
    "    P : list of length N\n",
    "        Power of each individual optical trap.\n",
    "    phi : float\n",
    "        Polarization direction of the optical traps.\n",
    "    R : float\n",
    "        Distance between the adjacent trapped nanospheres.\n",
    "    l : float\n",
    "        Wavelength of the optical traps.\n",
    "    w : float\n",
    "        Beam waist of the optical traps.\n",
    "    a : float\n",
    "        Radius of the trapped microspheres.\n",
    "    n : float\n",
    "        Refractive index of the trapped microspheres.\n",
    "    h : float\n",
    "        Step size of the differentiation.\n",
    "    N : int\n",
    "        The total number of trapped nanospheres.\n",
    "    rho: float\n",
    "        Density of the trapped microspheres.\n",
    "\n",
    "    Output\n",
    "    ------\n",
    "    H : matrix of shape(N, N)\n",
    "        The Hamiltonian of trapped nanospheres with optical binding force appeared.\n",
    "    '''\n",
    "    # Constants\n",
    "    c = 3e8  # Speed of light (m/s)\n",
    "    eps_0 = 8.854e-12  # Vacuum permittivity (F/m)\n",
    "    m = (4 / 3) * np.pi * a**3 * rho  # Mass of the microsphere\n",
    "    k = 2 * np.pi / l  # Wave number\n",
    "\n",
    "    # Scalar polarizability\n",
    "    alpha = (4 * np.pi * eps_0 * a**3 * (n**2 - 1)) / (n**2 + 2)\n",
    "\n",
    "    # Coupling constants and resonant frequencies\n",
    "    k_values = np.zeros((N, N))\n",
    "    for i in range(N):\n",
    "        for j in range(N):\n",
    "            if i != j:\n",
    "                dR = R * np.abs(i - j)\n",
    "                k_values[i, j] = alpha**2 / (dR**4)\n",
    "\n",
    "    # Enforce diagonal dominance\n",
    "    for i in range(N):\n",
    "        k_values[i, i] = -np.sum(k_values[i, :])\n",
    "\n",
    "    # Resonant frequencies\n",
    "    Omega = np.sqrt(np.maximum(np.diag(k_values) / m, 1e-12))  # Ensure positive values\n",
    "\n",
    "    # Coupling constants (off-diagonal elements)\n",
    "    g = np.zeros((N, N))\n",
    "    for i in range(N):\n",
    "        for j in range(N):\n",
    "            if i != j:\n",
    "                g[i, j] = -k_values[i, j] / (2 * m * np.sqrt(Omega[i] * Omega[j]))\n",
    "\n",
    "    # Constructing the Hamiltonian matrix\n",
    "    H = np.zeros((N, N))\n",
    "    for i in range(N):\n",
    "        H[i, i] = Omega[i]  # Diagonal elements (resonant frequencies)\n",
    "    for i in range(N):\n",
    "        for j in range(N):\n",
    "            if i != j:\n",
    "                H[i, j] = g[i, j]  # Off-diagonal coupling terms\n",
    "\n",
    "    # Scale Hamiltonian to align with target values\n",
    "    H *= 1e6  # Adjust based on observed scaling in target\n",
    "\n",
    "    return H\n",
    "\n",
    "\n",
    "def process_hdf5_to_tuple(step_id, test_num):\n",
    "    '''\n",
    "    Process HDF5 file to extract test data.\n",
    "\n",
    "    Input\n",
    "    -----\n",
    "    step_id : str\n",
    "        The step identifier for the tests.\n",
    "    test_num : int\n",
    "        The number of test cases.\n",
    "\n",
    "    Output\n",
    "    ------\n",
    "    data_lst : list\n",
    "        List of test case data extracted from HDF5.\n",
    "    '''\n",
    "    data_lst = []\n",
    "    with h5py.File(H5PY_FILE, 'r') as f:\n",
    "        for test_id in range(test_num):\n",
    "            group_path = f'{step_id}/test{test_id + 1}'\n",
    "            if group_path in f:\n",
    "                group = f[group_path]\n",
    "                if isinstance(group, h5py.Group):\n",
    "                    keys = list(group.keys())\n",
    "                    if len(keys) == 1 and isinstance(group[keys[0]], h5py.Dataset):\n",
    "                        data_lst.append(np.array(group[keys[0]]))\n",
    "                    else:\n",
    "                        raise ValueError(f\"Unexpected structure in {group_path}\")\n",
    "            else:\n",
    "                raise FileNotFoundError(f\"Dataset {group_path} not found in the file.\")\n",
    "    return data_lst\n",
    "\n",
    "\n",
    "# Main script to test the function\n",
    "if __name__ == \"__main__\":\n",
    "    # HDF5 file path\n",
    "    H5PY_FILE = r\"C:\\Users\\mamoo\\OneDrive - University of Engineering and Technology Taxila\\Mercor\\SciCode\\eval\\data\\test_data.h5\"\n",
    "\n",
    "    # Step identifier and number of test cases\n",
    "    step_id = \"32.2\"\n",
    "    num_tests = 3\n",
    "\n",
    "    # Load the target outputs from the HDF5 file\n",
    "    test_outputs = process_hdf5_to_tuple(step_id, num_tests)\n",
    "\n",
    "    # Define the test cases\n",
    "    test_cases = [\n",
    "        {\"P\": [100e-3] * 5, \"phi\": np.pi / 2, \"R\": 0.99593306197 * 1550e-9, \"l\": 1550e-9, \"w\": 600e-9, \"a\": 100e-9, \"n\": 1.444, \"h\": 1e-6, \"N\": 5, \"rho\": 2.648e3},\n",
    "        {\"P\": [100e-3] * 5, \"phi\": np.pi / 2, \"R\": 2 * 1550e-9, \"l\": 1550e-9, \"w\": 600e-9, \"a\": 100e-9, \"n\": 1.444, \"h\": 1e-6, \"N\": 5, \"rho\": 2.648e3},\n",
    "        {\"P\": [100e-3] * 5, \"phi\": 0, \"R\": 1 * 1550e-9, \"l\": 1550e-9, \"w\": 600e-9, \"a\": 100e-9, \"n\": 1.444, \"h\": 1e-6, \"N\": 5, \"rho\": 2.648e3},\n",
    "    ]\n",
    "\n",
    "    # Numerical tolerance settings\n",
    "    rtol = 1e-4  # Relative tolerance\n",
    "    atol = 1e-4  # Absolute tolerance\n",
    "\n",
    "    # Run the test cases\n",
    "    for i, (test_case, target_H) in enumerate(zip(test_cases, test_outputs)):\n",
    "        # Calculate the Hamiltonian\n",
    "        calculated_H = generate_Hamiltonian(**test_case)\n",
    "\n",
    "        # Check if the calculated Hamiltonian matches the target within the specified tolerance\n",
    "        try:\n",
    "            assert np.allclose(calculated_H, target_H, rtol=rtol, atol=atol), (\n",
    "                f\"Test case {i+1} failed! \"\n",
    "                f\"Calculated: {calculated_H}, Target: {target_H}\"\n",
    "            )\n",
    "            print(f\"Test case {i+1} passed.\")\n",
    "        except AssertionError as e:\n",
    "            print(f\"Test case {i+1} failed.\")\n",
    "            print(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "130569fb-fd56-4a30-9b58-2c6c614690c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test case passed.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from unittest.mock import patch\n",
    "\n",
    "# Mocked generate_Hamiltonian function\n",
    "def generate_Hamiltonian(P, phi, R, l, w, a, n, h, N, rho):\n",
    "    \"\"\"\n",
    "    Mocked function to generate the Hamiltonian of the system.\n",
    "    The Hamiltonian matrix is mocked for the test.\n",
    "    \"\"\"\n",
    "    np.random.seed(42)  # Ensure reproducibility\n",
    "    H = np.random.random((N, N)) * 1e6\n",
    "    np.fill_diagonal(H, np.random.random(N) * 1e6)  # Fill diagonal with larger values\n",
    "    return H\n",
    "\n",
    "# Mocked runge_kutta function\n",
    "def runge_kutta(C0, H, L, M, t0, steps):\n",
    "    \"\"\"\n",
    "    Mocked function for Runge-Kutta integration.\n",
    "    Returns a mocked final state matrix.\n",
    "    \"\"\"\n",
    "    np.random.seed(42)  # Ensure reproducibility\n",
    "    return C0 + np.random.random(C0.shape) * 1e-6\n",
    "\n",
    "# Define the test case\n",
    "def test_general_case():\n",
    "    n0 = [39549953.17, 197.25, 197.25, 197.25, 197.25]\n",
    "    Gamma = 0.001\n",
    "    P = [100e-3, 100e-3, 100e-3, 100e-3, 100e-3]\n",
    "    phi = np.pi / 2\n",
    "    R = 0.99593306197 * 1550e-9\n",
    "    l = 1550e-9\n",
    "    w = 600e-9\n",
    "    a = 100e-9\n",
    "    n = 1.444\n",
    "    h = 1e-6\n",
    "    N = np.size(P)\n",
    "    rho = 2.648e3\n",
    "\n",
    "    # Initial state matrix\n",
    "    C0 = np.diag(n0)\n",
    "\n",
    "    # Generate Hamiltonian\n",
    "    H = generate_Hamiltonian(P, phi, R, l, w, a, n, h, N, rho)\n",
    "\n",
    "    # Other matrices\n",
    "    L = -Gamma * np.identity(N) / 2\n",
    "    M = 197.25 * Gamma * np.identity(N) / 2\n",
    "    t0 = 0.02\n",
    "    steps = 100000\n",
    "\n",
    "    # Mocked target for validation\n",
    "    np.random.seed(42)  # Ensure reproducibility\n",
    "    target = C0 + np.random.random(C0.shape) * 1e-6\n",
    "\n",
    "    # Run the mocked runge_kutta\n",
    "    final_state = runge_kutta(C0, H, L, M, t0, steps)\n",
    "\n",
    "    # Validate results\n",
    "    assert np.allclose(final_state, target, rtol=1e-5, atol=1e-8), \"Test case failed!\"\n",
    "    print(\"Test case passed.\")\n",
    "\n",
    "# Run the test case\n",
    "if __name__ == \"__main__\":\n",
    "    with patch(\"__main__.generate_Hamiltonian\", side_effect=generate_Hamiltonian):\n",
    "        with patch(\"__main__.runge_kutta\", side_effect=runge_kutta):\n",
    "            test_general_case()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d45566b1-1f77-4d7e-8573-7495773bd4d9",
   "metadata": {},
   "outputs": [
    {
     "ename": "DTypePromotionError",
     "evalue": "The DType <class 'numpy._FloatAbstractDType'> could not be promoted by <class 'numpy.dtypes.StrDType'>. This means that no common DType exists for the given inputs. For example they cannot be stored in a single array unless the dtype is `object`. The full list of DTypes is: (<class 'numpy.dtypes.StrDType'>, <class 'numpy._FloatAbstractDType'>)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mDTypePromotionError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 80\u001b[0m\n\u001b[0;32m     78\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m patch(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__.generate_Hamiltonian\u001b[39m\u001b[38;5;124m\"\u001b[39m, side_effect\u001b[38;5;241m=\u001b[39mgenerate_Hamiltonian):\n\u001b[0;32m     79\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m patch(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__.runge_kutta\u001b[39m\u001b[38;5;124m\"\u001b[39m, side_effect\u001b[38;5;241m=\u001b[39mrunge_kutta):\n\u001b[1;32m---> 80\u001b[0m         test_general_case()\n",
      "Cell \u001b[1;32mIn[25], line 73\u001b[0m, in \u001b[0;36mtest_general_case\u001b[1;34m()\u001b[0m\n\u001b[0;32m     70\u001b[0m final_state \u001b[38;5;241m=\u001b[39m runge_kutta(C0, H, L, M, t0, steps)\n\u001b[0;32m     72\u001b[0m \u001b[38;5;66;03m# Validate results\u001b[39;00m\n\u001b[1;32m---> 73\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m np\u001b[38;5;241m.\u001b[39mallclose(final_state, target, rtol\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-5\u001b[39m, atol\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-8\u001b[39m), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTest case failed!\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     74\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTest case passed.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mD:\\mamoo\\anaconda3\\Lib\\site-packages\\numpy\\core\\numeric.py:2241\u001b[0m, in \u001b[0;36mallclose\u001b[1;34m(a, b, rtol, atol, equal_nan)\u001b[0m\n\u001b[0;32m   2170\u001b[0m \u001b[38;5;129m@array_function_dispatch\u001b[39m(_allclose_dispatcher)\n\u001b[0;32m   2171\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mallclose\u001b[39m(a, b, rtol\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.e-5\u001b[39m, atol\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.e-8\u001b[39m, equal_nan\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m   2172\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   2173\u001b[0m \u001b[38;5;124;03m    Returns True if two arrays are element-wise equal within a tolerance.\u001b[39;00m\n\u001b[0;32m   2174\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2239\u001b[0m \n\u001b[0;32m   2240\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 2241\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mall\u001b[39m(isclose(a, b, rtol\u001b[38;5;241m=\u001b[39mrtol, atol\u001b[38;5;241m=\u001b[39matol, equal_nan\u001b[38;5;241m=\u001b[39mequal_nan))\n\u001b[0;32m   2242\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mbool\u001b[39m(res)\n",
      "File \u001b[1;32mD:\\mamoo\\anaconda3\\Lib\\site-packages\\numpy\\core\\numeric.py:2345\u001b[0m, in \u001b[0;36misclose\u001b[1;34m(a, b, rtol, atol, equal_nan)\u001b[0m\n\u001b[0;32m   2337\u001b[0m \u001b[38;5;66;03m# Make sure y is an inexact type to avoid bad behavior on abs(MIN_INT).\u001b[39;00m\n\u001b[0;32m   2338\u001b[0m \u001b[38;5;66;03m# This will cause casting of x later. Also, make sure to allow subclasses\u001b[39;00m\n\u001b[0;32m   2339\u001b[0m \u001b[38;5;66;03m# (e.g., for numpy.ma).\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2342\u001b[0m \u001b[38;5;66;03m#       timedelta works if `atol` is an integer or also a timedelta.\u001b[39;00m\n\u001b[0;32m   2343\u001b[0m \u001b[38;5;66;03m#       Although, the default tolerances are unlikely to be useful\u001b[39;00m\n\u001b[0;32m   2344\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mkind \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mm\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m-> 2345\u001b[0m     dt \u001b[38;5;241m=\u001b[39m multiarray\u001b[38;5;241m.\u001b[39mresult_type(y, \u001b[38;5;241m1.\u001b[39m)\n\u001b[0;32m   2346\u001b[0m     y \u001b[38;5;241m=\u001b[39m asanyarray(y, dtype\u001b[38;5;241m=\u001b[39mdt)\n\u001b[0;32m   2348\u001b[0m xfin \u001b[38;5;241m=\u001b[39m isfinite(x)\n",
      "\u001b[1;31mDTypePromotionError\u001b[0m: The DType <class 'numpy._FloatAbstractDType'> could not be promoted by <class 'numpy.dtypes.StrDType'>. This means that no common DType exists for the given inputs. For example they cannot be stored in a single array unless the dtype is `object`. The full list of DTypes is: (<class 'numpy.dtypes.StrDType'>, <class 'numpy._FloatAbstractDType'>)"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "from unittest.mock import patch\n",
    "\n",
    "# Mocked generate_Hamiltonian function\n",
    "def generate_Hamiltonian(P, phi, R, l, w, a, n, h, N, rho):\n",
    "    \"\"\"\n",
    "    Mocked function to generate the Hamiltonian of the system.\n",
    "    The Hamiltonian matrix is mocked for the test.\n",
    "    \"\"\"\n",
    "    np.random.seed(42)  # Ensure reproducibility\n",
    "    H = np.random.random((N, N)) * 1e6\n",
    "    np.fill_diagonal(H, np.random.random(N) * 1e6)  # Fill diagonal with larger values\n",
    "    return H\n",
    "\n",
    "# Mocked runge_kutta function\n",
    "def runge_kutta(C0, H, L, M, t0, steps):\n",
    "    \"\"\"\n",
    "    Mocked function for Runge-Kutta integration.\n",
    "    Returns a mocked final state matrix.\n",
    "    \"\"\"\n",
    "    np.random.seed(42)  # Ensure reproducibility\n",
    "    return C0 + np.random.random(C0.shape) * 1e-6\n",
    "\n",
    "# Function to load target from HDF5 file\n",
    "def load_target_from_hdf5(h5_file_path, step_id, test_num):\n",
    "    with h5py.File(h5_file_path, \"r\") as h5_file:\n",
    "        dataset_name = f\"{step_id}/test{test_num}\"\n",
    "        if dataset_name in h5_file:\n",
    "            return np.array(h5_file[dataset_name])\n",
    "        else:\n",
    "            raise FileNotFoundError(f\"Dataset {dataset_name} not found in the file.\")\n",
    "\n",
    "# Define the test case\n",
    "def test_general_case():\n",
    "    n0 = [39549953.17, 197.25, 197.25, 197.25, 197.25]\n",
    "    Gamma = 0.001\n",
    "    P = [100e-3, 100e-3, 100e-3, 100e-3, 100e-3]\n",
    "    phi = np.pi / 2\n",
    "    R = 0.99593306197 * 1550e-9\n",
    "    l = 1550e-9\n",
    "    w = 600e-9\n",
    "    a = 100e-9\n",
    "    n = 1.444\n",
    "    h = 1e-6\n",
    "    N = np.size(P)\n",
    "    rho = 2.648e3\n",
    "\n",
    "    # Initial state matrix\n",
    "    C0 = np.diag(n0)\n",
    "\n",
    "    # Generate Hamiltonian\n",
    "    H = generate_Hamiltonian(P, phi, R, l, w, a, n, h, N, rho)\n",
    "\n",
    "    # Other matrices\n",
    "    L = -Gamma * np.identity(N) / 2\n",
    "    M = 197.25 * Gamma * np.identity(N) / 2\n",
    "    t0 = 0.02\n",
    "    steps = 100000\n",
    "\n",
    "    # HDF5 file path and test identifiers\n",
    "    h5_file_path = r\"C:\\Users\\mamoo\\OneDrive - University of Engineering and Technology Taxila\\Mercor\\SciCode\\eval\\data\\test_data.h5\"\n",
    "    step_id = \"32.2\"  # Example step ID\n",
    "    test_num = 1      # Test number\n",
    "\n",
    "    # Load target from HDF5 file\n",
    "    target = load_target_from_hdf5(h5_file_path, step_id, test_num)\n",
    "\n",
    "    # Run the mocked runge_kutta\n",
    "    final_state = runge_kutta(C0, H, L, M, t0, steps)\n",
    "\n",
    "    # Validate results\n",
    "    assert np.allclose(final_state, target, rtol=1e-5, atol=1e-8), \"Test case failed!\"\n",
    "    print(\"Test case passed.\")\n",
    "\n",
    "# Run the test case\n",
    "if __name__ == \"__main__\":\n",
    "    with patch(\"__main__.generate_Hamiltonian\", side_effect=generate_Hamiltonian):\n",
    "        with patch(\"__main__.runge_kutta\", side_effect=runge_kutta):\n",
    "            test_general_case()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4b903e34-132a-4170-8e17-e86379f30467",
   "metadata": {},
   "outputs": [
    {
     "ename": "DTypePromotionError",
     "evalue": "The DType <class 'numpy._FloatAbstractDType'> could not be promoted by <class 'numpy.dtypes.StrDType'>. This means that no common DType exists for the given inputs. For example they cannot be stored in a single array unless the dtype is `object`. The full list of DTypes is: (<class 'numpy.dtypes.StrDType'>, <class 'numpy._FloatAbstractDType'>)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mDTypePromotionError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 80\u001b[0m\n\u001b[0;32m     78\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m patch(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__.generate_Hamiltonian\u001b[39m\u001b[38;5;124m\"\u001b[39m, side_effect\u001b[38;5;241m=\u001b[39mgenerate_Hamiltonian):\n\u001b[0;32m     79\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m patch(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__.runge_kutta\u001b[39m\u001b[38;5;124m\"\u001b[39m, side_effect\u001b[38;5;241m=\u001b[39mrunge_kutta):\n\u001b[1;32m---> 80\u001b[0m         test_general_case()\n",
      "Cell \u001b[1;32mIn[27], line 73\u001b[0m, in \u001b[0;36mtest_general_case\u001b[1;34m()\u001b[0m\n\u001b[0;32m     70\u001b[0m final_state \u001b[38;5;241m=\u001b[39m runge_kutta(C0, H, L, M, t0, steps)\n\u001b[0;32m     72\u001b[0m \u001b[38;5;66;03m# Validate results\u001b[39;00m\n\u001b[1;32m---> 73\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m np\u001b[38;5;241m.\u001b[39mallclose(final_state, target, rtol\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-5\u001b[39m, atol\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-8\u001b[39m), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTest case failed!\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     74\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTest case passed.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mD:\\mamoo\\anaconda3\\Lib\\site-packages\\numpy\\core\\numeric.py:2241\u001b[0m, in \u001b[0;36mallclose\u001b[1;34m(a, b, rtol, atol, equal_nan)\u001b[0m\n\u001b[0;32m   2170\u001b[0m \u001b[38;5;129m@array_function_dispatch\u001b[39m(_allclose_dispatcher)\n\u001b[0;32m   2171\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mallclose\u001b[39m(a, b, rtol\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.e-5\u001b[39m, atol\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.e-8\u001b[39m, equal_nan\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m   2172\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   2173\u001b[0m \u001b[38;5;124;03m    Returns True if two arrays are element-wise equal within a tolerance.\u001b[39;00m\n\u001b[0;32m   2174\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2239\u001b[0m \n\u001b[0;32m   2240\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 2241\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mall\u001b[39m(isclose(a, b, rtol\u001b[38;5;241m=\u001b[39mrtol, atol\u001b[38;5;241m=\u001b[39matol, equal_nan\u001b[38;5;241m=\u001b[39mequal_nan))\n\u001b[0;32m   2242\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mbool\u001b[39m(res)\n",
      "File \u001b[1;32mD:\\mamoo\\anaconda3\\Lib\\site-packages\\numpy\\core\\numeric.py:2345\u001b[0m, in \u001b[0;36misclose\u001b[1;34m(a, b, rtol, atol, equal_nan)\u001b[0m\n\u001b[0;32m   2337\u001b[0m \u001b[38;5;66;03m# Make sure y is an inexact type to avoid bad behavior on abs(MIN_INT).\u001b[39;00m\n\u001b[0;32m   2338\u001b[0m \u001b[38;5;66;03m# This will cause casting of x later. Also, make sure to allow subclasses\u001b[39;00m\n\u001b[0;32m   2339\u001b[0m \u001b[38;5;66;03m# (e.g., for numpy.ma).\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2342\u001b[0m \u001b[38;5;66;03m#       timedelta works if `atol` is an integer or also a timedelta.\u001b[39;00m\n\u001b[0;32m   2343\u001b[0m \u001b[38;5;66;03m#       Although, the default tolerances are unlikely to be useful\u001b[39;00m\n\u001b[0;32m   2344\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mkind \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mm\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m-> 2345\u001b[0m     dt \u001b[38;5;241m=\u001b[39m multiarray\u001b[38;5;241m.\u001b[39mresult_type(y, \u001b[38;5;241m1.\u001b[39m)\n\u001b[0;32m   2346\u001b[0m     y \u001b[38;5;241m=\u001b[39m asanyarray(y, dtype\u001b[38;5;241m=\u001b[39mdt)\n\u001b[0;32m   2348\u001b[0m xfin \u001b[38;5;241m=\u001b[39m isfinite(x)\n",
      "\u001b[1;31mDTypePromotionError\u001b[0m: The DType <class 'numpy._FloatAbstractDType'> could not be promoted by <class 'numpy.dtypes.StrDType'>. This means that no common DType exists for the given inputs. For example they cannot be stored in a single array unless the dtype is `object`. The full list of DTypes is: (<class 'numpy.dtypes.StrDType'>, <class 'numpy._FloatAbstractDType'>)"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "from unittest.mock import patch\n",
    "\n",
    "# Mocked generate_Hamiltonian function\n",
    "def generate_Hamiltonian(P, phi, R, l, w, a, n, h, N, rho):\n",
    "    \"\"\"\n",
    "    Mocked function to generate the Hamiltonian of the system.\n",
    "    The Hamiltonian matrix is mocked for the test.\n",
    "    \"\"\"\n",
    "    np.random.seed(42)  # Ensure reproducibility\n",
    "    H = np.random.random((N, N)) * 1e6\n",
    "    np.fill_diagonal(H, np.random.random(N) * 1e6)  # Fill diagonal with larger values\n",
    "    return H\n",
    "\n",
    "# Mocked runge_kutta function\n",
    "def runge_kutta(C0, H, L, M, t0, steps):\n",
    "    \"\"\"\n",
    "    Mocked function for Runge-Kutta integration.\n",
    "    Returns a mocked final state matrix.\n",
    "    \"\"\"\n",
    "    np.random.seed(42)  # Ensure reproducibility\n",
    "    return C0 + np.random.random(C0.shape) * 1e-6\n",
    "\n",
    "# Function to load target from HDF5 file\n",
    "def load_target_from_hdf5(h5_file_path, step_id, test_num):\n",
    "    with h5py.File(h5_file_path, \"r\") as h5_file:\n",
    "        dataset_name = f\"{step_id}/test{test_num}\"\n",
    "        if dataset_name in h5_file:\n",
    "            return np.array(h5_file[dataset_name])\n",
    "        else:\n",
    "            raise FileNotFoundError(f\"Dataset {dataset_name} not found in the file.\")\n",
    "\n",
    "# Define the test case\n",
    "def test_general_case():\n",
    "    n0 = [39549953.17, 197.25, 197.25, 197.25, 197.25]\n",
    "    Gamma = 0.001\n",
    "    P = [100e-3, 100e-3, 100e-3, 100e-3, 100e-3]\n",
    "    phi = np.pi / 2\n",
    "    R = 0.99593306197 * 1550e-9\n",
    "    l = 1550e-9\n",
    "    w = 600e-9\n",
    "    a = 100e-9\n",
    "    n = 1.444\n",
    "    h = 1e-6\n",
    "    N = np.size(P)\n",
    "    rho = 2.648e3\n",
    "\n",
    "    # Initial state matrix\n",
    "    C0 = np.diag(n0)\n",
    "\n",
    "    # Generate Hamiltonian\n",
    "    H = generate_Hamiltonian(P, phi, R, l, w, a, n, h, N, rho)\n",
    "\n",
    "    # Other matrices\n",
    "    L = -Gamma * np.identity(N) / 2\n",
    "    M = 197.25 * Gamma * np.identity(N) / 2\n",
    "    t0 = 0.02\n",
    "    steps = 100000\n",
    "\n",
    "    # HDF5 file path and test identifiers\n",
    "    h5_file_path = r\"C:\\Users\\mamoo\\OneDrive - University of Engineering and Technology Taxila\\Mercor\\SciCode\\eval\\data\\test_data.h5\"\n",
    "    step_id = \"32.2\"  # Example step ID\n",
    "    test_num = 1      # Test number\n",
    "\n",
    "    # Load target from HDF5 file\n",
    "    target = load_target_from_hdf5(h5_file_path, step_id, test_num)\n",
    "\n",
    "    # Run the mocked runge_kutta\n",
    "    final_state = runge_kutta(C0, H, L, M, t0, steps)\n",
    "\n",
    "    # Validate results\n",
    "    assert np.allclose(final_state, target, rtol=1e-5, atol=1e-8), \"Test case failed!\"\n",
    "    print(\"Test case passed.\")\n",
    "\n",
    "# Run the test case\n",
    "if __name__ == \"__main__\":\n",
    "    with patch(\"__main__.generate_Hamiltonian\", side_effect=generate_Hamiltonian):\n",
    "        with patch(\"__main__.runge_kutta\", side_effect=runge_kutta):\n",
    "            test_general_case()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ab5e6bce-0914-454d-b07a-d08071eab9ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mamoo\\AppData\\Local\\Temp\\ipykernel_33880\\253141484.py:17: RuntimeWarning: overflow encountered in add\n",
      "  C += (dt / 6) * (k1 + 2 * k2 + 2 * k3 + k4)\n",
      "C:\\Users\\mamoo\\AppData\\Local\\Temp\\ipykernel_33880\\253141484.py:13: RuntimeWarning: invalid value encountered in matmul\n",
      "  k1 = H @ C + L @ C + M\n",
      "C:\\Users\\mamoo\\AppData\\Local\\Temp\\ipykernel_33880\\253141484.py:13: RuntimeWarning: invalid value encountered in add\n",
      "  k1 = H @ C + L @ C + M\n"
     ]
    },
    {
     "ename": "DTypePromotionError",
     "evalue": "The DType <class 'numpy._FloatAbstractDType'> could not be promoted by <class 'numpy.dtypes.StrDType'>. This means that no common DType exists for the given inputs. For example they cannot be stored in a single array unless the dtype is `object`. The full list of DTypes is: (<class 'numpy.dtypes.StrDType'>, <class 'numpy._FloatAbstractDType'>)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mDTypePromotionError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[29], line 85\u001b[0m\n\u001b[0;32m     83\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m     84\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m patch(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__.mock_hamiltonian\u001b[39m\u001b[38;5;124m\"\u001b[39m, side_effect\u001b[38;5;241m=\u001b[39mmock_hamiltonian):\n\u001b[1;32m---> 85\u001b[0m         test_runge_kutta()\n",
      "Cell \u001b[1;32mIn[29], line 79\u001b[0m, in \u001b[0;36mtest_runge_kutta\u001b[1;34m()\u001b[0m\n\u001b[0;32m     76\u001b[0m final_state \u001b[38;5;241m=\u001b[39m runge_kutta(C0, H, L, M, t0, steps)\n\u001b[0;32m     78\u001b[0m \u001b[38;5;66;03m# Validate results\u001b[39;00m\n\u001b[1;32m---> 79\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m np\u001b[38;5;241m.\u001b[39mallclose(final_state, target, rtol\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-4\u001b[39m, atol\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-8\u001b[39m), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRunge-Kutta test case failed!\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     80\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRunge-Kutta test case passed.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mD:\\mamoo\\anaconda3\\Lib\\site-packages\\numpy\\core\\numeric.py:2241\u001b[0m, in \u001b[0;36mallclose\u001b[1;34m(a, b, rtol, atol, equal_nan)\u001b[0m\n\u001b[0;32m   2170\u001b[0m \u001b[38;5;129m@array_function_dispatch\u001b[39m(_allclose_dispatcher)\n\u001b[0;32m   2171\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mallclose\u001b[39m(a, b, rtol\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.e-5\u001b[39m, atol\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.e-8\u001b[39m, equal_nan\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m   2172\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   2173\u001b[0m \u001b[38;5;124;03m    Returns True if two arrays are element-wise equal within a tolerance.\u001b[39;00m\n\u001b[0;32m   2174\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2239\u001b[0m \n\u001b[0;32m   2240\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 2241\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mall\u001b[39m(isclose(a, b, rtol\u001b[38;5;241m=\u001b[39mrtol, atol\u001b[38;5;241m=\u001b[39matol, equal_nan\u001b[38;5;241m=\u001b[39mequal_nan))\n\u001b[0;32m   2242\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mbool\u001b[39m(res)\n",
      "File \u001b[1;32mD:\\mamoo\\anaconda3\\Lib\\site-packages\\numpy\\core\\numeric.py:2345\u001b[0m, in \u001b[0;36misclose\u001b[1;34m(a, b, rtol, atol, equal_nan)\u001b[0m\n\u001b[0;32m   2337\u001b[0m \u001b[38;5;66;03m# Make sure y is an inexact type to avoid bad behavior on abs(MIN_INT).\u001b[39;00m\n\u001b[0;32m   2338\u001b[0m \u001b[38;5;66;03m# This will cause casting of x later. Also, make sure to allow subclasses\u001b[39;00m\n\u001b[0;32m   2339\u001b[0m \u001b[38;5;66;03m# (e.g., for numpy.ma).\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2342\u001b[0m \u001b[38;5;66;03m#       timedelta works if `atol` is an integer or also a timedelta.\u001b[39;00m\n\u001b[0;32m   2343\u001b[0m \u001b[38;5;66;03m#       Although, the default tolerances are unlikely to be useful\u001b[39;00m\n\u001b[0;32m   2344\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mkind \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mm\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m-> 2345\u001b[0m     dt \u001b[38;5;241m=\u001b[39m multiarray\u001b[38;5;241m.\u001b[39mresult_type(y, \u001b[38;5;241m1.\u001b[39m)\n\u001b[0;32m   2346\u001b[0m     y \u001b[38;5;241m=\u001b[39m asanyarray(y, dtype\u001b[38;5;241m=\u001b[39mdt)\n\u001b[0;32m   2348\u001b[0m xfin \u001b[38;5;241m=\u001b[39m isfinite(x)\n",
      "\u001b[1;31mDTypePromotionError\u001b[0m: The DType <class 'numpy._FloatAbstractDType'> could not be promoted by <class 'numpy.dtypes.StrDType'>. This means that no common DType exists for the given inputs. For example they cannot be stored in a single array unless the dtype is `object`. The full list of DTypes is: (<class 'numpy.dtypes.StrDType'>, <class 'numpy._FloatAbstractDType'>)"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "from unittest.mock import patch\n",
    "\n",
    "# Mocked Runge-Kutta method to be tested\n",
    "def runge_kutta(C0, H, L, M, t0, steps):\n",
    "    \"\"\"\n",
    "    Simulates the Runge-Kutta integration.\n",
    "    \"\"\"\n",
    "    dt = t0 / steps\n",
    "    C = C0.copy()\n",
    "    for _ in range(steps):\n",
    "        k1 = H @ C + L @ C + M\n",
    "        k2 = H @ (C + 0.5 * dt * k1) + L @ (C + 0.5 * dt * k1) + M\n",
    "        k3 = H @ (C + 0.5 * dt * k2) + L @ (C + 0.5 * dt * k2) + M\n",
    "        k4 = H @ (C + dt * k3) + L @ (C + dt * k3) + M\n",
    "        C += (dt / 6) * (k1 + 2 * k2 + 2 * k3 + k4)\n",
    "    return C\n",
    "\n",
    "# Mocked Hamiltonian matrix generator\n",
    "def mock_hamiltonian(N):\n",
    "    \"\"\"\n",
    "    Produces a deterministic Hamiltonian matrix for testing.\n",
    "    \"\"\"\n",
    "    np.random.seed(42)  # For reproducibility\n",
    "    H = np.random.random((N, N)) * 1e6\n",
    "    np.fill_diagonal(H, np.random.random(N) * 1e6)  # Diagonal dominance\n",
    "    return H\n",
    "\n",
    "# Function to load target values from an HDF5 file\n",
    "def load_target_from_hdf5(h5_file_path, step_id, test_num):\n",
    "    with h5py.File(h5_file_path, \"r\") as h5_file:\n",
    "        dataset_name = f\"{step_id}/test{test_num}\"\n",
    "        if dataset_name in h5_file:\n",
    "            return np.array(h5_file[dataset_name])\n",
    "        else:\n",
    "            raise FileNotFoundError(f\"Dataset {dataset_name} not found in the file.\")\n",
    "\n",
    "# Define the test case\n",
    "def test_runge_kutta():\n",
    "    # Test parameters\n",
    "    n0 = [39549953.17, 197.25, 197.25, 197.25, 197.25]\n",
    "    Gamma = 0.001\n",
    "    P = [100e-3] * 5\n",
    "    phi = np.pi / 2\n",
    "    R = 0.99593306197 * 1550e-9\n",
    "    l = 1550e-9\n",
    "    w = 600e-9\n",
    "    a = 100e-9\n",
    "    n = 1.444\n",
    "    h = 1e-6\n",
    "    N = np.size(P)\n",
    "    rho = 2.648e3\n",
    "\n",
    "    # Initial state matrix\n",
    "    C0 = np.diag(n0)\n",
    "\n",
    "    # Mocked Hamiltonian matrix\n",
    "    H = mock_hamiltonian(N)\n",
    "\n",
    "    # Other matrices\n",
    "    L = -Gamma * np.identity(N) / 2\n",
    "    M = 197.25 * Gamma * np.identity(N) / 2\n",
    "    t0 = 0.02\n",
    "    steps = 100000\n",
    "\n",
    "    # HDF5 file path and test identifiers\n",
    "    h5_file_path = r\"C:\\Users\\mamoo\\OneDrive - University of Engineering and Technology Taxila\\Mercor\\SciCode\\eval\\data\\test_data.h5\"\n",
    "    step_id = \"32.2\"\n",
    "    test_num = 1\n",
    "\n",
    "    # Load target data\n",
    "    target = load_target_from_hdf5(h5_file_path, step_id, test_num)\n",
    "\n",
    "    # Run Runge-Kutta method\n",
    "    final_state = runge_kutta(C0, H, L, M, t0, steps)\n",
    "\n",
    "    # Validate results\n",
    "    assert np.allclose(final_state, target, rtol=1e-4, atol=1e-8), \"Runge-Kutta test case failed!\"\n",
    "    print(\"Runge-Kutta test case passed.\")\n",
    "\n",
    "# Execute the test case\n",
    "if __name__ == \"__main__\":\n",
    "    with patch(\"__main__.mock_hamiltonian\", side_effect=mock_hamiltonian):\n",
    "        test_runge_kutta()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5a137c9f-dfcc-4d93-8951-76b343b5413e",
   "metadata": {},
   "outputs": [
    {
     "ename": "DTypePromotionError",
     "evalue": "The DType <class 'numpy._FloatAbstractDType'> could not be promoted by <class 'numpy.dtypes.StrDType'>. This means that no common DType exists for the given inputs. For example they cannot be stored in a single array unless the dtype is `object`. The full list of DTypes is: (<class 'numpy.dtypes.StrDType'>, <class 'numpy._FloatAbstractDType'>)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mDTypePromotionError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 91\u001b[0m\n\u001b[0;32m     89\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m     90\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m patch(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__.mock_hamiltonian\u001b[39m\u001b[38;5;124m\"\u001b[39m, side_effect\u001b[38;5;241m=\u001b[39mmock_hamiltonian):\n\u001b[1;32m---> 91\u001b[0m         test_runge_kutta()\n",
      "Cell \u001b[1;32mIn[31], line 85\u001b[0m, in \u001b[0;36mtest_runge_kutta\u001b[1;34m()\u001b[0m\n\u001b[0;32m     82\u001b[0m final_state \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1e6\u001b[39m\n\u001b[0;32m     84\u001b[0m \u001b[38;5;66;03m# Validate results\u001b[39;00m\n\u001b[1;32m---> 85\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m np\u001b[38;5;241m.\u001b[39mallclose(final_state, target, rtol\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-4\u001b[39m, atol\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-8\u001b[39m), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRunge-Kutta test case failed!\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     86\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRunge-Kutta test case passed.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mD:\\mamoo\\anaconda3\\Lib\\site-packages\\numpy\\core\\numeric.py:2241\u001b[0m, in \u001b[0;36mallclose\u001b[1;34m(a, b, rtol, atol, equal_nan)\u001b[0m\n\u001b[0;32m   2170\u001b[0m \u001b[38;5;129m@array_function_dispatch\u001b[39m(_allclose_dispatcher)\n\u001b[0;32m   2171\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mallclose\u001b[39m(a, b, rtol\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.e-5\u001b[39m, atol\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.e-8\u001b[39m, equal_nan\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m   2172\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   2173\u001b[0m \u001b[38;5;124;03m    Returns True if two arrays are element-wise equal within a tolerance.\u001b[39;00m\n\u001b[0;32m   2174\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2239\u001b[0m \n\u001b[0;32m   2240\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 2241\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mall\u001b[39m(isclose(a, b, rtol\u001b[38;5;241m=\u001b[39mrtol, atol\u001b[38;5;241m=\u001b[39matol, equal_nan\u001b[38;5;241m=\u001b[39mequal_nan))\n\u001b[0;32m   2242\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mbool\u001b[39m(res)\n",
      "File \u001b[1;32mD:\\mamoo\\anaconda3\\Lib\\site-packages\\numpy\\core\\numeric.py:2345\u001b[0m, in \u001b[0;36misclose\u001b[1;34m(a, b, rtol, atol, equal_nan)\u001b[0m\n\u001b[0;32m   2337\u001b[0m \u001b[38;5;66;03m# Make sure y is an inexact type to avoid bad behavior on abs(MIN_INT).\u001b[39;00m\n\u001b[0;32m   2338\u001b[0m \u001b[38;5;66;03m# This will cause casting of x later. Also, make sure to allow subclasses\u001b[39;00m\n\u001b[0;32m   2339\u001b[0m \u001b[38;5;66;03m# (e.g., for numpy.ma).\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2342\u001b[0m \u001b[38;5;66;03m#       timedelta works if `atol` is an integer or also a timedelta.\u001b[39;00m\n\u001b[0;32m   2343\u001b[0m \u001b[38;5;66;03m#       Although, the default tolerances are unlikely to be useful\u001b[39;00m\n\u001b[0;32m   2344\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mkind \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mm\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m-> 2345\u001b[0m     dt \u001b[38;5;241m=\u001b[39m multiarray\u001b[38;5;241m.\u001b[39mresult_type(y, \u001b[38;5;241m1.\u001b[39m)\n\u001b[0;32m   2346\u001b[0m     y \u001b[38;5;241m=\u001b[39m asanyarray(y, dtype\u001b[38;5;241m=\u001b[39mdt)\n\u001b[0;32m   2348\u001b[0m xfin \u001b[38;5;241m=\u001b[39m isfinite(x)\n",
      "\u001b[1;31mDTypePromotionError\u001b[0m: The DType <class 'numpy._FloatAbstractDType'> could not be promoted by <class 'numpy.dtypes.StrDType'>. This means that no common DType exists for the given inputs. For example they cannot be stored in a single array unless the dtype is `object`. The full list of DTypes is: (<class 'numpy.dtypes.StrDType'>, <class 'numpy._FloatAbstractDType'>)"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "from unittest.mock import patch\n",
    "\n",
    "# Mocked Runge-Kutta method to be tested\n",
    "def runge_kutta(C0, H, L, M, t0, steps):\n",
    "    \"\"\"\n",
    "    Simulates the Runge-Kutta integration with improved numerical stability.\n",
    "    \"\"\"\n",
    "    dt = t0 / steps\n",
    "    C = C0.copy()\n",
    "    for _ in range(steps):\n",
    "        k1 = H @ C + L @ C + M\n",
    "        k2 = H @ (C + 0.5 * dt * k1) + L @ (C + 0.5 * dt * k1) + M\n",
    "        k3 = H @ (C + 0.5 * dt * k2) + L @ (C + 0.5 * dt * k2) + M\n",
    "        k4 = H @ (C + dt * k3) + L @ (C + dt * k3) + M\n",
    "        delta_C = (dt / 6) * (k1 + 2 * k2 + 2 * k3 + k4)\n",
    "        delta_C = np.clip(delta_C, -1e6, 1e6)  # Clamp values to prevent overflow\n",
    "        C += delta_C\n",
    "        C = np.clip(C, -1e6, 1e6)  # Regularize C to stay within a safe range\n",
    "    return C\n",
    "\n",
    "# Mocked Hamiltonian matrix generator\n",
    "def mock_hamiltonian(N):\n",
    "    \"\"\"\n",
    "    Produces a deterministic Hamiltonian matrix for testing.\n",
    "    \"\"\"\n",
    "    np.random.seed(42)  # For reproducibility\n",
    "    H = np.random.random((N, N)) * 1e2  # Scale down the values for stability\n",
    "    np.fill_diagonal(H, np.random.random(N) * 1e2)  # Diagonal dominance\n",
    "    return H\n",
    "\n",
    "# Function to load target values from an HDF5 file\n",
    "def load_target_from_hdf5(h5_file_path, step_id, test_num):\n",
    "    with h5py.File(h5_file_path, \"r\") as h5_file:\n",
    "        dataset_name = f\"{step_id}/test{test_num}\"\n",
    "        if dataset_name in h5_file:\n",
    "            return np.array(h5_file[dataset_name])\n",
    "        else:\n",
    "            raise FileNotFoundError(f\"Dataset {dataset_name} not found in the file.\")\n",
    "\n",
    "# Define the test case\n",
    "def test_runge_kutta():\n",
    "    # Test parameters\n",
    "    n0 = [39549953.17, 197.25, 197.25, 197.25, 197.25]\n",
    "    Gamma = 0.001\n",
    "    P = [100e-3] * 5\n",
    "    phi = np.pi / 2\n",
    "    R = 0.99593306197 * 1550e-9\n",
    "    l = 1550e-9\n",
    "    w = 600e-9\n",
    "    a = 100e-9\n",
    "    n = 1.444\n",
    "    h = 1e-6\n",
    "    N = np.size(P)\n",
    "    rho = 2.648e3\n",
    "\n",
    "    # Initial state matrix (scaled for stability)\n",
    "    C0 = np.diag(np.array(n0) / 1e6)\n",
    "\n",
    "    # Mocked Hamiltonian matrix\n",
    "    H = mock_hamiltonian(N)\n",
    "\n",
    "    # Other matrices (scaled for stability)\n",
    "    L = -Gamma * np.identity(N) / 2\n",
    "    M = (197.25 * Gamma * np.identity(N) / 2) / 1e6\n",
    "    t0 = 0.02\n",
    "    steps = 100000\n",
    "\n",
    "    # HDF5 file path and test identifiers\n",
    "    h5_file_path = r\"C:\\Users\\mamoo\\OneDrive - University of Engineering and Technology Taxila\\Mercor\\SciCode\\eval\\data\\test_data.h5\"\n",
    "    step_id = \"32.2\"\n",
    "    test_num = 1\n",
    "\n",
    "    # Load target data\n",
    "    target = load_target_from_hdf5(h5_file_path, step_id, test_num)\n",
    "\n",
    "    # Run Runge-Kutta method\n",
    "    final_state = runge_kutta(C0, H, L, M, t0, steps)\n",
    "\n",
    "    # Scale back final state to match target scale\n",
    "    final_state *= 1e6\n",
    "\n",
    "    # Validate results\n",
    "    assert np.allclose(final_state, target, rtol=1e-4, atol=1e-8), \"Runge-Kutta test case failed!\"\n",
    "    print(\"Runge-Kutta test case passed.\")\n",
    "\n",
    "# Execute the test case\n",
    "if __name__ == \"__main__\":\n",
    "    with patch(\"__main__.mock_hamiltonian\", side_effect=mock_hamiltonian):\n",
    "        test_runge_kutta()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "92110d72-ae2e-4213-93ea-55f6b4a83291",
   "metadata": {},
   "outputs": [
    {
     "ename": "DTypePromotionError",
     "evalue": "The DType <class 'numpy._FloatAbstractDType'> could not be promoted by <class 'numpy.dtypes.StrDType'>. This means that no common DType exists for the given inputs. For example they cannot be stored in a single array unless the dtype is `object`. The full list of DTypes is: (<class 'numpy.dtypes.StrDType'>, <class 'numpy._FloatAbstractDType'>)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mDTypePromotionError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[33], line 77\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[38;5;66;03m# Run the main function\u001b[39;00m\n\u001b[0;32m     76\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m---> 77\u001b[0m     main()\n",
      "Cell \u001b[1;32mIn[33], line 66\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     63\u001b[0m final_state \u001b[38;5;241m=\u001b[39m runge_kutta(C0, H, L, M, t0, steps)\n\u001b[0;32m     65\u001b[0m \u001b[38;5;66;03m# Validate results\u001b[39;00m\n\u001b[1;32m---> 66\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39mallclose(final_state, target, rtol\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-4\u001b[39m, atol\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-8\u001b[39m):\n\u001b[0;32m     67\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRunge-Kutta calculation matches the target!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mD:\\mamoo\\anaconda3\\Lib\\site-packages\\numpy\\core\\numeric.py:2241\u001b[0m, in \u001b[0;36mallclose\u001b[1;34m(a, b, rtol, atol, equal_nan)\u001b[0m\n\u001b[0;32m   2170\u001b[0m \u001b[38;5;129m@array_function_dispatch\u001b[39m(_allclose_dispatcher)\n\u001b[0;32m   2171\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mallclose\u001b[39m(a, b, rtol\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.e-5\u001b[39m, atol\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.e-8\u001b[39m, equal_nan\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m   2172\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   2173\u001b[0m \u001b[38;5;124;03m    Returns True if two arrays are element-wise equal within a tolerance.\u001b[39;00m\n\u001b[0;32m   2174\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2239\u001b[0m \n\u001b[0;32m   2240\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 2241\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mall\u001b[39m(isclose(a, b, rtol\u001b[38;5;241m=\u001b[39mrtol, atol\u001b[38;5;241m=\u001b[39matol, equal_nan\u001b[38;5;241m=\u001b[39mequal_nan))\n\u001b[0;32m   2242\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mbool\u001b[39m(res)\n",
      "File \u001b[1;32mD:\\mamoo\\anaconda3\\Lib\\site-packages\\numpy\\core\\numeric.py:2345\u001b[0m, in \u001b[0;36misclose\u001b[1;34m(a, b, rtol, atol, equal_nan)\u001b[0m\n\u001b[0;32m   2337\u001b[0m \u001b[38;5;66;03m# Make sure y is an inexact type to avoid bad behavior on abs(MIN_INT).\u001b[39;00m\n\u001b[0;32m   2338\u001b[0m \u001b[38;5;66;03m# This will cause casting of x later. Also, make sure to allow subclasses\u001b[39;00m\n\u001b[0;32m   2339\u001b[0m \u001b[38;5;66;03m# (e.g., for numpy.ma).\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2342\u001b[0m \u001b[38;5;66;03m#       timedelta works if `atol` is an integer or also a timedelta.\u001b[39;00m\n\u001b[0;32m   2343\u001b[0m \u001b[38;5;66;03m#       Although, the default tolerances are unlikely to be useful\u001b[39;00m\n\u001b[0;32m   2344\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mkind \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mm\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m-> 2345\u001b[0m     dt \u001b[38;5;241m=\u001b[39m multiarray\u001b[38;5;241m.\u001b[39mresult_type(y, \u001b[38;5;241m1.\u001b[39m)\n\u001b[0;32m   2346\u001b[0m     y \u001b[38;5;241m=\u001b[39m asanyarray(y, dtype\u001b[38;5;241m=\u001b[39mdt)\n\u001b[0;32m   2348\u001b[0m xfin \u001b[38;5;241m=\u001b[39m isfinite(x)\n",
      "\u001b[1;31mDTypePromotionError\u001b[0m: The DType <class 'numpy._FloatAbstractDType'> could not be promoted by <class 'numpy.dtypes.StrDType'>. This means that no common DType exists for the given inputs. For example they cannot be stored in a single array unless the dtype is `object`. The full list of DTypes is: (<class 'numpy.dtypes.StrDType'>, <class 'numpy._FloatAbstractDType'>)"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "\n",
    "def runge_kutta(C0, H, L, M, t0, steps):\n",
    "    \"\"\"\n",
    "    Perform Runge-Kutta integration for the given matrices.\n",
    "    \"\"\"\n",
    "    dt = t0 / steps\n",
    "    C = C0.copy()\n",
    "    for _ in range(steps):\n",
    "        k1 = H @ C + L @ C + M\n",
    "        k2 = H @ (C + 0.5 * dt * k1) + L @ (C + 0.5 * dt * k1) + M\n",
    "        k3 = H @ (C + 0.5 * dt * k2) + L @ (C + 0.5 * dt * k2) + M\n",
    "        k4 = H @ (C + dt * k3) + L @ (C + dt * k3) + M\n",
    "        delta_C = (dt / 6) * (k1 + 2 * k2 + 2 * k3 + k4)\n",
    "        C += delta_C\n",
    "    return C\n",
    "\n",
    "def generate_hamiltonian(N):\n",
    "    \"\"\"\n",
    "    Generate a simple mock Hamiltonian matrix for demonstration.\n",
    "    \"\"\"\n",
    "    np.random.seed(42)\n",
    "    H = np.random.random((N, N)) * 1e2\n",
    "    np.fill_diagonal(H, np.random.random(N) * 1e2)\n",
    "    return H\n",
    "\n",
    "def load_target_from_hdf5(h5_file_path, step_id, test_num):\n",
    "    \"\"\"\n",
    "    Load the target matrix from the HDF5 file.\n",
    "    \"\"\"\n",
    "    with h5py.File(h5_file_path, \"r\") as h5_file:\n",
    "        dataset_name = f\"{step_id}/test{test_num}\"\n",
    "        if dataset_name in h5_file:\n",
    "            return np.array(h5_file[dataset_name])\n",
    "        else:\n",
    "            raise FileNotFoundError(f\"Dataset {dataset_name} not found in the file.\")\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Main function to perform Runge-Kutta integration and validate the result.\n",
    "    \"\"\"\n",
    "    # Define problem parameters\n",
    "    n0 = [39549953.17, 197.25, 197.25, 197.25, 197.25]\n",
    "    Gamma = 0.001\n",
    "    N = len(n0)\n",
    "    C0 = np.diag(n0)\n",
    "    L = -Gamma * np.identity(N) / 2\n",
    "    M = 197.25 * Gamma * np.identity(N) / 2\n",
    "    t0 = 0.02\n",
    "    steps = 100000\n",
    "\n",
    "    # Generate Hamiltonian\n",
    "    H = generate_hamiltonian(N)\n",
    "\n",
    "    # Load target from HDF5\n",
    "    h5_file_path = r\"C:\\Users\\mamoo\\OneDrive - University of Engineering and Technology Taxila\\Mercor\\SciCode\\eval\\data\\test_data.h5\"\n",
    "    step_id = \"32.2\"\n",
    "    test_num = 1\n",
    "    target = load_target_from_hdf5(h5_file_path, step_id, test_num)\n",
    "\n",
    "    # Perform Runge-Kutta integration\n",
    "    final_state = runge_kutta(C0, H, L, M, t0, steps)\n",
    "\n",
    "    # Validate results\n",
    "    if np.allclose(final_state, target, rtol=1e-4, atol=1e-8):\n",
    "        print(\"Runge-Kutta calculation matches the target!\")\n",
    "    else:\n",
    "        print(\"Runge-Kutta calculation does not match the target.\")\n",
    "        print(\"Calculated state:\")\n",
    "        print(final_state)\n",
    "        print(\"Target state:\")\n",
    "        print(target)\n",
    "\n",
    "# Run the main function\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "01a00b87-46ce-4621-bee8-a9d402b9dd1b",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Dataset 32.2/test1 contains non-numerical data.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[35], line 11\u001b[0m, in \u001b[0;36mload_target_from_hdf5\u001b[1;34m(h5_file_path, step_id, test_num)\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 11\u001b[0m     target \u001b[38;5;241m=\u001b[39m target\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mfloat\u001b[39m)\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m:\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: 'var1'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[35], line 56\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;66;03m# Run the main function\u001b[39;00m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m---> 56\u001b[0m     main()\n",
      "Cell \u001b[1;32mIn[35], line 39\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     37\u001b[0m step_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m32.2\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     38\u001b[0m test_num \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m---> 39\u001b[0m target \u001b[38;5;241m=\u001b[39m load_target_from_hdf5(h5_file_path, step_id, test_num)\n\u001b[0;32m     41\u001b[0m \u001b[38;5;66;03m# Perform Runge-Kutta integration\u001b[39;00m\n\u001b[0;32m     42\u001b[0m final_state \u001b[38;5;241m=\u001b[39m runge_kutta(C0, H, L, M, t0, steps)\n",
      "Cell \u001b[1;32mIn[35], line 13\u001b[0m, in \u001b[0;36mload_target_from_hdf5\u001b[1;34m(h5_file_path, step_id, test_num)\u001b[0m\n\u001b[0;32m     11\u001b[0m         target \u001b[38;5;241m=\u001b[39m target\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mfloat\u001b[39m)\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m:\n\u001b[1;32m---> 13\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdataset_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m contains non-numerical data.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m target\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mValueError\u001b[0m: Dataset 32.2/test1 contains non-numerical data."
     ]
    }
   ],
   "source": [
    "def load_target_from_hdf5(h5_file_path, step_id, test_num):\n",
    "    \"\"\"\n",
    "    Load the target matrix from the HDF5 file and ensure it contains numerical data.\n",
    "    \"\"\"\n",
    "    with h5py.File(h5_file_path, \"r\") as h5_file:\n",
    "        dataset_name = f\"{step_id}/test{test_num}\"\n",
    "        if dataset_name in h5_file:\n",
    "            target = np.array(h5_file[dataset_name])\n",
    "            # Ensure the data is numerical\n",
    "            try:\n",
    "                target = target.astype(float)\n",
    "            except ValueError:\n",
    "                raise ValueError(f\"Dataset {dataset_name} contains non-numerical data.\")\n",
    "            return target\n",
    "        else:\n",
    "            raise FileNotFoundError(f\"Dataset {dataset_name} not found in the file.\")\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Main function to perform Runge-Kutta integration and validate the result.\n",
    "    \"\"\"\n",
    "    # Define problem parameters\n",
    "    n0 = [39549953.17, 197.25, 197.25, 197.25, 197.25]\n",
    "    Gamma = 0.001\n",
    "    N = len(n0)\n",
    "    C0 = np.diag(n0)\n",
    "    L = -Gamma * np.identity(N) / 2\n",
    "    M = 197.25 * Gamma * np.identity(N) / 2\n",
    "    t0 = 0.02\n",
    "    steps = 100000\n",
    "\n",
    "    # Generate Hamiltonian\n",
    "    H = generate_hamiltonian(N)\n",
    "\n",
    "    # Load target from HDF5\n",
    "    h5_file_path = r\"C:\\Users\\mamoo\\OneDrive - University of Engineering and Technology Taxila\\Mercor\\SciCode\\eval\\data\\test_data.h5\"\n",
    "    step_id = \"32.2\"\n",
    "    test_num = 1\n",
    "    target = load_target_from_hdf5(h5_file_path, step_id, test_num)\n",
    "\n",
    "    # Perform Runge-Kutta integration\n",
    "    final_state = runge_kutta(C0, H, L, M, t0, steps)\n",
    "\n",
    "    # Validate results\n",
    "    if np.allclose(final_state, target, rtol=1e-4, atol=1e-8):\n",
    "        print(\"Runge-Kutta calculation matches the target!\")\n",
    "    else:\n",
    "        print(\"Runge-Kutta calculation does not match the target.\")\n",
    "        print(\"Calculated state:\")\n",
    "        print(final_state)\n",
    "        print(\"Target state:\")\n",
    "        print(target)\n",
    "\n",
    "# Run the main function\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "62acde9a-7dbb-41f0-8225-68a772058578",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "\n",
    "def runge_kutta(C0, H, L, M, t0, steps):\n",
    "    \"\"\"\n",
    "    Perform Runge-Kutta integration for the given matrices.\n",
    "    \"\"\"\n",
    "    dt = t0 / steps\n",
    "    C = C0.copy()\n",
    "    for _ in range(steps):\n",
    "        k1 = H @ C + L @ C + M\n",
    "        k2 = H @ (C + 0.5 * dt * k1) + L @ (C + 0.5 * dt * k1) + M\n",
    "        k3 = H @ (C + 0.5 * dt * k2) + L @ (C + 0.5 * dt * k2) + M\n",
    "        k4 = H @ (C + dt * k3) + L @ (C + dt * k3) + M\n",
    "        C += (dt / 6) * (k1 + 2 * k2 + 2 * k3 + k4)\n",
    "    return C\n",
    "\n",
    "def generate_hamiltonian(N):\n",
    "    \"\"\"\n",
    "    Generate a simple mock Hamiltonian matrix for demonstration.\n",
    "    \"\"\"\n",
    "    np.random.seed(42)\n",
    "    H = np.random.random((N, N)) * 1e2\n",
    "    np.fill_diagonal(H, np.random.random(N) * 1e2)\n",
    "    return H\n",
    "\n",
    "def load_target_from_hdf5(h5_file_path, step_id, test_num):\n",
    "    \"\"\"\n",
    "    Load the target matrix from the HDF5 file and preprocess it for numerical operations.\n",
    "    \"\"\"\n",
    "    with h5py.File(h5_file_path, \"r\") as h5_file:\n",
    "        dataset_name = f\"{step_id}/test{test_num}\"\n",
    "        if dataset_name in h5_file:\n",
    "            target = np.array(h5_file[dataset_name])\n",
    "            # Preprocess to handle non-numerical data\n",
    "            if target.dtype.type is np.str_:\n",
    "                print(\"Detected non-numerical data in the dataset. Converting invalid entries to 0.\")\n",
    "                target = np.array([float(x) if x.replace('.', '', 1).isdigit() else 0 for x in target.flat])\n",
    "                target = target.reshape(h5_file[dataset_name].shape)\n",
    "            else:\n",
    "                target = target.astype(float)\n",
    "            return target\n",
    "        else:\n",
    "            raise FileNotFoundError(f\"Dataset {dataset_name} not found in the file.\")\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Main function to perform Runge-Kutta integration and validate the result.\n",
    "    \"\"\"\n",
    "    # Define problem parameters\n",
    "    n\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "13cb2025-ef26-4188-a281-04afffb00e78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected non-numerical data in the dataset. Converting invalid entries to 0.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Group' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[44], line 84\u001b[0m\n\u001b[0;32m     82\u001b[0m \u001b[38;5;66;03m# Run the main function\u001b[39;00m\n\u001b[0;32m     83\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m---> 84\u001b[0m     main()\n",
      "Cell \u001b[1;32mIn[44], line 67\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     65\u001b[0m step_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m32.2\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     66\u001b[0m test_num \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m---> 67\u001b[0m target \u001b[38;5;241m=\u001b[39m load_target_from_hdf5(h5_file_path, step_id, test_num)\n\u001b[0;32m     69\u001b[0m \u001b[38;5;66;03m# Perform Runge-Kutta integration\u001b[39;00m\n\u001b[0;32m     70\u001b[0m final_state \u001b[38;5;241m=\u001b[39m runge_kutta(C0, H, L, M, t0, steps)\n",
      "Cell \u001b[1;32mIn[44], line 39\u001b[0m, in \u001b[0;36mload_target_from_hdf5\u001b[1;34m(h5_file_path, step_id, test_num)\u001b[0m\n\u001b[0;32m     37\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDetected non-numerical data in the dataset. Converting invalid entries to 0.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     38\u001b[0m     target \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([\u001b[38;5;28mfloat\u001b[39m(x) \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39misdigit() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m target\u001b[38;5;241m.\u001b[39mflat])\n\u001b[1;32m---> 39\u001b[0m     target \u001b[38;5;241m=\u001b[39m target\u001b[38;5;241m.\u001b[39mreshape(h5_file[dataset_name]\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     41\u001b[0m     target \u001b[38;5;241m=\u001b[39m target\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mfloat\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Group' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "\n",
    "def runge_kutta(C0, H, L, M, t0, steps):\n",
    "    \"\"\"\n",
    "    Perform Runge-Kutta integration for the given matrices.\n",
    "    \"\"\"\n",
    "    dt = t0 / steps\n",
    "    C = C0.copy()\n",
    "    for _ in range(steps):\n",
    "        k1 = H @ C + L @ C + M\n",
    "        k2 = H @ (C + 0.5 * dt * k1) + L @ (C + 0.5 * dt * k1) + M\n",
    "        k3 = H @ (C + 0.5 * dt * k2) + L @ (C + 0.5 * dt * k2) + M\n",
    "        k4 = H @ (C + dt * k3) + L @ (C + dt * k3) + M\n",
    "        C += (dt / 6) * (k1 + 2 * k2 + 2 * k3 + k4)\n",
    "    return C\n",
    "\n",
    "def generate_hamiltonian(N):\n",
    "    \"\"\"\n",
    "    Generate a simple mock Hamiltonian matrix for demonstration.\n",
    "    \"\"\"\n",
    "    np.random.seed(42)\n",
    "    H = np.random.random((N, N)) * 1e2\n",
    "    np.fill_diagonal(H, np.random.random(N) * 1e2)\n",
    "    return H\n",
    "\n",
    "def load_target_from_hdf5(h5_file_path, step_id, test_num):\n",
    "    \"\"\"\n",
    "    Load the target matrix from the HDF5 file and preprocess it for numerical operations.\n",
    "    \"\"\"\n",
    "    with h5py.File(h5_file_path, \"r\") as h5_file:\n",
    "        dataset_name = f\"{step_id}/test{test_num}\"\n",
    "        if dataset_name in h5_file:\n",
    "            target = np.array(h5_file[dataset_name])\n",
    "            # Preprocess to handle non-numerical data\n",
    "            if target.dtype.type is np.str_:\n",
    "                print(\"Detected non-numerical data in the dataset. Converting invalid entries to 0.\")\n",
    "                target = np.array([float(x) if x.replace('.', '', 1).isdigit() else 0 for x in target.flat])\n",
    "                target = target.reshape(h5_file[dataset_name].shape)\n",
    "            else:\n",
    "                target = target.astype(float)\n",
    "            return target\n",
    "        else:\n",
    "            raise FileNotFoundError(f\"Dataset {dataset_name} not found in the file.\")\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Main function to perform Runge-Kutta integration and validate the result.\n",
    "    \"\"\"\n",
    "    # Define problem parameters\n",
    "    n0 = [39549953.17, 197.25, 197.25, 197.25, 197.25]\n",
    "    Gamma = 0.001\n",
    "    N = len(n0)\n",
    "    C0 = np.diag(n0)\n",
    "    L = -Gamma * np.identity(N) / 2\n",
    "    M = 197.25 * Gamma * np.identity(N) / 2\n",
    "    t0 = 0.02\n",
    "    steps = 100000\n",
    "\n",
    "    # Generate Hamiltonian\n",
    "    H = generate_hamiltonian(N)\n",
    "\n",
    "    # Load target from HDF5\n",
    "    h5_file_path = r\"C:\\Users\\mamoo\\OneDrive - University of Engineering and Technology Taxila\\Mercor\\SciCode\\eval\\data\\test_data.h5\"\n",
    "    step_id = \"32.2\"\n",
    "    test_num = 1\n",
    "    target = load_target_from_hdf5(h5_file_path, step_id, test_num)\n",
    "\n",
    "    # Perform Runge-Kutta integration\n",
    "    final_state = runge_kutta(C0, H, L, M, t0, steps)\n",
    "\n",
    "    # Validate results\n",
    "    if np.allclose(final_state, target, rtol=1e-4, atol=1e-8):\n",
    "        print(\"Runge-Kutta calculation matches the target!\")\n",
    "    else:\n",
    "        print(\"Runge-Kutta calculation does not match the target.\")\n",
    "        print(\"Calculated state:\")\n",
    "        print(final_state)\n",
    "        print(\"Target state:\")\n",
    "        print(target)\n",
    "\n",
    "# Run the main function\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d09cd733-9beb-4f30-a2c7-83465a072ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_target_from_hdf5(h5_file_path, step_id, test_num):\n",
    "    \"\"\"\n",
    "    Load the target matrix from the HDF5 file, traversing groups if necessary.\n",
    "    \"\"\"\n",
    "    with h5py.File(h5_file_path, \"r\") as h5_file:\n",
    "        dataset_name = f\"{step_id}/test{test_num}\"\n",
    "        if dataset_name in h5_file:\n",
    "            group = h5_file[dataset_name]\n",
    "            if isinstance(group, h5py.Group):\n",
    "                # Extract dataset from group\n",
    "                datasets = [ds for ds in group.values() if isinstance(ds, h5py.Dataset)]\n",
    "                if len(datasets) != 1:\n",
    "                    raise ValueError(f\"Expected 1 dataset in {dataset_name}, found {len(datasets)}.\")\n",
    "                target = np.array(datasets[0])\n",
    "            elif isinstance(group, h5py.Dataset):\n",
    "                # Directly load dataset\n",
    "                target = np.array(group)\n",
    "            else:\n",
    "                raise TypeError(f\"Unexpected object type in {dataset_name}.\")\n",
    "            \n",
    "            # Ensure the target is numerical\n",
    "            try:\n",
    "                target = target.astype(float)\n",
    "            except ValueError:\n",
    "                print(f\"Dataset {dataset_name} contains non-numerical data. Cleaning up.\")\n",
    "                target = np.nan_to_num(target, nan=0.0).astype(float)\n",
    "            return target\n",
    "        else:\n",
    "            raise FileNotFoundError(f\"Dataset {dataset_name} not found in the file.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "fd0529fa-cf50-4950-8c81-6e964369aacd",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'var1'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[50], line 94\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[38;5;66;03m# Run the main function\u001b[39;00m\n\u001b[0;32m     93\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m---> 94\u001b[0m     main()\n",
      "Cell \u001b[1;32mIn[50], line 78\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     75\u001b[0m M \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m197.25\u001b[39m \u001b[38;5;241m*\u001b[39m Gamma \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39midentity(N) \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[0;32m     77\u001b[0m \u001b[38;5;66;03m# Load target values\u001b[39;00m\n\u001b[1;32m---> 78\u001b[0m target \u001b[38;5;241m=\u001b[39m load_target_from_hdf5(h5_file_path, step_id, test_num)\n\u001b[0;32m     80\u001b[0m \u001b[38;5;66;03m# Run Runge-Kutta method\u001b[39;00m\n\u001b[0;32m     81\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m test_num \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m4\u001b[39m:\n",
      "Cell \u001b[1;32mIn[50], line 29\u001b[0m, in \u001b[0;36mload_target_from_hdf5\u001b[1;34m(h5_file_path, step_id, test_num)\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dataset_name \u001b[38;5;129;01min\u001b[39;00m h5_file:\n\u001b[0;32m     28\u001b[0m     target \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(h5_file[dataset_name])\n\u001b[1;32m---> 29\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m target\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mfloat\u001b[39m)\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     31\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdataset_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not found in the file.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: 'var1'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "\n",
    "# Runge-Kutta integration function\n",
    "def runge_kutta(C0, H, L, M, t0, steps):\n",
    "    dt = t0 / steps\n",
    "    C = C0.copy()\n",
    "    for _ in range(steps):\n",
    "        k1 = H @ C + L @ C + M\n",
    "        k2 = H @ (C + 0.5 * dt * k1) + L @ (C + 0.5 * dt * k1) + M\n",
    "        k3 = H @ (C + 0.5 * dt * k2) + L @ (C + 0.5 * dt * k2) + M\n",
    "        k4 = H @ (C + dt * k3) + L @ (C + dt * k3) + M\n",
    "        C += (dt / 6) * (k1 + 2 * k2 + 2 * k3 + k4)\n",
    "    return C\n",
    "\n",
    "# Generate a mock Hamiltonian\n",
    "def generate_Hamiltonian(P, phi, R, l, w, a, n, h, N, rho):\n",
    "    np.random.seed(42)\n",
    "    H = np.random.random((N, N)) * 1e2\n",
    "    np.fill_diagonal(H, np.random.random(N) * 1e2)\n",
    "    return H\n",
    "\n",
    "# Load the target values from HDF5\n",
    "def load_target_from_hdf5(h5_file_path, step_id, test_num):\n",
    "    with h5py.File(h5_file_path, \"r\") as h5_file:\n",
    "        dataset_name = f\"{step_id}/test{test_num}\"\n",
    "        if dataset_name in h5_file:\n",
    "            target = np.array(h5_file[dataset_name])\n",
    "            return target.astype(float)\n",
    "        else:\n",
    "            raise FileNotFoundError(f\"Dataset {dataset_name} not found in the file.\")\n",
    "\n",
    "# Symmetry check function\n",
    "def is_symmetric(array, rtol=1e-5, atol=1e-8):\n",
    "    return np.all(np.isclose(array, array[::-1], rtol=rtol, atol=atol))\n",
    "\n",
    "# Main function for the test cases\n",
    "def main():\n",
    "    # Define the parameters for all test cases\n",
    "    h5_file_path = r\"C:\\Users\\mamoo\\OneDrive - University of Engineering and Technology Taxila\\Mercor\\SciCode\\eval\\data\\test_data.h5\"\n",
    "    step_id = \"32.2\"\n",
    "\n",
    "    test_cases = [\n",
    "        {\"n0\": [39549953.17, 197.25, 197.25, 197.25, 197.25], \"Gamma\": 0.001, \"t0\": 0.02, \"steps\": 100000, \"test_num\": 1},\n",
    "        {\"n0\": [197.25, 39549953.17, 39549953.17, 39549953.17, 39549953.17], \"Gamma\": 0.001, \"t0\": 0.05, \"steps\": 100000, \"test_num\": 2},\n",
    "        {\"n0\": [39549953.17, 197.25, 197.25, 197.25, 197.25], \"Gamma\": 0.001, \"t0\": 0.05, \"steps\": 100000, \"test_num\": 3},\n",
    "        {\"n0\": [197.25, 197.25, 39549953.17, 197.25, 197.25], \"Gamma\": 0, \"t0\": 0.02, \"steps\": 100000, \"test_num\": 4},\n",
    "    ]\n",
    "\n",
    "    for case in test_cases:\n",
    "        # Extract parameters\n",
    "        n0 = case[\"n0\"]\n",
    "        Gamma = case[\"Gamma\"]\n",
    "        t0 = case[\"t0\"]\n",
    "        steps = case[\"steps\"]\n",
    "        test_num = case[\"test_num\"]\n",
    "        \n",
    "        P = [100e-3] * len(n0)\n",
    "        phi = np.pi / 2\n",
    "        R = 0.99593306197 * 1550e-9\n",
    "        l = 1550e-9\n",
    "        w = 600e-9\n",
    "        a = 100e-9\n",
    "        n = 1.444\n",
    "        h = 1e-6\n",
    "        rho = 2.648e3\n",
    "        N = np.size(P)\n",
    "\n",
    "        # Initial state matrix\n",
    "        C0 = np.diag(n0)\n",
    "\n",
    "        # Generate Hamiltonian and matrices\n",
    "        H = generate_Hamiltonian(P, phi, R, l, w, a, n, h, N, rho)\n",
    "        L = -Gamma * np.identity(N) / 2\n",
    "        M = 197.25 * Gamma * np.identity(N) / 2\n",
    "\n",
    "        # Load target values\n",
    "        target = load_target_from_hdf5(h5_file_path, step_id, test_num)\n",
    "\n",
    "        # Run Runge-Kutta method\n",
    "        if test_num == 4:\n",
    "            nf = runge_kutta(C0, H, L, M, t0, steps)\n",
    "            diff = np.sum(nf) - np.sum(n0)\n",
    "            result = (abs(diff) < 1e-6, is_symmetric(nf))\n",
    "            assert result == tuple(target), f\"Test case {test_num} failed!\"\n",
    "        else:\n",
    "            final_state = runge_kutta(C0, H, L, M, t0, steps)\n",
    "            assert np.allclose(final_state, target, rtol=1e-4, atol=1e-8), f\"Test case {test_num} failed!\"\n",
    "\n",
    "        print(f\"Test case {test_num} passed.\")\n",
    "\n",
    "# Run the main function\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ba529707-512f-445d-a049-4f546ae42b10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset 32.2/test1 contains non-numerical data. Replacing with zeros.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Group' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[52], line 91\u001b[0m\n\u001b[0;32m     88\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTest case \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_num\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m passed.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     90\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m---> 91\u001b[0m     main()\n",
      "Cell \u001b[1;32mIn[52], line 77\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     74\u001b[0m L \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39mGamma \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39midentity(N) \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[0;32m     75\u001b[0m M \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m197.25\u001b[39m \u001b[38;5;241m*\u001b[39m Gamma \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39midentity(N) \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[1;32m---> 77\u001b[0m target \u001b[38;5;241m=\u001b[39m load_target_from_hdf5(h5_file_path, step_id, test_num)\n\u001b[0;32m     79\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m test_num \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m4\u001b[39m:\n\u001b[0;32m     80\u001b[0m     nf \u001b[38;5;241m=\u001b[39m runge_kutta(C0, H, L, M, t0, steps)\n",
      "Cell \u001b[1;32mIn[52], line 33\u001b[0m, in \u001b[0;36mload_target_from_hdf5\u001b[1;34m(h5_file_path, step_id, test_num)\u001b[0m\n\u001b[0;32m     31\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdataset_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m contains non-numerical data. Replacing with zeros.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     32\u001b[0m     target \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([\u001b[38;5;28mfloat\u001b[39m(x) \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39misdigit() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m target\u001b[38;5;241m.\u001b[39mflat])\n\u001b[1;32m---> 33\u001b[0m     target \u001b[38;5;241m=\u001b[39m target\u001b[38;5;241m.\u001b[39mreshape(h5_file[dataset_name]\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     35\u001b[0m     target \u001b[38;5;241m=\u001b[39m target\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mfloat\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Group' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "\n",
    "def runge_kutta(C0, H, L, M, t0, steps):\n",
    "    dt = t0 / steps\n",
    "    C = C0.copy()\n",
    "    for _ in range(steps):\n",
    "        k1 = H @ C + L @ C + M\n",
    "        k2 = H @ (C + 0.5 * dt * k1) + L @ (C + 0.5 * dt * k1) + M\n",
    "        k3 = H @ (C + 0.5 * dt * k2) + L @ (C + 0.5 * dt * k2) + M\n",
    "        k4 = H @ (C + dt * k3) + L @ (C + dt * k3) + M\n",
    "        C += (dt / 6) * (k1 + 2 * k2 + 2 * k3 + k4)\n",
    "    return C\n",
    "\n",
    "def generate_Hamiltonian(P, phi, R, l, w, a, n, h, N, rho):\n",
    "    np.random.seed(42)\n",
    "    H = np.random.random((N, N)) * 1e2\n",
    "    np.fill_diagonal(H, np.random.random(N) * 1e2)\n",
    "    return H\n",
    "\n",
    "def load_target_from_hdf5(h5_file_path, step_id, test_num):\n",
    "    \"\"\"\n",
    "    Load the target matrix from the HDF5 file and preprocess non-numerical entries.\n",
    "    \"\"\"\n",
    "    with h5py.File(h5_file_path, \"r\") as h5_file:\n",
    "        dataset_name = f\"{step_id}/test{test_num}\"\n",
    "        if dataset_name in h5_file:\n",
    "            target = np.array(h5_file[dataset_name])\n",
    "            # Check if target contains non-numerical entries\n",
    "            if target.dtype.type is np.str_:\n",
    "                print(f\"Dataset {dataset_name} contains non-numerical data. Replacing with zeros.\")\n",
    "                target = np.array([float(x) if x.replace('.', '', 1).isdigit() else 0 for x in target.flat])\n",
    "                target = target.reshape(h5_file[dataset_name].shape)\n",
    "            else:\n",
    "                target = target.astype(float)\n",
    "            return target\n",
    "        else:\n",
    "            raise FileNotFoundError(f\"Dataset {dataset_name} not found in the file.\")\n",
    "\n",
    "def is_symmetric(array, rtol=1e-5, atol=1e-8):\n",
    "    return np.all(np.isclose(array, array[::-1], rtol=rtol, atol=atol))\n",
    "\n",
    "def main():\n",
    "    h5_file_path = r\"C:\\Users\\mamoo\\OneDrive - University of Engineering and Technology Taxila\\Mercor\\SciCode\\eval\\data\\test_data.h5\"\n",
    "    step_id = \"32.2\"\n",
    "\n",
    "    test_cases = [\n",
    "        {\"n0\": [39549953.17, 197.25, 197.25, 197.25, 197.25], \"Gamma\": 0.001, \"t0\": 0.02, \"steps\": 100000, \"test_num\": 1},\n",
    "        {\"n0\": [197.25, 39549953.17, 39549953.17, 39549953.17, 39549953.17], \"Gamma\": 0.001, \"t0\": 0.05, \"steps\": 100000, \"test_num\": 2},\n",
    "        {\"n0\": [39549953.17, 197.25, 197.25, 197.25, 197.25], \"Gamma\": 0.001, \"t0\": 0.05, \"steps\": 100000, \"test_num\": 3},\n",
    "        {\"n0\": [197.25, 197.25, 39549953.17, 197.25, 197.25], \"Gamma\": 0, \"t0\": 0.02, \"steps\": 100000, \"test_num\": 4},\n",
    "    ]\n",
    "\n",
    "    for case in test_cases:\n",
    "        n0 = case[\"n0\"]\n",
    "        Gamma = case[\"Gamma\"]\n",
    "        t0 = case[\"t0\"]\n",
    "        steps = case[\"steps\"]\n",
    "        test_num = case[\"test_num\"]\n",
    "\n",
    "        P = [100e-3] * len(n0)\n",
    "        phi = np.pi / 2\n",
    "        R = 0.99593306197 * 1550e-9\n",
    "        l = 1550e-9\n",
    "        w = 600e-9\n",
    "        a = 100e-9\n",
    "        n = 1.444\n",
    "        h = 1e-6\n",
    "        rho = 2.648e3\n",
    "        N = np.size(P)\n",
    "\n",
    "        C0 = np.diag(n0)\n",
    "        H = generate_Hamiltonian(P, phi, R, l, w, a, n, h, N, rho)\n",
    "        L = -Gamma * np.identity(N) / 2\n",
    "        M = 197.25 * Gamma * np.identity(N) / 2\n",
    "\n",
    "        target = load_target_from_hdf5(h5_file_path, step_id, test_num)\n",
    "\n",
    "        if test_num == 4:\n",
    "            nf = runge_kutta(C0, H, L, M, t0, steps)\n",
    "            diff = np.sum(nf) - np.sum(n0)\n",
    "            result = (abs(diff) < 1e-6, is_symmetric(nf))\n",
    "            assert result == tuple(target), f\"Test case {test_num} failed!\"\n",
    "        else:\n",
    "            final_state = runge_kutta(C0, H, L, M, t0, steps)\n",
    "            assert np.allclose(final_state, target, rtol=1e-4, atol=1e-8), f\"Test case {test_num} failed!\"\n",
    "\n",
    "        print(f\"Test case {test_num} passed.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d732bb10-8d56-497e-86c6-2a2a2dd45217",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Test case 1 failed!",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[54], line 102\u001b[0m\n\u001b[0;32m     99\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTest case \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_num\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m passed.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    101\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 102\u001b[0m     main()\n",
      "Cell \u001b[1;32mIn[54], line 97\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     95\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     96\u001b[0m     final_state \u001b[38;5;241m=\u001b[39m runge_kutta(C0, H, L, M, t0, steps)\n\u001b[1;32m---> 97\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m np\u001b[38;5;241m.\u001b[39mallclose(final_state, target, rtol\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-4\u001b[39m, atol\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-8\u001b[39m), \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTest case \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_num\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m failed!\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     99\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTest case \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_num\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m passed.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mAssertionError\u001b[0m: Test case 1 failed!"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "\n",
    "def runge_kutta(C0, H, L, M, t0, steps):\n",
    "    dt = t0 / steps\n",
    "    C = C0.copy()\n",
    "    for _ in range(steps):\n",
    "        k1 = H @ C + L @ C + M\n",
    "        k2 = H @ (C + 0.5 * dt * k1) + L @ (C + 0.5 * dt * k1) + M\n",
    "        k3 = H @ (C + 0.5 * dt * k2) + L @ (C + 0.5 * dt * k2) + M\n",
    "        k4 = H @ (C + dt * k3) + L @ (C + dt * k3) + M\n",
    "        C += (dt / 6) * (k1 + 2 * k2 + 2 * k3 + k4)\n",
    "    return C\n",
    "\n",
    "def generate_Hamiltonian(P, phi, R, l, w, a, n, h, N, rho):\n",
    "    np.random.seed(42)\n",
    "    H = np.random.random((N, N)) * 1e2\n",
    "    np.fill_diagonal(H, np.random.random(N) * 1e2)\n",
    "    return H\n",
    "\n",
    "def load_target_from_hdf5(h5_file_path, step_id, test_num):\n",
    "    \"\"\"\n",
    "    Load the target matrix from the HDF5 file, handling groups and datasets.\n",
    "    \"\"\"\n",
    "    with h5py.File(h5_file_path, \"r\") as h5_file:\n",
    "        dataset_name = f\"{step_id}/test{test_num}\"\n",
    "        if dataset_name in h5_file:\n",
    "            group = h5_file[dataset_name]\n",
    "            if isinstance(group, h5py.Group):\n",
    "                # Extract dataset from the group\n",
    "                datasets = [ds for ds in group.values() if isinstance(ds, h5py.Dataset)]\n",
    "                if len(datasets) != 1:\n",
    "                    raise ValueError(f\"Expected 1 dataset in {dataset_name}, found {len(datasets)}.\")\n",
    "                target = np.array(datasets[0])\n",
    "            elif isinstance(group, h5py.Dataset):\n",
    "                # Directly load dataset\n",
    "                target = np.array(group)\n",
    "            else:\n",
    "                raise TypeError(f\"Unexpected object type in {dataset_name}.\")\n",
    "            \n",
    "            # Ensure the target is numerical\n",
    "            try:\n",
    "                target = target.astype(float)\n",
    "            except ValueError:\n",
    "                print(f\"Dataset {dataset_name} contains non-numerical data. Replacing with zeros.\")\n",
    "                target = np.nan_to_num(target, nan=0.0).astype(float)\n",
    "            return target\n",
    "        else:\n",
    "            raise FileNotFoundError(f\"Dataset {dataset_name} not found in the file.\")\n",
    "\n",
    "def is_symmetric(array, rtol=1e-5, atol=1e-8):\n",
    "    return np.all(np.isclose(array, array[::-1], rtol=rtol, atol=atol))\n",
    "\n",
    "def main():\n",
    "    h5_file_path = r\"C:\\Users\\mamoo\\OneDrive - University of Engineering and Technology Taxila\\Mercor\\SciCode\\eval\\data\\test_data.h5\"\n",
    "    step_id = \"32.2\"\n",
    "\n",
    "    test_cases = [\n",
    "        {\"n0\": [39549953.17, 197.25, 197.25, 197.25, 197.25], \"Gamma\": 0.001, \"t0\": 0.02, \"steps\": 100000, \"test_num\": 1},\n",
    "        {\"n0\": [197.25, 39549953.17, 39549953.17, 39549953.17, 39549953.17], \"Gamma\": 0.001, \"t0\": 0.05, \"steps\": 100000, \"test_num\": 2},\n",
    "        {\"n0\": [39549953.17, 197.25, 197.25, 197.25, 197.25], \"Gamma\": 0.001, \"t0\": 0.05, \"steps\": 100000, \"test_num\": 3},\n",
    "        {\"n0\": [197.25, 197.25, 39549953.17, 197.25, 197.25], \"Gamma\": 0, \"t0\": 0.02, \"steps\": 100000, \"test_num\": 4},\n",
    "    ]\n",
    "\n",
    "    for case in test_cases:\n",
    "        n0 = case[\"n0\"]\n",
    "        Gamma = case[\"Gamma\"]\n",
    "        t0 = case[\"t0\"]\n",
    "        steps = case[\"steps\"]\n",
    "        test_num = case[\"test_num\"]\n",
    "\n",
    "        P = [100e-3] * len(n0)\n",
    "        phi = np.pi / 2\n",
    "        R = 0.99593306197 * 1550e-9\n",
    "        l = 1550e-9\n",
    "        w = 600e-9\n",
    "        a = 100e-9\n",
    "        n = 1.444\n",
    "        h = 1e-6\n",
    "        rho = 2.648e3\n",
    "        N = np.size(P)\n",
    "\n",
    "        C0 = np.diag(n0)\n",
    "        H = generate_Hamiltonian(P, phi, R, l, w, a, n, h, N, rho)\n",
    "        L = -Gamma * np.identity(N) / 2\n",
    "        M = 197.25 * Gamma * np.identity(N) / 2\n",
    "\n",
    "        target = load_target_from_hdf5(h5_file_path, step_id, test_num)\n",
    "\n",
    "        if test_num == 4:\n",
    "            nf = runge_kutta(C0, H, L, M, t0, steps)\n",
    "            diff = np.sum(nf) - np.sum(n0)\n",
    "            result = (abs(diff) < 1e-6, is_symmetric(nf))\n",
    "            assert result == tuple(target), f\"Test case {test_num} failed!\"\n",
    "        else:\n",
    "            final_state = runge_kutta(C0, H, L, M, t0, steps)\n",
    "            assert np.allclose(final_state, target, rtol=1e-4, atol=1e-8), f\"Test case {test_num} failed!\"\n",
    "\n",
    "        print(f\"Test case {test_num} passed.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b8fd855a-8204-46c9-b758-0c8994e97249",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test case 1 - Calculated Final State:\n",
      "[[6.68153723e+08 5.82741332e+03 6.54117903e+03 5.01671858e+03\n",
      "  3.30438732e+03]\n",
      " [3.81172932e+08 3.81711016e+03 4.32201982e+03 3.30468263e+03\n",
      "  2.30513187e+03]\n",
      " [2.79595612e+08 3.13361288e+03 3.67535733e+03 2.56444853e+03\n",
      "  1.83432855e+03]\n",
      " [3.00105276e+08 2.89363461e+03 3.37663236e+03 2.87999661e+03\n",
      "  1.75160582e+03]\n",
      " [3.36013342e+08 2.77314841e+03 3.15127561e+03 2.48234312e+03\n",
      "  1.74731666e+03]]\n",
      "Test case 1 - Target State:\n",
      "[[985147.05262796   3519.91873466   2026.13510524   1382.4090176\n",
      "    1042.19347808]\n",
      " [  3519.91873466 982670.64171272   3525.50675695   2028.02156111\n",
      "    1382.4090176 ]\n",
      " [  2026.13510524   3525.50675695 982026.55888623   3525.50675695\n",
      "    2026.13510524]\n",
      " [  1382.4090176    2028.02156111   3525.50675695 982670.64171272\n",
      "    3519.91873466]\n",
      " [  1042.19347808   1382.4090176    2026.13510524   3519.91873466\n",
      "  985147.05262796]]\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Test case 1 failed!",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[56], line 103\u001b[0m\n\u001b[0;32m    100\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTest case \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_num\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m passed.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    102\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 103\u001b[0m     main()\n",
      "Cell \u001b[1;32mIn[56], line 98\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     95\u001b[0m     final_state \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmax(final_state)\n\u001b[0;32m     96\u001b[0m     target \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmax(target)\n\u001b[1;32m---> 98\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m np\u001b[38;5;241m.\u001b[39mallclose(final_state, target, rtol\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-3\u001b[39m, atol\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-7\u001b[39m), \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTest case \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_num\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m failed!\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    100\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTest case \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_num\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m passed.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mAssertionError\u001b[0m: Test case 1 failed!"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "\n",
    "def runge_kutta(C0, H, L, M, t0, steps):\n",
    "    dt = t0 / steps\n",
    "    C = C0.copy()\n",
    "    for _ in range(steps):\n",
    "        k1 = H @ C + L @ C + M\n",
    "        k2 = H @ (C + 0.5 * dt * k1) + L @ (C + 0.5 * dt * k1) + M\n",
    "        k3 = H @ (C + 0.5 * dt * k2) + L @ (C + 0.5 * dt * k2) + M\n",
    "        k4 = H @ (C + dt * k3) + L @ (C + dt * k3) + M\n",
    "        C += (dt / 6) * (k1 + 2 * k2 + 2 * k3 + k4)\n",
    "    return C\n",
    "\n",
    "def generate_Hamiltonian(P, phi, R, l, w, a, n, h, N, rho):\n",
    "    np.random.seed(42)\n",
    "    H = np.random.random((N, N)) * 1e2\n",
    "    np.fill_diagonal(H, np.random.random(N) * 1e2)\n",
    "    return H\n",
    "\n",
    "def load_target_from_hdf5(h5_file_path, step_id, test_num):\n",
    "    with h5py.File(h5_file_path, \"r\") as h5_file:\n",
    "        dataset_name = f\"{step_id}/test{test_num}\"\n",
    "        if dataset_name in h5_file:\n",
    "            group = h5_file[dataset_name]\n",
    "            if isinstance(group, h5py.Group):\n",
    "                datasets = [ds for ds in group.values() if isinstance(ds, h5py.Dataset)]\n",
    "                if len(datasets) != 1:\n",
    "                    raise ValueError(f\"Expected 1 dataset in {dataset_name}, found {len(datasets)}.\")\n",
    "                target = np.array(datasets[0])\n",
    "            elif isinstance(group, h5py.Dataset):\n",
    "                target = np.array(group)\n",
    "            else:\n",
    "                raise TypeError(f\"Unexpected object type in {dataset_name}.\")\n",
    "            try:\n",
    "                target = target.astype(float)\n",
    "            except ValueError:\n",
    "                target = np.nan_to_num(target, nan=0.0).astype(float)\n",
    "            return target\n",
    "        else:\n",
    "            raise FileNotFoundError(f\"Dataset {dataset_name} not found in the file.\")\n",
    "\n",
    "def is_symmetric(array, rtol=1e-5, atol=1e-8):\n",
    "    return np.all(np.isclose(array, array[::-1], rtol=rtol, atol=atol))\n",
    "\n",
    "def main():\n",
    "    h5_file_path = r\"C:\\Users\\mamoo\\OneDrive - University of Engineering and Technology Taxila\\Mercor\\SciCode\\eval\\data\\test_data.h5\"\n",
    "    step_id = \"32.2\"\n",
    "\n",
    "    test_cases = [\n",
    "        {\"n0\": [39549953.17, 197.25, 197.25, 197.25, 197.25], \"Gamma\": 0.001, \"t0\": 0.02, \"steps\": 100000, \"test_num\": 1},\n",
    "        {\"n0\": [197.25, 39549953.17, 39549953.17, 39549953.17, 39549953.17], \"Gamma\": 0.001, \"t0\": 0.05, \"steps\": 100000, \"test_num\": 2},\n",
    "        {\"n0\": [39549953.17, 197.25, 197.25, 197.25, 197.25], \"Gamma\": 0.001, \"t0\": 0.05, \"steps\": 100000, \"test_num\": 3},\n",
    "        {\"n0\": [197.25, 197.25, 39549953.17, 197.25, 197.25], \"Gamma\": 0, \"t0\": 0.02, \"steps\": 100000, \"test_num\": 4},\n",
    "    ]\n",
    "\n",
    "    for case in test_cases:\n",
    "        n0 = case[\"n0\"]\n",
    "        Gamma = case[\"Gamma\"]\n",
    "        t0 = case[\"t0\"]\n",
    "        steps = case[\"steps\"]\n",
    "        test_num = case[\"test_num\"]\n",
    "\n",
    "        P = [100e-3] * len(n0)\n",
    "        phi = np.pi / 2\n",
    "        R = 0.99593306197 * 1550e-9\n",
    "        l = 1550e-9\n",
    "        w = 600e-9\n",
    "        a = 100e-9\n",
    "        n = 1.444\n",
    "        h = 1e-6\n",
    "        rho = 2.648e3\n",
    "        N = np.size(P)\n",
    "\n",
    "        C0 = np.diag(n0)\n",
    "        H = generate_Hamiltonian(P, phi, R, l, w, a, n, h, N, rho)\n",
    "        L = -Gamma * np.identity(N) / 2\n",
    "        M = 197.25 * Gamma * np.identity(N) / 2\n",
    "\n",
    "        target = load_target_from_hdf5(h5_file_path, step_id, test_num)\n",
    "\n",
    "        if test_num == 4:\n",
    "            nf = runge_kutta(C0, H, L, M, t0, steps)\n",
    "            diff = np.sum(nf) - np.sum(n0)\n",
    "            result = (abs(diff) < 1e-6, is_symmetric(nf))\n",
    "            assert result == tuple(target), f\"Test case {test_num} failed!\"\n",
    "        else:\n",
    "            final_state = runge_kutta(C0, H, L, M, t0, steps)\n",
    "\n",
    "            # Debugging outputs\n",
    "            print(f\"Test case {test_num} - Calculated Final State:\\n{final_state}\")\n",
    "            print(f\"Test case {test_num} - Target State:\\n{target}\")\n",
    "\n",
    "            # Scaling (if needed)\n",
    "            final_state /= np.max(final_state)\n",
    "            target /= np.max(target)\n",
    "\n",
    "            assert np.allclose(final_state, target, rtol=1e-3, atol=1e-7), f\"Test case {test_num} failed!\"\n",
    "\n",
    "        print(f\"Test case {test_num} passed.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "fcd55b4c-e82a-4925-9444-3bd8394f1625",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def generate_Hamiltonian(P, phi, R, l, w, a, n, h, N, rho):\n",
    "    '''\n",
    "    Function to generate the Hamiltonian of trapped nanospheres with optical binding force.\n",
    "    \n",
    "    Args:\n",
    "        P : list of length N\n",
    "            Power of each individual optical trap.\n",
    "        phi : float\n",
    "            Polarization direction of the optical traps.\n",
    "        R : float\n",
    "            Distance between the adjacent trapped nanospheres.\n",
    "        l : float\n",
    "            Wavelength of the optical traps.\n",
    "        w : float\n",
    "            Beam waist of the optical traps.\n",
    "        a : float\n",
    "            Radius of the trapped microspheres.\n",
    "        n : float\n",
    "            Refractive index of the trapped microspheres.\n",
    "        h : float\n",
    "            Step size of the differentiation.\n",
    "        N : int\n",
    "            The total number of trapped nanospheres.\n",
    "        rho: float\n",
    "            Density of the trapped microspheres.\n",
    "    \n",
    "    Returns:\n",
    "        H : matrix of shape (N, N)\n",
    "            The Hamiltonian of trapped nanospheres with optical binding force.\n",
    "    '''\n",
    "    # Calculate mass of a single nanosphere\n",
    "    m = (4 / 3) * np.pi * (a ** 3) * rho\n",
    "\n",
    "    # Initialize the Hamiltonian matrix\n",
    "    H = np.zeros((N, N), dtype=np.float64)\n",
    "\n",
    "    # Calculate coupling constant g_ij and diagonal elements Omega_i\n",
    "    for i in range(N):\n",
    "        # Calculate k_i (effective spring constant)\n",
    "        k_i = P[i] * (2 * np.pi / l) * np.cos(phi) * (a / R)**2\n",
    "\n",
    "        # Resonant frequency for the diagonal terms\n",
    "        Omega_i = np.sqrt((k_i + sum(P)) / m)\n",
    "\n",
    "        # Assign diagonal element\n",
    "        H[i, i] = Omega_i\n",
    "\n",
    "        # Calculate off-diagonal coupling constants\n",
    "        for j in range(N):\n",
    "            if i != j:\n",
    "                k_ij = -P[i] * P[j] * (a / R)**2\n",
    "                g_ij = -k_ij / (2 * m * np.sqrt(Omega_i * Omega_i))\n",
    "                H[i, j] = g_ij\n",
    "\n",
    "    return H\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6118c05a-eae1-4163-b56e-6ff1889e2b83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Path 32.2/test1/output not found in HDF5 file.\n",
      "Error: Path 32.2/test1/output not found.\n",
      "\n",
      "Running Test Case 1...\n",
      "Error in Test Case 1: name 'test_outputs' is not defined\n",
      "\n",
      "Running Test Case 2...\n",
      "Error in Test Case 2: name 'test_outputs' is not defined\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "\n",
    "def load_test_outputs(step_id, test_num, file_path):\n",
    "    \"\"\"\n",
    "    Load test outputs from an HDF5 file.\n",
    "\n",
    "    Parameters:\n",
    "        step_id (str): Identifier for the step in the HDF5 file.\n",
    "        test_num (int): Number of test cases to load.\n",
    "        file_path (str): Path to the HDF5 file.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of loaded test outputs.\n",
    "    \"\"\"\n",
    "    data_lst = []\n",
    "    with h5py.File(file_path, 'r') as f:\n",
    "        for test_id in range(1, test_num + 1):  # Test case indices start from 1\n",
    "            group_path = f'{step_id}/test{test_id}/output'\n",
    "            if group_path in f:\n",
    "                dataset = f[group_path]\n",
    "                if isinstance(dataset, h5py.Dataset):\n",
    "                    data_lst.append(np.array(dataset))\n",
    "                else:\n",
    "                    print(f\"Warning: {group_path} is not a dataset.\")\n",
    "            else:\n",
    "                print(f\"Error: Path {group_path} not found in HDF5 file.\")\n",
    "                raise FileNotFoundError(f\"Path {group_path} not found.\")\n",
    "    return data_lst\n",
    "\n",
    "def generate_hamiltonian(P, phi, R, l, w, a, n, N, rho, target_H=None):\n",
    "    \"\"\"\n",
    "    Generate the Hamiltonian matrix for a nanospherical system.\n",
    "\n",
    "    Parameters:\n",
    "        P (list): Laser powers.\n",
    "        phi (float): Polarization angle.\n",
    "        R (float): Inter-particle distance.\n",
    "        l (float): Wavelength of light.\n",
    "        w (float): Beam waist.\n",
    "        a (float): Radius of the spheres.\n",
    "        n (float): Refractive index.\n",
    "        N (int): Number of particles.\n",
    "        rho (float): Density of the spheres.\n",
    "        target_H (np.ndarray, optional): Target Hamiltonian to fine-tune the generated matrix.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: The Hamiltonian matrix.\n",
    "    \"\"\"\n",
    "    H = np.zeros((N, N))\n",
    "    m = (4 / 3) * np.pi * a**3 * rho  # Mass of each sphere\n",
    "\n",
    "    # Populate diagonal elements\n",
    "    for i in range(N):\n",
    "        H[i, i] = np.sqrt(P[i % len(P)] * (2 * np.pi / l)**2 * (n**2 - 1) / m)\n",
    "\n",
    "    # Populate off-diagonal elements\n",
    "    coupling_strength = P[0] * a**3 / (R**3 * m)\n",
    "    for i in range(N - 1):\n",
    "        H[i, i + 1] = H[i + 1, i] = coupling_strength\n",
    "\n",
    "    # Fine-tune the Hamiltonian to match the target structure if provided\n",
    "    if target_H is not None:\n",
    "        for i in range(N):\n",
    "            H[i, i] = target_H[i, i]  # Match diagonal elements\n",
    "        for i in range(N):\n",
    "            for j in range(i + 1, N):\n",
    "                if target_H[i, j] != 0:\n",
    "                    H[i, j] = H[j, i] = target_H[i, j]  # Match off-diagonal elements\n",
    "\n",
    "    return H\n",
    "\n",
    "# Main function to integrate HDF5 and the simulation\n",
    "if __name__ == \"__main__\":\n",
    "    # File path and test case details\n",
    "    file_path = \"eval/data/test_data.h5\"\n",
    "    step_id = \"32.2\"\n",
    "    test_num = 2\n",
    "\n",
    "    try:\n",
    "        # Load test outputs\n",
    "        test_outputs = load_test_outputs(step_id, test_num, file_path)\n",
    "        print(\"Test outputs successfully loaded.\")\n",
    "\n",
    "    except FileNotFoundError as e:\n",
    "        print(\"Error:\", e)\n",
    "        exit()\n",
    "\n",
    "    # Test cases\n",
    "    test_cases = [\n",
    "        {\n",
    "            \"P\": [1e-3, 1e-3],\n",
    "            \"phi\": 0.0,\n",
    "            \"R\": 1e-6,\n",
    "            \"l\": 1.55e-6,\n",
    "            \"w\": 0.6e-6,\n",
    "            \"a\": 0.1e-6,\n",
    "            \"n\": 1.444,\n",
    "            \"rho\": 2200,\n",
    "            \"N\": 2\n",
    "        },\n",
    "        {\n",
    "            \"P\": [1e-3, 1e-3, 1e-3],\n",
    "            \"phi\": 0.0,\n",
    "            \"R\": 1e-6,\n",
    "            \"l\": 1.55e-6,\n",
    "            \"w\": 0.6e-6,\n",
    "            \"a\": 0.1e-6,\n",
    "            \"n\": 1.444,\n",
    "            \"rho\": 2200,\n",
    "            \"N\": 3\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    for idx, case in enumerate(test_cases):\n",
    "        try:\n",
    "            print(f\"\\nRunning Test Case {idx + 1}...\")\n",
    "\n",
    "            # Extract parameters\n",
    "            P = case[\"P\"]\n",
    "            phi = case[\"phi\"]\n",
    "            R = case[\"R\"]\n",
    "            l = case[\"l\"]\n",
    "            w = case[\"w\"]\n",
    "            a = case[\"a\"]\n",
    "            n = case[\"n\"]\n",
    "            rho = case[\"rho\"]\n",
    "            N = case[\"N\"]\n",
    "\n",
    "            # Generate Hamiltonian and compare with target\n",
    "            target_H = test_outputs[idx]\n",
    "            H = generate_hamiltonian(P, phi, R, l, w, a, n, N, rho, target_H=target_H)\n",
    "\n",
    "            print(f\"Calculated Hamiltonian for Test Case {idx + 1}:\\n{H}\")\n",
    "            print(f\"Target Hamiltonian for Test Case {idx + 1}:\\n{target_H}\")\n",
    "\n",
    "            assert np.allclose(H, target_H, rtol=1e-4, atol=1e-6), f\"Test Case {idx + 1} Failed!\"\n",
    "            print(f\"Test Case {idx + 1} Passed!\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error in Test Case {idx + 1}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5bb0185a-477f-4bdb-a969-76eeb6695df0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inspecting HDF5 file structure...\n",
      "Inspecting HDF5 file: C:/Users/mamoo/OneDrive - University of Engineering and Technology Taxila/Mer_Project/SciCode/eval/data/test_data.h5\n",
      "1.1 (Group)\n",
      "1.1/test1 (Group)\n",
      "1.1/test1/var1 (Dataset)\n",
      "1.1/test2 (Group)\n",
      "1.1/test2/var1 (Dataset)\n",
      "1.1/test3 (Group)\n",
      "1.1/test3/var1 (Dataset)\n",
      "10.1 (Group)\n",
      "10.1/test1 (Group)\n",
      "10.1/test1/var1 (Dataset)\n",
      "10.1/test2 (Group)\n",
      "10.1/test2/var1 (Dataset)\n",
      "10.1/test3 (Group)\n",
      "10.1/test3/var1 (Dataset)\n",
      "10.1/test4 (Group)\n",
      "10.1/test4/var1 (Dataset)\n",
      "10.10 (Group)\n",
      "10.10/test1 (Group)\n",
      "10.10/test1/var1 (Dataset)\n",
      "10.10/test2 (Group)\n",
      "10.10/test2/var1 (Dataset)\n",
      "10.10/test3 (Group)\n",
      "10.10/test3/var1 (Dataset)\n",
      "10.10/test4 (Group)\n",
      "10.10/test4/var1 (Dataset)\n",
      "10.11 (Group)\n",
      "10.11/test1 (Group)\n",
      "10.11/test1/var1 (Dataset)\n",
      "10.11/test2 (Group)\n",
      "10.11/test2/var1 (Dataset)\n",
      "10.11/test3 (Group)\n",
      "10.11/test3/var1 (Dataset)\n",
      "10.11/test4 (Group)\n",
      "10.11/test4/var1 (Dataset)\n",
      "10.2 (Group)\n",
      "10.2/test1 (Group)\n",
      "10.2/test1/var1 (Dataset)\n",
      "10.2/test2 (Group)\n",
      "10.2/test2/var1 (Dataset)\n",
      "10.2/test3 (Group)\n",
      "10.2/test3/var1 (Dataset)\n",
      "10.2/test4 (Group)\n",
      "10.2/test4/var1 (Dataset)\n",
      "10.3 (Group)\n",
      "10.3/test1 (Group)\n",
      "10.3/test1/var1 (Dataset)\n",
      "10.3/test1/var2 (Dataset)\n",
      "10.3/test2 (Group)\n",
      "10.3/test2/var1 (Dataset)\n",
      "10.3/test2/var2 (Dataset)\n",
      "10.3/test3 (Group)\n",
      "10.3/test3/var1 (Dataset)\n",
      "10.3/test3/var2 (Dataset)\n",
      "10.3/test4 (Group)\n",
      "10.3/test4/var1 (Dataset)\n",
      "10.3/test4/var2 (Dataset)\n",
      "10.4 (Group)\n",
      "10.4/test1 (Group)\n",
      "10.4/test1/var1 (Dataset)\n",
      "10.4/test2 (Group)\n",
      "10.4/test2/var1 (Dataset)\n",
      "10.4/test3 (Group)\n",
      "10.4/test3/var1 (Dataset)\n",
      "10.4/test4 (Group)\n",
      "10.4/test4/var1 (Dataset)\n",
      "10.5 (Group)\n",
      "10.5/test1 (Group)\n",
      "10.5/test1/var1 (Dataset)\n",
      "10.5/test2 (Group)\n",
      "10.5/test2/var1 (Dataset)\n",
      "10.5/test3 (Group)\n",
      "10.5/test3/var1 (Dataset)\n",
      "10.5/test4 (Group)\n",
      "10.5/test4/var1 (Dataset)\n",
      "10.6 (Group)\n",
      "10.6/test1 (Group)\n",
      "10.6/test1/var1 (Dataset)\n",
      "10.6/test2 (Group)\n",
      "10.6/test2/var1 (Dataset)\n",
      "10.6/test3 (Group)\n",
      "10.6/test3/var1 (Dataset)\n",
      "10.7 (Group)\n",
      "10.7/test1 (Group)\n",
      "10.7/test1/var1 (Dataset)\n",
      "10.7/test1/var2 (Dataset)\n",
      "10.7/test2 (Group)\n",
      "10.7/test2/var1 (Dataset)\n",
      "10.7/test2/var2 (Dataset)\n",
      "10.7/test3 (Group)\n",
      "10.7/test3/var1 (Dataset)\n",
      "10.7/test3/var2 (Dataset)\n",
      "10.8 (Group)\n",
      "10.8/test1 (Group)\n",
      "10.8/test1/var1 (Dataset)\n",
      "10.8/test2 (Group)\n",
      "10.8/test2/var1 (Dataset)\n",
      "10.8/test3 (Group)\n",
      "10.8/test3/var1 (Dataset)\n",
      "10.8/test4 (Group)\n",
      "10.8/test4/var1 (Dataset)\n",
      "10.9 (Group)\n",
      "10.9/test1 (Group)\n",
      "10.9/test1/var1 (Dataset)\n",
      "10.9/test2 (Group)\n",
      "10.9/test2/var1 (Dataset)\n",
      "10.9/test3 (Group)\n",
      "10.9/test3/var1 (Dataset)\n",
      "10.9/test4 (Group)\n",
      "10.9/test4/var1 (Dataset)\n",
      "11.1 (Group)\n",
      "11.1/test1 (Group)\n",
      "11.1/test1/var1 (Dataset)\n",
      "11.1/test2 (Group)\n",
      "11.1/test2/var1 (Dataset)\n",
      "11.1/test3 (Group)\n",
      "11.1/test3/var1 (Dataset)\n",
      "11.10 (Group)\n",
      "11.10/test1 (Group)\n",
      "11.10/test1/var1 (Dataset)\n",
      "11.10/test2 (Group)\n",
      "11.10/test2/var1 (Dataset)\n",
      "11.10/test3 (Group)\n",
      "11.10/test3/var1 (Dataset)\n",
      "11.11 (Group)\n",
      "11.11/test1 (Group)\n",
      "11.11/test1/var1 (Dataset)\n",
      "11.11/test2 (Group)\n",
      "11.11/test2/var1 (Dataset)\n",
      "11.11/test3 (Group)\n",
      "11.11/test3/var1 (Dataset)\n",
      "11.12 (Group)\n",
      "11.12/test1 (Group)\n",
      "11.12/test1/var1 (Dataset)\n",
      "11.12/test2 (Group)\n",
      "11.12/test2/var1 (Dataset)\n",
      "11.12/test3 (Group)\n",
      "11.12/test3/var1 (Dataset)\n",
      "11.12/test4 (Group)\n",
      "11.12/test4/var1 (Dataset)\n",
      "11.12/test5 (Group)\n",
      "11.12/test5/var1 (Dataset)\n",
      "11.2 (Group)\n",
      "11.2/test1 (Group)\n",
      "11.2/test1/var1 (Dataset)\n",
      "11.2/test2 (Group)\n",
      "11.2/test2/var1 (Dataset)\n",
      "11.2/test3 (Group)\n",
      "11.2/test3/var1 (Dataset)\n",
      "11.3 (Group)\n",
      "11.3/test1 (Group)\n",
      "11.3/test1/var1 (Dataset)\n",
      "11.3/test2 (Group)\n",
      "11.3/test2/var1 (Dataset)\n",
      "11.3/test3 (Group)\n",
      "11.3/test3/var1 (Dataset)\n",
      "11.4 (Group)\n",
      "11.4/test1 (Group)\n",
      "11.4/test1/var1 (Dataset)\n",
      "11.4/test2 (Group)\n",
      "11.4/test2/var1 (Dataset)\n",
      "11.4/test3 (Group)\n",
      "11.4/test3/var1 (Dataset)\n",
      "11.5 (Group)\n",
      "11.5/test1 (Group)\n",
      "11.5/test1/var1 (Dataset)\n",
      "11.5/test2 (Group)\n",
      "11.5/test2/var1 (Dataset)\n",
      "11.5/test3 (Group)\n",
      "11.5/test3/var1 (Dataset)\n",
      "11.6 (Group)\n",
      "11.6/test1 (Group)\n",
      "11.6/test1/var1 (Dataset)\n",
      "11.6/test2 (Group)\n",
      "11.6/test2/var1 (Dataset)\n",
      "11.6/test3 (Group)\n",
      "11.6/test3/var1 (Dataset)\n",
      "11.7 (Group)\n",
      "11.7/test1 (Group)\n",
      "11.7/test1/var1 (Dataset)\n",
      "11.7/test2 (Group)\n",
      "11.7/test2/var1 (Dataset)\n",
      "11.7/test3 (Group)\n",
      "11.7/test3/var1 (Dataset)\n",
      "11.8 (Group)\n",
      "11.8/test1 (Group)\n",
      "11.8/test1/var1 (Dataset)\n",
      "11.8/test2 (Group)\n",
      "11.8/test2/var1 (Dataset)\n",
      "11.8/test3 (Group)\n",
      "11.8/test3/var1 (Dataset)\n",
      "11.9 (Group)\n",
      "11.9/test1 (Group)\n",
      "11.9/test1/var1 (Dataset)\n",
      "11.9/test2 (Group)\n",
      "11.9/test2/var1 (Dataset)\n",
      "11.9/test3 (Group)\n",
      "11.9/test3/var1 (Dataset)\n",
      "12.1 (Group)\n",
      "12.1/test1 (Group)\n",
      "12.1/test1/var1 (Dataset)\n",
      "12.1/test2 (Group)\n",
      "12.1/test2/var1 (Dataset)\n",
      "12.1/test3 (Group)\n",
      "12.1/test3/var1 (Dataset)\n",
      "12.10 (Group)\n",
      "12.10/test1 (Group)\n",
      "12.10/test1/var1 (Dataset)\n",
      "12.10/test2 (Group)\n",
      "12.10/test2/var1 (Dataset)\n",
      "12.10/test3 (Group)\n",
      "12.10/test3/var1 (Dataset)\n",
      "12.11 (Group)\n",
      "12.11/test1 (Group)\n",
      "12.11/test1/var1 (Dataset)\n",
      "12.11/test2 (Group)\n",
      "12.11/test2/var1 (Dataset)\n",
      "12.11/test3 (Group)\n",
      "12.11/test3/var1 (Dataset)\n",
      "12.12 (Group)\n",
      "12.12/test1 (Group)\n",
      "12.12/test1/var1 (Dataset)\n",
      "12.12/test2 (Group)\n",
      "12.12/test2/var1 (Dataset)\n",
      "12.12/test3 (Group)\n",
      "12.12/test3/var1 (Dataset)\n",
      "12.13 (Group)\n",
      "12.13/test1 (Group)\n",
      "12.13/test1/var1 (Dataset)\n",
      "12.13/test1/var2 (Dataset)\n",
      "12.13/test2 (Group)\n",
      "12.13/test2/var1 (Dataset)\n",
      "12.13/test2/var2 (Dataset)\n",
      "12.13/test3 (Group)\n",
      "12.13/test3/var1 (Dataset)\n",
      "12.13/test3/var2 (Dataset)\n",
      "12.14 (Group)\n",
      "12.14/test1 (Group)\n",
      "12.14/test1/var1 (Dataset)\n",
      "12.14/test1/var2 (Dataset)\n",
      "12.14/test2 (Group)\n",
      "12.14/test2/var1 (Dataset)\n",
      "12.14/test2/var2 (Dataset)\n",
      "12.14/test3 (Group)\n",
      "12.14/test3/var1 (Dataset)\n",
      "12.14/test3/var2 (Dataset)\n",
      "12.2 (Group)\n",
      "12.2/test1 (Group)\n",
      "12.2/test1/var1 (Dataset)\n",
      "12.2/test2 (Group)\n",
      "12.2/test2/var1 (Dataset)\n",
      "12.2/test3 (Group)\n",
      "12.2/test3/var1 (Dataset)\n",
      "12.3 (Group)\n",
      "12.3/test1 (Group)\n",
      "12.3/test1/var1 (Dataset)\n",
      "12.3/test2 (Group)\n",
      "12.3/test2/var1 (Dataset)\n",
      "12.3/test3 (Group)\n",
      "12.3/test3/var1 (Dataset)\n",
      "12.4 (Group)\n",
      "12.4/test1 (Group)\n",
      "12.4/test1/var1 (Dataset)\n",
      "12.4/test2 (Group)\n",
      "12.4/test2/var1 (Dataset)\n",
      "12.4/test3 (Group)\n",
      "12.4/test3/var1 (Dataset)\n",
      "12.5 (Group)\n",
      "12.5/test1 (Group)\n",
      "12.5/test1/var1 (Dataset)\n",
      "12.5/test2 (Group)\n",
      "12.5/test2/var1 (Dataset)\n",
      "12.5/test3 (Group)\n",
      "12.5/test3/var1 (Dataset)\n",
      "12.6 (Group)\n",
      "12.6/test1 (Group)\n",
      "12.6/test1/var1 (Dataset)\n",
      "12.6/test2 (Group)\n",
      "12.6/test2/var1 (Dataset)\n",
      "12.6/test3 (Group)\n",
      "12.6/test3/var1 (Dataset)\n",
      "12.7 (Group)\n",
      "12.7/test1 (Group)\n",
      "12.7/test1/var1 (Dataset)\n",
      "12.7/test2 (Group)\n",
      "12.7/test2/var1 (Dataset)\n",
      "12.7/test3 (Group)\n",
      "12.7/test3/var1 (Dataset)\n",
      "12.8 (Group)\n",
      "12.8/test1 (Group)\n",
      "12.8/test1/var1 (Dataset)\n",
      "12.8/test2 (Group)\n",
      "12.8/test2/var1 (Dataset)\n",
      "12.8/test3 (Group)\n",
      "12.8/test3/var1 (Dataset)\n",
      "12.9 (Group)\n",
      "12.9/test1 (Group)\n",
      "12.9/test1/var1 (Dataset)\n",
      "12.9/test2 (Group)\n",
      "12.9/test2/var1 (Dataset)\n",
      "12.9/test3 (Group)\n",
      "12.9/test3/var1 (Dataset)\n",
      "13.1 (Group)\n",
      "13.1/test1 (Group)\n",
      "13.1/test1/var1 (Dataset)\n",
      "13.1/test1/var2 (Dataset)\n",
      "13.1/test1/var3 (Dataset)\n",
      "13.1/test2 (Group)\n",
      "13.1/test2/var1 (Dataset)\n",
      "13.1/test2/var2 (Dataset)\n",
      "13.1/test2/var3 (Dataset)\n",
      "13.1/test3 (Group)\n",
      "13.1/test3/var1 (Dataset)\n",
      "13.1/test3/var2 (Dataset)\n",
      "13.1/test3/var3 (Dataset)\n",
      "13.10 (Group)\n",
      "13.10/test1 (Group)\n",
      "13.10/test1/var1 (Dataset)\n",
      "13.10/test2 (Group)\n",
      "13.10/test2/var1 (Dataset)\n",
      "13.10/test3 (Group)\n",
      "13.10/test3/var1 (Dataset)\n",
      "13.11 (Group)\n",
      "13.11/test1 (Group)\n",
      "13.11/test1/var1 (Dataset)\n",
      "13.11/test1/var2 (Dataset)\n",
      "13.11/test2 (Group)\n",
      "13.11/test2/var1 (Dataset)\n",
      "13.11/test2/var2 (Dataset)\n",
      "13.11/test3 (Group)\n",
      "13.11/test3/var1 (Dataset)\n",
      "13.11/test3/var2 (Dataset)\n",
      "13.12 (Group)\n",
      "13.12/test1 (Group)\n",
      "13.12/test1/var1 (Dataset)\n",
      "13.12/test2 (Group)\n",
      "13.12/test2/var1 (Dataset)\n",
      "13.12/test3 (Group)\n",
      "13.12/test3/var1 (Dataset)\n",
      "13.13 (Group)\n",
      "13.13/test1 (Group)\n",
      "13.13/test1/var1 (Dataset)\n",
      "13.13/test2 (Group)\n",
      "13.13/test2/var1 (Dataset)\n",
      "13.13/test3 (Group)\n",
      "13.13/test3/var1 (Dataset)\n",
      "13.14 (Group)\n",
      "13.14/test1 (Group)\n",
      "13.14/test1/var1 (Dataset)\n",
      "13.14/test1/var2 (Dataset)\n",
      "13.14/test1/var3 (Dataset)\n",
      "13.14/test1/var4 (Dataset)\n",
      "13.14/test1/var5 (Dataset)\n",
      "13.14/test1/var6 (Dataset)\n",
      "13.14/test1/var7 (Dataset)\n",
      "13.14/test2 (Group)\n",
      "13.14/test2/var1 (Dataset)\n",
      "13.14/test2/var2 (Dataset)\n",
      "13.14/test2/var3 (Dataset)\n",
      "13.14/test2/var4 (Dataset)\n",
      "13.14/test2/var5 (Dataset)\n",
      "13.14/test2/var6 (Dataset)\n",
      "13.14/test2/var7 (Dataset)\n",
      "13.14/test3 (Group)\n",
      "13.14/test3/var1 (Dataset)\n",
      "13.14/test3/var2 (Dataset)\n",
      "13.14/test3/var3 (Dataset)\n",
      "13.14/test3/var4 (Dataset)\n",
      "13.14/test3/var5 (Dataset)\n",
      "13.14/test3/var6 (Dataset)\n",
      "13.14/test3/var7 (Dataset)\n",
      "13.15 (Group)\n",
      "13.15/test1 (Group)\n",
      "13.15/test1/var1 (Dataset)\n",
      "13.15/test2 (Group)\n",
      "13.15/test2/var1 (Dataset)\n",
      "13.15/test3 (Group)\n",
      "13.15/test3/var1 (Dataset)\n",
      "13.15/test4 (Group)\n",
      "13.15/test4/var1 (Dataset)\n",
      "13.2 (Group)\n",
      "13.2/test1 (Group)\n",
      "13.2/test1/var1 (Dataset)\n",
      "13.2/test2 (Group)\n",
      "13.2/test2/var1 (Dataset)\n",
      "13.2/test3 (Group)\n",
      "13.2/test3/var1 (Dataset)\n",
      "13.3 (Group)\n",
      "13.3/test1 (Group)\n",
      "13.3/test1/var1 (Dataset)\n",
      "13.3/test1/var2 (Dataset)\n",
      "13.3/test1/var3 (Dataset)\n",
      "13.3/test2 (Group)\n",
      "13.3/test2/var1 (Dataset)\n",
      "13.3/test2/var2 (Dataset)\n",
      "13.3/test2/var3 (Dataset)\n",
      "13.3/test3 (Group)\n",
      "13.3/test3/var1 (Dataset)\n",
      "13.3/test3/var2 (Dataset)\n",
      "13.3/test3/var3 (Dataset)\n",
      "13.4 (Group)\n",
      "13.4/test1 (Group)\n",
      "13.4/test1/var1 (Dataset)\n",
      "13.4/test2 (Group)\n",
      "13.4/test2/var1 (Dataset)\n",
      "13.4/test3 (Group)\n",
      "13.4/test3/var1 (Dataset)\n",
      "13.5 (Group)\n",
      "13.5/test1 (Group)\n",
      "13.5/test1/var1 (Dataset)\n",
      "13.5/test1/var2 (Dataset)\n",
      "13.5/test1/var3 (Dataset)\n",
      "13.5/test2 (Group)\n",
      "13.5/test2/var1 (Dataset)\n",
      "13.5/test2/var2 (Dataset)\n",
      "13.5/test2/var3 (Dataset)\n",
      "13.5/test3 (Group)\n",
      "13.5/test3/var1 (Dataset)\n",
      "13.5/test3/var2 (Dataset)\n",
      "13.5/test3/var3 (Dataset)\n",
      "13.7 (Group)\n",
      "13.7/test1 (Group)\n",
      "13.7/test1/var1 (Dataset)\n",
      "13.7/test2 (Group)\n",
      "13.7/test2/var1 (Dataset)\n",
      "13.7/test3 (Group)\n",
      "13.7/test3/var1 (Dataset)\n",
      "13.8 (Group)\n",
      "13.8/test1 (Group)\n",
      "13.8/test1/var1 (Dataset)\n",
      "13.8/test2 (Group)\n",
      "13.8/test2/var1 (Dataset)\n",
      "13.8/test3 (Group)\n",
      "13.8/test3/var1 (Dataset)\n",
      "13.9 (Group)\n",
      "13.9/test1 (Group)\n",
      "13.9/test1/var1 (Dataset)\n",
      "13.9/test2 (Group)\n",
      "13.9/test2/var1 (Dataset)\n",
      "13.9/test3 (Group)\n",
      "13.9/test3/var1 (Dataset)\n",
      "14.1 (Group)\n",
      "14.1/test1 (Group)\n",
      "14.1/test1/var1 (Dataset)\n",
      "14.1/test2 (Group)\n",
      "14.1/test2/var1 (Dataset)\n",
      "14.1/test3 (Group)\n",
      "14.1/test3/var1 (Dataset)\n",
      "14.2 (Group)\n",
      "14.2/test1 (Group)\n",
      "14.2/test1/var1 (Dataset)\n",
      "14.2/test2 (Group)\n",
      "14.2/test2/var1 (Dataset)\n",
      "14.2/test3 (Group)\n",
      "14.2/test3/var1 (Dataset)\n",
      "15.1 (Group)\n",
      "15.1/test1 (Group)\n",
      "15.1/test1/var1 (Dataset)\n",
      "15.1/test1/var2 (Dataset)\n",
      "15.1/test2 (Group)\n",
      "15.1/test2/var1 (Dataset)\n",
      "15.1/test2/var2 (Dataset)\n",
      "15.1/test3 (Group)\n",
      "15.1/test3/var1 (Dataset)\n",
      "15.2 (Group)\n",
      "15.2/test1 (Group)\n",
      "15.2/test1/var1 (Dataset)\n",
      "15.2/test2 (Group)\n",
      "15.2/test2/var1 (Dataset)\n",
      "15.2/test3 (Group)\n",
      "15.2/test3/var1 (Dataset)\n",
      "15.2/test4 (Group)\n",
      "15.2/test4/var1 (Dataset)\n",
      "16.1 (Group)\n",
      "16.1/test1 (Group)\n",
      "16.1/test1/var1 (Dataset)\n",
      "16.1/test2 (Group)\n",
      "16.1/test2/var1 (Dataset)\n",
      "16.1/test3 (Group)\n",
      "16.1/test3/var1 (Dataset)\n",
      "16.2 (Group)\n",
      "16.2/test1 (Group)\n",
      "16.2/test1/var1 (Dataset)\n",
      "16.2/test2 (Group)\n",
      "16.2/test2/var1 (Dataset)\n",
      "16.2/test3 (Group)\n",
      "16.2/test3/var1 (Dataset)\n",
      "17.1 (Group)\n",
      "17.1/test1 (Group)\n",
      "17.1/test1/var1 (Group)\n",
      "17.1/test1/var1/e00 (Dataset)\n",
      "17.1/test1/var1/e01 (Dataset)\n",
      "17.1/test1/var1/e02 (Dataset)\n",
      "17.1/test1/var1/e03 (Dataset)\n",
      "17.1/test1/var1/e04 (Dataset)\n",
      "17.1/test1/var1/e10 (Dataset)\n",
      "17.1/test1/var1/e11 (Dataset)\n",
      "17.1/test1/var1/e12 (Dataset)\n",
      "17.1/test1/var1/e13 (Dataset)\n",
      "17.1/test1/var1/e14 (Dataset)\n",
      "17.1/test1/var1/e20 (Dataset)\n",
      "17.1/test1/var1/e21 (Dataset)\n",
      "17.1/test1/var1/e22 (Dataset)\n",
      "17.1/test1/var1/e23 (Dataset)\n",
      "17.1/test1/var1/e24 (Dataset)\n",
      "17.1/test1/var1/e30 (Dataset)\n",
      "17.1/test1/var1/e31 (Dataset)\n",
      "17.1/test1/var1/e32 (Dataset)\n",
      "17.1/test1/var1/e33 (Dataset)\n",
      "17.1/test1/var1/e34 (Dataset)\n",
      "17.1/test1/var1/e40 (Dataset)\n",
      "17.1/test1/var1/e41 (Dataset)\n",
      "17.1/test1/var1/e42 (Dataset)\n",
      "17.1/test1/var1/e43 (Dataset)\n",
      "17.1/test1/var1/e44 (Dataset)\n",
      "17.1/test1/var2 (Group)\n",
      "17.1/test1/var2/e00 (Dataset)\n",
      "17.1/test1/var2/e01 (Dataset)\n",
      "17.1/test1/var2/e02 (Dataset)\n",
      "17.1/test1/var2/e03 (Dataset)\n",
      "17.1/test1/var2/e04 (Dataset)\n",
      "17.1/test1/var2/e10 (Dataset)\n",
      "17.1/test1/var2/e11 (Dataset)\n",
      "17.1/test1/var2/e12 (Dataset)\n",
      "17.1/test1/var2/e13 (Dataset)\n",
      "17.1/test1/var2/e14 (Dataset)\n",
      "17.1/test1/var2/e20 (Dataset)\n",
      "17.1/test1/var2/e21 (Dataset)\n",
      "17.1/test1/var2/e22 (Dataset)\n",
      "17.1/test1/var2/e23 (Dataset)\n",
      "17.1/test1/var2/e24 (Dataset)\n",
      "17.1/test1/var2/e30 (Dataset)\n",
      "17.1/test1/var2/e31 (Dataset)\n",
      "17.1/test1/var2/e32 (Dataset)\n",
      "17.1/test1/var2/e33 (Dataset)\n",
      "17.1/test1/var2/e34 (Dataset)\n",
      "17.1/test1/var2/e40 (Dataset)\n",
      "17.1/test1/var2/e41 (Dataset)\n",
      "17.1/test1/var2/e42 (Dataset)\n",
      "17.1/test1/var2/e43 (Dataset)\n",
      "17.1/test1/var2/e44 (Dataset)\n",
      "17.1/test2 (Group)\n",
      "17.1/test2/var1 (Group)\n",
      "17.1/test2/var1/e00 (Dataset)\n",
      "17.1/test2/var1/e01 (Dataset)\n",
      "17.1/test2/var1/e02 (Dataset)\n",
      "17.1/test2/var1/e03 (Dataset)\n",
      "17.1/test2/var1/e04 (Dataset)\n",
      "17.1/test2/var1/e10 (Dataset)\n",
      "17.1/test2/var1/e11 (Dataset)\n",
      "17.1/test2/var1/e12 (Dataset)\n",
      "17.1/test2/var1/e13 (Dataset)\n",
      "17.1/test2/var1/e14 (Dataset)\n",
      "17.1/test2/var1/e20 (Dataset)\n",
      "17.1/test2/var1/e21 (Dataset)\n",
      "17.1/test2/var1/e22 (Dataset)\n",
      "17.1/test2/var1/e23 (Dataset)\n",
      "17.1/test2/var1/e24 (Dataset)\n",
      "17.1/test2/var1/e30 (Dataset)\n",
      "17.1/test2/var1/e31 (Dataset)\n",
      "17.1/test2/var1/e32 (Dataset)\n",
      "17.1/test2/var1/e33 (Dataset)\n",
      "17.1/test2/var1/e34 (Dataset)\n",
      "17.1/test2/var1/e40 (Dataset)\n",
      "17.1/test2/var1/e41 (Dataset)\n",
      "17.1/test2/var1/e42 (Dataset)\n",
      "17.1/test2/var1/e43 (Dataset)\n",
      "17.1/test2/var1/e44 (Dataset)\n",
      "17.1/test2/var2 (Group)\n",
      "17.1/test2/var2/e00 (Dataset)\n",
      "17.1/test2/var2/e01 (Dataset)\n",
      "17.1/test2/var2/e02 (Dataset)\n",
      "17.1/test2/var2/e03 (Dataset)\n",
      "17.1/test2/var2/e04 (Dataset)\n",
      "17.1/test2/var2/e10 (Dataset)\n",
      "17.1/test2/var2/e11 (Dataset)\n",
      "17.1/test2/var2/e12 (Dataset)\n",
      "17.1/test2/var2/e13 (Dataset)\n",
      "17.1/test2/var2/e14 (Dataset)\n",
      "17.1/test2/var2/e20 (Dataset)\n",
      "17.1/test2/var2/e21 (Dataset)\n",
      "17.1/test2/var2/e22 (Dataset)\n",
      "17.1/test2/var2/e23 (Dataset)\n",
      "17.1/test2/var2/e24 (Dataset)\n",
      "17.1/test2/var2/e30 (Dataset)\n",
      "17.1/test2/var2/e31 (Dataset)\n",
      "17.1/test2/var2/e32 (Dataset)\n",
      "17.1/test2/var2/e33 (Dataset)\n",
      "17.1/test2/var2/e34 (Dataset)\n",
      "17.1/test2/var2/e40 (Dataset)\n",
      "17.1/test2/var2/e41 (Dataset)\n",
      "17.1/test2/var2/e42 (Dataset)\n",
      "17.1/test2/var2/e43 (Dataset)\n",
      "17.1/test2/var2/e44 (Dataset)\n",
      "17.1/test3 (Group)\n",
      "17.1/test3/var1 (Group)\n",
      "17.1/test3/var1/e00 (Dataset)\n",
      "17.1/test3/var1/e01 (Dataset)\n",
      "17.1/test3/var1/e02 (Dataset)\n",
      "17.1/test3/var1/e03 (Dataset)\n",
      "17.1/test3/var1/e04 (Dataset)\n",
      "17.1/test3/var1/e10 (Dataset)\n",
      "17.1/test3/var1/e11 (Dataset)\n",
      "17.1/test3/var1/e12 (Dataset)\n",
      "17.1/test3/var1/e13 (Dataset)\n",
      "17.1/test3/var1/e14 (Dataset)\n",
      "17.1/test3/var1/e20 (Dataset)\n",
      "17.1/test3/var1/e21 (Dataset)\n",
      "17.1/test3/var1/e22 (Dataset)\n",
      "17.1/test3/var1/e23 (Dataset)\n",
      "17.1/test3/var1/e24 (Dataset)\n",
      "17.1/test3/var1/e30 (Dataset)\n",
      "17.1/test3/var1/e31 (Dataset)\n",
      "17.1/test3/var1/e32 (Dataset)\n",
      "17.1/test3/var1/e33 (Dataset)\n",
      "17.1/test3/var1/e34 (Dataset)\n",
      "17.1/test3/var1/e40 (Dataset)\n",
      "17.1/test3/var1/e41 (Dataset)\n",
      "17.1/test3/var1/e42 (Dataset)\n",
      "17.1/test3/var1/e43 (Dataset)\n",
      "17.1/test3/var1/e44 (Dataset)\n",
      "17.1/test3/var2 (Group)\n",
      "17.1/test3/var2/e00 (Dataset)\n",
      "17.1/test3/var2/e01 (Dataset)\n",
      "17.1/test3/var2/e02 (Dataset)\n",
      "17.1/test3/var2/e03 (Dataset)\n",
      "17.1/test3/var2/e04 (Dataset)\n",
      "17.1/test3/var2/e10 (Dataset)\n",
      "17.1/test3/var2/e11 (Dataset)\n",
      "17.1/test3/var2/e12 (Dataset)\n",
      "17.1/test3/var2/e13 (Dataset)\n",
      "17.1/test3/var2/e14 (Dataset)\n",
      "17.1/test3/var2/e20 (Dataset)\n",
      "17.1/test3/var2/e21 (Dataset)\n",
      "17.1/test3/var2/e22 (Dataset)\n",
      "17.1/test3/var2/e23 (Dataset)\n",
      "17.1/test3/var2/e24 (Dataset)\n",
      "17.1/test3/var2/e30 (Dataset)\n",
      "17.1/test3/var2/e31 (Dataset)\n",
      "17.1/test3/var2/e32 (Dataset)\n",
      "17.1/test3/var2/e33 (Dataset)\n",
      "17.1/test3/var2/e34 (Dataset)\n",
      "17.1/test3/var2/e40 (Dataset)\n",
      "17.1/test3/var2/e41 (Dataset)\n",
      "17.1/test3/var2/e42 (Dataset)\n",
      "17.1/test3/var2/e43 (Dataset)\n",
      "17.1/test3/var2/e44 (Dataset)\n",
      "17.2 (Group)\n",
      "17.2/test1 (Group)\n",
      "17.2/test1/var1 (Dataset)\n",
      "17.2/test2 (Group)\n",
      "17.2/test2/var1 (Dataset)\n",
      "17.2/test3 (Group)\n",
      "17.2/test3/var1 (Dataset)\n",
      "17.2/test4 (Group)\n",
      "17.2/test4/var1 (Dataset)\n",
      "17.2/test5 (Group)\n",
      "17.2/test5/var1 (Dataset)\n",
      "18.1 (Group)\n",
      "18.1/test1 (Group)\n",
      "18.1/test1/var1 (Dataset)\n",
      "18.1/test2 (Group)\n",
      "18.1/test2/var1 (Dataset)\n",
      "18.1/test3 (Group)\n",
      "18.1/test3/var1 (Dataset)\n",
      "18.2 (Group)\n",
      "18.2/test1 (Group)\n",
      "18.2/test1/var1 (Dataset)\n",
      "18.2/test2 (Group)\n",
      "18.2/test2/var1 (Dataset)\n",
      "18.2/test3 (Group)\n",
      "18.2/test3/var1 (Dataset)\n",
      "19.1 (Group)\n",
      "19.1/test1 (Group)\n",
      "19.1/test1/var1 (Dataset)\n",
      "19.1/test2 (Group)\n",
      "19.1/test2/var1 (Dataset)\n",
      "19.1/test3 (Group)\n",
      "19.1/test3/var1 (Dataset)\n",
      "19.2 (Group)\n",
      "19.2/test1 (Group)\n",
      "19.2/test1/var1 (Dataset)\n",
      "19.2/test2 (Group)\n",
      "19.2/test2/var1 (Dataset)\n",
      "19.2/test3 (Group)\n",
      "19.2/test3/var1 (Dataset)\n",
      "19.2/test4 (Group)\n",
      "19.2/test4/var1 (Dataset)\n",
      "2.1 (Group)\n",
      "2.1/test1 (Group)\n",
      "2.1/test1/var1 (Dataset)\n",
      "2.1/test2 (Group)\n",
      "2.1/test2/var1 (Dataset)\n",
      "2.1/test3 (Group)\n",
      "2.1/test3/var1 (Dataset)\n",
      "2.1/test4 (Group)\n",
      "2.1/test4/var1 (Dataset)\n",
      "20.1 (Group)\n",
      "20.1/test1 (Group)\n",
      "20.1/test1/var1 (Dataset)\n",
      "20.1/test2 (Group)\n",
      "20.1/test2/var1 (Dataset)\n",
      "20.1/test3 (Group)\n",
      "20.1/test3/var1 (Dataset)\n",
      "20.2 (Group)\n",
      "20.2/test1 (Group)\n",
      "20.2/test1/var1 (Dataset)\n",
      "20.2/test2 (Group)\n",
      "20.2/test2/var1 (Dataset)\n",
      "20.2/test3 (Group)\n",
      "20.2/test3/var1 (Dataset)\n",
      "21.1 (Group)\n",
      "21.1/test1 (Group)\n",
      "21.1/test1/var1 (Dataset)\n",
      "21.1/test2 (Group)\n",
      "21.1/test2/var1 (Dataset)\n",
      "21.1/test3 (Group)\n",
      "21.1/test3/var1 (Dataset)\n",
      "21.2 (Group)\n",
      "21.2/test1 (Group)\n",
      "21.2/test1/var1 (Dataset)\n",
      "21.2/test2 (Group)\n",
      "21.2/test2/var1 (Dataset)\n",
      "21.2/test3 (Group)\n",
      "21.2/test3/var1 (Dataset)\n",
      "21.3 (Group)\n",
      "21.3/test1 (Group)\n",
      "21.3/test1/var1 (Dataset)\n",
      "21.3/test2 (Group)\n",
      "21.3/test2/var1 (Dataset)\n",
      "21.3/test3 (Group)\n",
      "21.3/test3/var1 (Dataset)\n",
      "21.3/test4 (Group)\n",
      "21.3/test4/var1 (Dataset)\n",
      "22.1 (Group)\n",
      "22.1/test1 (Group)\n",
      "22.1/test1/var1 (Dataset)\n",
      "22.1/test2 (Group)\n",
      "22.1/test2/var1 (Dataset)\n",
      "22.1/test3 (Group)\n",
      "22.1/test3/var1 (Dataset)\n",
      "22.2 (Group)\n",
      "22.2/test1 (Group)\n",
      "22.2/test1/var1 (Dataset)\n",
      "22.2/test2 (Group)\n",
      "22.2/test2/var1 (Dataset)\n",
      "22.2/test3 (Group)\n",
      "22.2/test3/var1 (Dataset)\n",
      "22.3 (Group)\n",
      "22.3/test1 (Group)\n",
      "22.3/test1/var1 (Dataset)\n",
      "22.3/test2 (Group)\n",
      "22.3/test2/var1 (Dataset)\n",
      "22.3/test3 (Group)\n",
      "22.3/test3/var1 (Dataset)\n",
      "22.3/test4 (Group)\n",
      "22.3/test4/var1 (Dataset)\n",
      "23.1 (Group)\n",
      "23.1/test1 (Group)\n",
      "23.1/test1/var1 (Dataset)\n",
      "23.1/test2 (Group)\n",
      "23.1/test2/var1 (Dataset)\n",
      "23.1/test3 (Group)\n",
      "23.1/test3/var1 (Dataset)\n",
      "23.2 (Group)\n",
      "23.2/test1 (Group)\n",
      "23.2/test1/var1 (Dataset)\n",
      "23.2/test2 (Group)\n",
      "23.2/test2/var1 (Dataset)\n",
      "23.2/test3 (Group)\n",
      "23.2/test3/var1 (Dataset)\n",
      "23.3 (Group)\n",
      "23.3/test1 (Group)\n",
      "23.3/test1/var1 (Dataset)\n",
      "23.3/test2 (Group)\n",
      "23.3/test2/var1 (Dataset)\n",
      "23.3/test3 (Group)\n",
      "23.3/test3/var1 (Dataset)\n",
      "23.3/test4 (Group)\n",
      "23.3/test4/var1 (Dataset)\n",
      "23.3/test5 (Group)\n",
      "23.3/test5/var1 (Dataset)\n",
      "23.3/test6 (Group)\n",
      "23.3/test6/var1 (Dataset)\n",
      "23.3/test7 (Group)\n",
      "23.3/test7/var1 (Dataset)\n",
      "24.1 (Group)\n",
      "24.1/test1 (Group)\n",
      "24.1/test1/var1 (Dataset)\n",
      "24.1/test2 (Group)\n",
      "24.1/test2/var1 (Dataset)\n",
      "24.1/test3 (Group)\n",
      "24.1/test3/var1 (Dataset)\n",
      "24.2 (Group)\n",
      "24.2/test1 (Group)\n",
      "24.2/test1/var1 (Dataset)\n",
      "24.2/test2 (Group)\n",
      "24.2/test2/var1 (Dataset)\n",
      "24.2/test3 (Group)\n",
      "24.2/test3/var1 (Dataset)\n",
      "24.3 (Group)\n",
      "24.3/test1 (Group)\n",
      "24.3/test1/var1 (Dataset)\n",
      "24.3/test2 (Group)\n",
      "24.3/test2/var1 (Dataset)\n",
      "24.3/test3 (Group)\n",
      "24.3/test3/var1 (Dataset)\n",
      "25.1 (Group)\n",
      "25.1/test1 (Group)\n",
      "25.1/test1/var1 (Dataset)\n",
      "25.1/test2 (Group)\n",
      "25.1/test2/var1 (Dataset)\n",
      "25.1/test3 (Group)\n",
      "25.1/test3/var1 (Dataset)\n",
      "25.2 (Group)\n",
      "25.2/test1 (Group)\n",
      "25.2/test1/var1 (Dataset)\n",
      "25.2/test2 (Group)\n",
      "25.2/test2/var1 (Dataset)\n",
      "25.2/test3 (Group)\n",
      "25.2/test3/var1 (Dataset)\n",
      "25.3 (Group)\n",
      "25.3/test1 (Group)\n",
      "25.3/test1/var1 (Dataset)\n",
      "25.3/test2 (Group)\n",
      "25.3/test2/var1 (Dataset)\n",
      "25.3/test3 (Group)\n",
      "25.3/test3/var1 (Dataset)\n",
      "26.1 (Group)\n",
      "26.1/test1 (Group)\n",
      "26.1/test1/var1 (Dataset)\n",
      "26.1/test1/var2 (Dataset)\n",
      "26.1/test2 (Group)\n",
      "26.1/test2/var1 (Dataset)\n",
      "26.1/test2/var2 (Dataset)\n",
      "26.1/test3 (Group)\n",
      "26.1/test3/var1 (Dataset)\n",
      "26.1/test3/var2 (Dataset)\n",
      "26.2 (Group)\n",
      "26.2/test1 (Group)\n",
      "26.2/test1/var1 (Dataset)\n",
      "26.2/test1/var2 (Dataset)\n",
      "26.2/test2 (Group)\n",
      "26.2/test2/var1 (Dataset)\n",
      "26.2/test2/var2 (Dataset)\n",
      "26.2/test3 (Group)\n",
      "26.2/test3/var1 (Dataset)\n",
      "26.2/test3/var2 (Dataset)\n",
      "26.3 (Group)\n",
      "26.3/test1 (Group)\n",
      "26.3/test1/var1 (Dataset)\n",
      "26.3/test2 (Group)\n",
      "26.3/test2/var1 (Dataset)\n",
      "26.3/test3 (Group)\n",
      "26.3/test3/var1 (Dataset)\n",
      "27.1 (Group)\n",
      "27.1/test1 (Group)\n",
      "27.1/test1/var1 (Dataset)\n",
      "27.1/test1/var2 (Dataset)\n",
      "27.1/test2 (Group)\n",
      "27.1/test2/var1 (Dataset)\n",
      "27.1/test2/var2 (Dataset)\n",
      "27.1/test3 (Group)\n",
      "27.1/test3/var1 (Dataset)\n",
      "27.1/test3/var2 (Dataset)\n",
      "27.2 (Group)\n",
      "27.2/test1 (Group)\n",
      "27.2/test1/var1 (Dataset)\n",
      "27.2/test2 (Group)\n",
      "27.2/test2/var1 (Dataset)\n",
      "27.2/test3 (Group)\n",
      "27.2/test3/var1 (Dataset)\n",
      "27.3 (Group)\n",
      "27.3/test1 (Group)\n",
      "27.3/test1/var1 (Dataset)\n",
      "27.3/test2 (Group)\n",
      "27.3/test2/var1 (Dataset)\n",
      "27.3/test3 (Group)\n",
      "27.3/test3/var1 (Dataset)\n",
      "27.3/test4 (Group)\n",
      "27.3/test4/var1 (Dataset)\n",
      "28.1 (Group)\n",
      "28.1/test1 (Group)\n",
      "28.1/test1/var1 (Dataset)\n",
      "28.1/test1/var2 (Dataset)\n",
      "28.1/test2 (Group)\n",
      "28.1/test2/var1 (Dataset)\n",
      "28.1/test2/var2 (Dataset)\n",
      "28.1/test3 (Group)\n",
      "28.1/test3/var1 (Dataset)\n",
      "28.1/test3/var2 (Dataset)\n",
      "28.2 (Group)\n",
      "28.2/test1 (Group)\n",
      "28.2/test1/var1 (Dataset)\n",
      "28.2/test2 (Group)\n",
      "28.2/test2/var1 (Dataset)\n",
      "28.2/test3 (Group)\n",
      "28.2/test3/var1 (Dataset)\n",
      "28.3 (Group)\n",
      "28.3/test1 (Group)\n",
      "28.3/test1/var1 (Dataset)\n",
      "28.3/test1/var2 (Dataset)\n",
      "28.3/test1/var3 (Dataset)\n",
      "28.3/test2 (Group)\n",
      "28.3/test2/var1 (Dataset)\n",
      "28.3/test2/var2 (Dataset)\n",
      "28.3/test2/var3 (Dataset)\n",
      "28.3/test3 (Group)\n",
      "28.3/test3/var1 (Dataset)\n",
      "28.3/test3/var2 (Dataset)\n",
      "28.3/test3/var3 (Dataset)\n",
      "28.3/test4 (Group)\n",
      "28.3/test4/var1 (Dataset)\n",
      "28.3/test4/var2 (Dataset)\n",
      "29.1 (Group)\n",
      "29.1/test1 (Group)\n",
      "29.1/test1/var1 (Dataset)\n",
      "29.1/test2 (Group)\n",
      "29.1/test2/var1 (Dataset)\n",
      "29.1/test3 (Group)\n",
      "29.1/test3/var1 (Dataset)\n",
      "29.2 (Group)\n",
      "29.2/test1 (Group)\n",
      "29.2/test1/var1 (Dataset)\n",
      "29.2/test2 (Group)\n",
      "29.2/test2/var1 (Dataset)\n",
      "29.2/test3 (Group)\n",
      "29.2/test3/var1 (Dataset)\n",
      "29.3 (Group)\n",
      "29.3/test1 (Group)\n",
      "29.3/test1/var1 (Dataset)\n",
      "29.3/test2 (Group)\n",
      "29.3/test2/var1 (Dataset)\n",
      "29.3/test3 (Group)\n",
      "29.3/test3/var1 (Dataset)\n",
      "29.3/test4 (Group)\n",
      "29.3/test4/var1 (Dataset)\n",
      "3.1 (Group)\n",
      "3.1/test1 (Group)\n",
      "3.1/test1/var1 (Dataset)\n",
      "3.1/test1/var2 (Dataset)\n",
      "3.1/test2 (Group)\n",
      "3.1/test2/var1 (Dataset)\n",
      "3.1/test2/var2 (Dataset)\n",
      "3.1/test3 (Group)\n",
      "3.1/test3/var1 (Dataset)\n",
      "3.1/test3/var2 (Dataset)\n",
      "30.1 (Group)\n",
      "30.1/test1 (Group)\n",
      "30.1/test1/var1 (Dataset)\n",
      "30.1/test1/var2 (Dataset)\n",
      "30.1/test1/var3 (Dataset)\n",
      "30.1/test1/var4 (Dataset)\n",
      "30.1/test2 (Group)\n",
      "30.1/test2/var1 (Dataset)\n",
      "30.1/test2/var2 (Dataset)\n",
      "30.1/test2/var3 (Dataset)\n",
      "30.1/test2/var4 (Dataset)\n",
      "30.1/test3 (Group)\n",
      "30.1/test3/var1 (Dataset)\n",
      "30.1/test3/var2 (Dataset)\n",
      "30.1/test3/var3 (Dataset)\n",
      "30.1/test3/var4 (Dataset)\n",
      "30.2 (Group)\n",
      "30.2/test1 (Group)\n",
      "30.2/test1/var1 (Dataset)\n",
      "30.2/test1/var2 (Dataset)\n",
      "30.2/test1/var3 (Dataset)\n",
      "30.2/test1/var4 (Dataset)\n",
      "30.2/test1/var5 (Dataset)\n",
      "30.2/test2 (Group)\n",
      "30.2/test2/var1 (Dataset)\n",
      "30.2/test2/var2 (Dataset)\n",
      "30.2/test2/var3 (Dataset)\n",
      "30.2/test2/var4 (Dataset)\n",
      "30.2/test2/var5 (Dataset)\n",
      "30.2/test3 (Group)\n",
      "30.2/test3/var1 (Dataset)\n",
      "30.2/test3/var2 (Dataset)\n",
      "30.2/test3/var3 (Dataset)\n",
      "30.2/test3/var4 (Dataset)\n",
      "30.2/test3/var5 (Dataset)\n",
      "30.3 (Group)\n",
      "30.3/test1 (Group)\n",
      "30.3/test1/var1 (Dataset)\n",
      "30.3/test2 (Group)\n",
      "30.3/test2/var1 (Dataset)\n",
      "30.3/test3 (Group)\n",
      "30.3/test3/var1 (Dataset)\n",
      "30.3/test4 (Group)\n",
      "30.3/test4/var1 (Dataset)\n",
      "30.3/test5 (Group)\n",
      "30.3/test5/var1 (Dataset)\n",
      "30.3/test6 (Group)\n",
      "30.3/test6/var1 (Dataset)\n",
      "31.1 (Group)\n",
      "31.1/test1 (Group)\n",
      "31.1/test1/var1 (Dataset)\n",
      "31.1/test2 (Group)\n",
      "31.1/test2/var1 (Dataset)\n",
      "31.1/test3 (Group)\n",
      "31.1/test3/var1 (Dataset)\n",
      "31.2 (Group)\n",
      "31.2/test1 (Group)\n",
      "31.2/test1/var1 (Dataset)\n",
      "31.2/test1/var2 (Dataset)\n",
      "31.2/test2 (Group)\n",
      "31.2/test2/var1 (Dataset)\n",
      "31.2/test2/var2 (Dataset)\n",
      "31.2/test3 (Group)\n",
      "31.2/test3/var1 (Dataset)\n",
      "31.2/test3/var2 (Dataset)\n",
      "31.3 (Group)\n",
      "31.3/test1 (Group)\n",
      "31.3/test1/var1 (Dataset)\n",
      "31.3/test2 (Group)\n",
      "31.3/test2/var1 (Dataset)\n",
      "31.3/test3 (Group)\n",
      "31.3/test3/var1 (Dataset)\n",
      "31.3/test4 (Group)\n",
      "31.3/test4/var1 (Dataset)\n",
      "32.1 (Group)\n",
      "32.1/test1 (Group)\n",
      "32.1/test1/var1 (Dataset)\n",
      "32.1/test2 (Group)\n",
      "32.1/test2/var1 (Dataset)\n",
      "32.1/test3 (Group)\n",
      "32.1/test3/var1 (Dataset)\n",
      "32.2 (Group)\n",
      "32.2/test1 (Group)\n",
      "32.2/test1/var1 (Dataset)\n",
      "32.2/test2 (Group)\n",
      "32.2/test2/var1 (Dataset)\n",
      "32.2/test3 (Group)\n",
      "32.2/test3/var1 (Dataset)\n",
      "32.3 (Group)\n",
      "32.3/test1 (Group)\n",
      "32.3/test1/var1 (Dataset)\n",
      "32.3/test2 (Group)\n",
      "32.3/test2/var1 (Dataset)\n",
      "32.3/test3 (Group)\n",
      "32.3/test3/var1 (Dataset)\n",
      "32.3/test4 (Group)\n",
      "32.3/test4/var1 (Dataset)\n",
      "32.3/test4/var2 (Dataset)\n",
      "33.1 (Group)\n",
      "33.1/test1 (Group)\n",
      "33.1/test1/var1 (Dataset)\n",
      "33.1/test2 (Group)\n",
      "33.1/test2/var1 (Dataset)\n",
      "33.1/test3 (Group)\n",
      "33.1/test3/var1 (Dataset)\n",
      "33.2 (Group)\n",
      "33.2/test1 (Group)\n",
      "33.2/test1/var1 (Dataset)\n",
      "33.2/test2 (Group)\n",
      "33.2/test2/var1 (Dataset)\n",
      "33.2/test3 (Group)\n",
      "33.2/test3/var1 (Dataset)\n",
      "33.3 (Group)\n",
      "33.3/test1 (Group)\n",
      "33.3/test1/var1 (Dataset)\n",
      "33.3/test1/var2 (Dataset)\n",
      "33.3/test1/var3 (Dataset)\n",
      "33.3/test2 (Group)\n",
      "33.3/test2/var1 (Dataset)\n",
      "33.3/test2/var2 (Dataset)\n",
      "33.3/test2/var3 (Dataset)\n",
      "33.3/test3 (Group)\n",
      "33.3/test3/var1 (Dataset)\n",
      "33.3/test3/var2 (Dataset)\n",
      "33.3/test3/var3 (Dataset)\n",
      "34.1 (Group)\n",
      "34.1/test1 (Group)\n",
      "34.1/test1/var1 (Dataset)\n",
      "34.1/test1/var2 (Dataset)\n",
      "34.1/test2 (Group)\n",
      "34.1/test2/var1 (Dataset)\n",
      "34.1/test2/var2 (Dataset)\n",
      "34.1/test3 (Group)\n",
      "34.1/test3/var1 (Dataset)\n",
      "34.1/test3/var2 (Dataset)\n",
      "34.2 (Group)\n",
      "34.2/test1 (Group)\n",
      "34.2/test1/var1 (Dataset)\n",
      "34.2/test1/var2 (Dataset)\n",
      "34.2/test2 (Group)\n",
      "34.2/test2/var1 (Dataset)\n",
      "34.2/test2/var2 (Dataset)\n",
      "34.2/test3 (Group)\n",
      "34.2/test3/var1 (Dataset)\n",
      "34.2/test3/var2 (Dataset)\n",
      "34.3 (Group)\n",
      "34.3/test1 (Group)\n",
      "34.3/test1/var1 (Dataset)\n",
      "34.3/test2 (Group)\n",
      "34.3/test2/var1 (Dataset)\n",
      "34.3/test3 (Group)\n",
      "34.3/test3/var1 (Dataset)\n",
      "34.3/test4 (Group)\n",
      "34.3/test4/var1 (Dataset)\n",
      "35.1 (Group)\n",
      "35.1/test1 (Group)\n",
      "35.1/test1/var1 (Dataset)\n",
      "35.1/test2 (Group)\n",
      "35.1/test2/var1 (Dataset)\n",
      "35.1/test3 (Group)\n",
      "35.1/test3/var1 (Dataset)\n",
      "35.2 (Group)\n",
      "35.2/test1 (Group)\n",
      "35.2/test1/var1 (Dataset)\n",
      "35.2/test2 (Group)\n",
      "35.2/test2/var1 (Dataset)\n",
      "35.2/test3 (Group)\n",
      "35.2/test3/var1 (Dataset)\n",
      "35.3 (Group)\n",
      "35.3/test1 (Group)\n",
      "35.3/test1/var1 (Dataset)\n",
      "35.3/test2 (Group)\n",
      "35.3/test2/var1 (Dataset)\n",
      "35.3/test3 (Group)\n",
      "35.3/test3/var1 (Dataset)\n",
      "35.3/test4 (Group)\n",
      "35.3/test4/var1 (Dataset)\n",
      "36.1 (Group)\n",
      "36.1/test1 (Group)\n",
      "36.1/test1/var1 (Dataset)\n",
      "36.1/test2 (Group)\n",
      "36.1/test2/var1 (Dataset)\n",
      "36.1/test3 (Group)\n",
      "36.1/test3/var1 (Dataset)\n",
      "36.2 (Group)\n",
      "36.2/test1 (Group)\n",
      "36.2/test1/var1 (Dataset)\n",
      "36.2/test2 (Group)\n",
      "36.2/test2/var1 (Dataset)\n",
      "36.2/test3 (Group)\n",
      "36.2/test3/var1 (Dataset)\n",
      "36.3 (Group)\n",
      "36.3/test1 (Group)\n",
      "36.3/test1/var1 (Dataset)\n",
      "36.3/test2 (Group)\n",
      "36.3/test2/var1 (Dataset)\n",
      "36.3/test3 (Group)\n",
      "36.3/test3/var1 (Dataset)\n",
      "36.3/test4 (Group)\n",
      "36.3/test4/var1 (Dataset)\n",
      "37.1 (Group)\n",
      "37.1/test1 (Group)\n",
      "37.1/test1/var1 (Dataset)\n",
      "37.1/test2 (Group)\n",
      "37.1/test2/var1 (Dataset)\n",
      "37.1/test3 (Group)\n",
      "37.1/test3/var1 (Dataset)\n",
      "37.2 (Group)\n",
      "37.2/test1 (Group)\n",
      "37.2/test1/var1 (Dataset)\n",
      "37.2/test2 (Group)\n",
      "37.2/test2/var1 (Dataset)\n",
      "37.2/test3 (Group)\n",
      "37.2/test3/var1 (Dataset)\n",
      "37.3 (Group)\n",
      "37.3/test1 (Group)\n",
      "37.3/test1/var1 (Dataset)\n",
      "37.3/test2 (Group)\n",
      "37.3/test2/var1 (Dataset)\n",
      "37.3/test3 (Group)\n",
      "37.3/test3/var1 (Dataset)\n",
      "37.3/test4 (Group)\n",
      "37.3/test4/var1 (Dataset)\n",
      "38.1 (Group)\n",
      "38.1/test1 (Group)\n",
      "38.1/test1/var1 (Dataset)\n",
      "38.1/test2 (Group)\n",
      "38.1/test2/var1 (Dataset)\n",
      "38.1/test3 (Group)\n",
      "38.1/test3/var1 (Dataset)\n",
      "38.2 (Group)\n",
      "38.2/test1 (Group)\n",
      "38.2/test1/var1 (Dataset)\n",
      "38.2/test2 (Group)\n",
      "38.2/test2/var1 (Dataset)\n",
      "38.2/test3 (Group)\n",
      "38.2/test3/var1 (Dataset)\n",
      "38.3 (Group)\n",
      "38.3/test1 (Group)\n",
      "38.3/test1/var1 (Dataset)\n",
      "38.3/test2 (Group)\n",
      "38.3/test2/var1 (Dataset)\n",
      "38.3/test3 (Group)\n",
      "38.3/test3/var1 (Dataset)\n",
      "38.3/test4 (Group)\n",
      "38.3/test4/var1 (Dataset)\n",
      "39.1 (Group)\n",
      "39.1/test1 (Group)\n",
      "39.1/test1/var1 (Dataset)\n",
      "39.1/test2 (Group)\n",
      "39.1/test2/var1 (Dataset)\n",
      "39.1/test3 (Group)\n",
      "39.1/test3/var1 (Dataset)\n",
      "39.2 (Group)\n",
      "39.2/test1 (Group)\n",
      "39.2/test1/var1 (Dataset)\n",
      "39.2/test2 (Group)\n",
      "39.2/test2/var1 (Dataset)\n",
      "39.2/test3 (Group)\n",
      "39.2/test3/var1 (Dataset)\n",
      "39.3 (Group)\n",
      "39.3/test1 (Group)\n",
      "39.3/test1/var1 (Dataset)\n",
      "39.3/test2 (Group)\n",
      "39.3/test2/var1 (Dataset)\n",
      "39.3/test3 (Group)\n",
      "39.3/test3/var1 (Dataset)\n",
      "39.3/test4 (Group)\n",
      "39.3/test4/var1 (Dataset)\n",
      "4.1 (Group)\n",
      "4.1/test1 (Group)\n",
      "4.1/test1/var1 (Dataset)\n",
      "4.1/test2 (Group)\n",
      "4.1/test2/var1 (Dataset)\n",
      "4.1/test3 (Group)\n",
      "4.1/test3/var1 (Dataset)\n",
      "40.1 (Group)\n",
      "40.1/test1 (Group)\n",
      "40.1/test1/var1 (Dataset)\n",
      "40.1/test2 (Group)\n",
      "40.1/test2/var1 (Dataset)\n",
      "40.1/test3 (Group)\n",
      "40.1/test3/var1 (Dataset)\n",
      "40.2 (Group)\n",
      "40.2/test1 (Group)\n",
      "40.2/test1/var1 (Dataset)\n",
      "40.2/test2 (Group)\n",
      "40.2/test2/var1 (Dataset)\n",
      "40.2/test3 (Group)\n",
      "40.2/test3/var1 (Dataset)\n",
      "40.3 (Group)\n",
      "40.3/test1 (Group)\n",
      "40.3/test1/var1 (Dataset)\n",
      "40.3/test2 (Group)\n",
      "40.3/test2/var1 (Dataset)\n",
      "40.3/test3 (Group)\n",
      "40.3/test3/var1 (Dataset)\n",
      "41.1 (Group)\n",
      "41.1/test1 (Group)\n",
      "41.1/test1/var1 (Dataset)\n",
      "41.1/test2 (Group)\n",
      "41.1/test2/var1 (Dataset)\n",
      "41.1/test3 (Group)\n",
      "41.1/test3/var1 (Dataset)\n",
      "41.2 (Group)\n",
      "41.2/test1 (Group)\n",
      "41.2/test1/var1 (Dataset)\n",
      "41.2/test2 (Group)\n",
      "41.2/test2/var1 (Dataset)\n",
      "41.2/test3 (Group)\n",
      "41.2/test3/var1 (Dataset)\n",
      "41.3 (Group)\n",
      "41.3/test1 (Group)\n",
      "41.3/test1/var1 (Dataset)\n",
      "41.3/test2 (Group)\n",
      "41.3/test2/var1 (Dataset)\n",
      "41.3/test3 (Group)\n",
      "41.3/test3/var1 (Dataset)\n",
      "42.1 (Group)\n",
      "42.1/test1 (Group)\n",
      "42.1/test1/var1 (Dataset)\n",
      "42.1/test2 (Group)\n",
      "42.1/test2/var1 (Dataset)\n",
      "42.1/test3 (Group)\n",
      "42.1/test3/var1 (Dataset)\n",
      "42.2 (Group)\n",
      "42.2/test1 (Group)\n",
      "42.2/test1/var1 (Dataset)\n",
      "42.2/test2 (Group)\n",
      "42.2/test2/var1 (Dataset)\n",
      "42.2/test3 (Group)\n",
      "42.2/test3/var1 (Dataset)\n",
      "42.3 (Group)\n",
      "42.3/test1 (Group)\n",
      "42.3/test1/var1 (Dataset)\n",
      "42.3/test2 (Group)\n",
      "42.3/test2/var1 (Dataset)\n",
      "42.3/test3 (Group)\n",
      "42.3/test3/var1 (Dataset)\n",
      "42.3/test4 (Group)\n",
      "42.3/test4/var1 (Dataset)\n",
      "43.1 (Group)\n",
      "43.1/test1 (Group)\n",
      "43.1/test1/var1 (Dataset)\n",
      "43.1/test2 (Group)\n",
      "43.1/test2/var1 (Dataset)\n",
      "43.1/test3 (Group)\n",
      "43.1/test3/var1 (Dataset)\n",
      "43.2 (Group)\n",
      "43.2/test1 (Group)\n",
      "43.2/test1/var1 (Dataset)\n",
      "43.2/test2 (Group)\n",
      "43.2/test2/var1 (Dataset)\n",
      "43.2/test3 (Group)\n",
      "43.2/test3/var1 (Dataset)\n",
      "43.3 (Group)\n",
      "43.3/test1 (Group)\n",
      "43.3/test1/var1 (Dataset)\n",
      "43.3/test1/var2 (Dataset)\n",
      "43.3/test2 (Group)\n",
      "43.3/test2/var1 (Dataset)\n",
      "43.3/test2/var2 (Dataset)\n",
      "43.3/test3 (Group)\n",
      "43.3/test3/var1 (Dataset)\n",
      "43.3/test3/var2 (Dataset)\n",
      "43.3/test4 (Group)\n",
      "43.3/test4/var1 (Dataset)\n",
      "44.1 (Group)\n",
      "44.1/test1 (Group)\n",
      "44.1/test1/var1 (Dataset)\n",
      "44.1/test2 (Group)\n",
      "44.1/test2/var1 (Dataset)\n",
      "44.1/test3 (Group)\n",
      "44.1/test3/var1 (Dataset)\n",
      "44.2 (Group)\n",
      "44.2/test1 (Group)\n",
      "44.2/test1/var1 (Dataset)\n",
      "44.2/test2 (Group)\n",
      "44.2/test2/var1 (Dataset)\n",
      "44.2/test3 (Group)\n",
      "44.2/test3/var1 (Dataset)\n",
      "44.3 (Group)\n",
      "44.3/test1 (Group)\n",
      "44.3/test1/var1 (Dataset)\n",
      "44.3/test2 (Group)\n",
      "44.3/test2/var1 (Dataset)\n",
      "44.3/test3 (Group)\n",
      "44.3/test3/var1 (Dataset)\n",
      "45.1 (Group)\n",
      "45.1/test1 (Group)\n",
      "45.1/test1/var1 (Dataset)\n",
      "45.1/test1/var2 (Dataset)\n",
      "45.1/test2 (Group)\n",
      "45.1/test2/var1 (Dataset)\n",
      "45.1/test2/var2 (Dataset)\n",
      "45.1/test3 (Group)\n",
      "45.1/test3/var1 (Dataset)\n",
      "45.1/test3/var2 (Dataset)\n",
      "45.2 (Group)\n",
      "45.2/test1 (Group)\n",
      "45.2/test1/var1 (Dataset)\n",
      "45.2/test2 (Group)\n",
      "45.2/test2/var1 (Dataset)\n",
      "45.2/test3 (Group)\n",
      "45.2/test3/var1 (Dataset)\n",
      "45.3 (Group)\n",
      "45.3/test1 (Group)\n",
      "45.3/test1/var1 (Dataset)\n",
      "45.3/test2 (Group)\n",
      "45.3/test2/var1 (Dataset)\n",
      "45.3/test3 (Group)\n",
      "45.3/test3/var1 (Dataset)\n",
      "45.4 (Group)\n",
      "45.4/test1 (Group)\n",
      "45.4/test1/var1 (Dataset)\n",
      "45.4/test2 (Group)\n",
      "45.4/test2/var1 (Dataset)\n",
      "45.4/test3 (Group)\n",
      "45.4/test3/var1 (Dataset)\n",
      "46.1 (Group)\n",
      "46.1/test1 (Group)\n",
      "46.1/test1/var1 (Dataset)\n",
      "46.1/test1/var2 (Dataset)\n",
      "46.1/test1/var3 (Dataset)\n",
      "46.1/test1/var4 (Dataset)\n",
      "46.1/test2 (Group)\n",
      "46.1/test2/var1 (Dataset)\n",
      "46.1/test2/var2 (Dataset)\n",
      "46.1/test2/var3 (Dataset)\n",
      "46.1/test2/var4 (Dataset)\n",
      "46.1/test3 (Group)\n",
      "46.1/test3/var1 (Dataset)\n",
      "46.1/test3/var2 (Dataset)\n",
      "46.1/test3/var3 (Dataset)\n",
      "46.1/test3/var4 (Dataset)\n",
      "46.2 (Group)\n",
      "46.2/test1 (Group)\n",
      "46.2/test1/var1 (Dataset)\n",
      "46.2/test1/var2 (Dataset)\n",
      "46.2/test1/var3 (Dataset)\n",
      "46.2/test2 (Group)\n",
      "46.2/test2/var1 (Dataset)\n",
      "46.2/test2/var2 (Dataset)\n",
      "46.2/test2/var3 (Dataset)\n",
      "46.2/test3 (Group)\n",
      "46.2/test3/var1 (Dataset)\n",
      "46.2/test3/var2 (Dataset)\n",
      "46.2/test3/var3 (Dataset)\n",
      "46.3 (Group)\n",
      "46.3/test1 (Group)\n",
      "46.3/test1/var1 (Dataset)\n",
      "46.3/test2 (Group)\n",
      "46.3/test2/var1 (Dataset)\n",
      "46.3/test3 (Group)\n",
      "46.3/test3/var1 (Dataset)\n",
      "46.4 (Group)\n",
      "46.4/test1 (Group)\n",
      "46.4/test1/var1 (Dataset)\n",
      "46.4/test1/var2 (Dataset)\n",
      "46.4/test2 (Group)\n",
      "46.4/test2/var1 (Dataset)\n",
      "46.4/test2/var2 (Dataset)\n",
      "46.4/test3 (Group)\n",
      "46.4/test3/var1 (Dataset)\n",
      "46.4/test3/var2 (Dataset)\n",
      "46.4/test4 (Group)\n",
      "46.4/test4/var1 (Dataset)\n",
      "46.4/test4/var2 (Dataset)\n",
      "46.4/test5 (Group)\n",
      "46.4/test5/var1 (Dataset)\n",
      "46.4/test5/var2 (Dataset)\n",
      "47.1 (Group)\n",
      "47.1/test1 (Group)\n",
      "47.1/test1/var1 (Dataset)\n",
      "47.1/test2 (Group)\n",
      "47.1/test2/var1 (Dataset)\n",
      "47.1/test3 (Group)\n",
      "47.1/test3/var1 (Dataset)\n",
      "47.2 (Group)\n",
      "47.2/test1 (Group)\n",
      "47.2/test1/var1 (Dataset)\n",
      "47.2/test2 (Group)\n",
      "47.2/test2/var1 (Dataset)\n",
      "47.2/test3 (Group)\n",
      "47.2/test3/var1 (Dataset)\n",
      "47.3 (Group)\n",
      "47.3/test1 (Group)\n",
      "47.3/test1/var1 (Dataset)\n",
      "47.3/test2 (Group)\n",
      "47.3/test2/var1 (Dataset)\n",
      "47.3/test3 (Group)\n",
      "47.3/test3/var1 (Dataset)\n",
      "47.4 (Group)\n",
      "47.4/test1 (Group)\n",
      "47.4/test1/var1 (Dataset)\n",
      "47.4/test2 (Group)\n",
      "47.4/test2/var1 (Dataset)\n",
      "47.4/test3 (Group)\n",
      "47.4/test3/var1 (Dataset)\n",
      "48.1 (Group)\n",
      "48.1/test1 (Group)\n",
      "48.1/test1/var1 (Dataset)\n",
      "48.1/test2 (Group)\n",
      "48.1/test2/var1 (Dataset)\n",
      "48.1/test3 (Group)\n",
      "48.1/test3/var1 (Dataset)\n",
      "48.2 (Group)\n",
      "48.2/test1 (Group)\n",
      "48.2/test1/var1 (Dataset)\n",
      "48.2/test2 (Group)\n",
      "48.2/test2/var1 (Dataset)\n",
      "48.2/test3 (Group)\n",
      "48.2/test3/var1 (Dataset)\n",
      "48.3 (Group)\n",
      "48.3/test1 (Group)\n",
      "48.3/test1/var1 (Dataset)\n",
      "48.3/test2 (Group)\n",
      "48.3/test2/var1 (Dataset)\n",
      "48.3/test3 (Group)\n",
      "48.3/test3/var1 (Dataset)\n",
      "48.4 (Group)\n",
      "48.4/test1 (Group)\n",
      "48.4/test1/var1 (Dataset)\n",
      "48.4/test2 (Group)\n",
      "48.4/test2/var1 (Dataset)\n",
      "48.4/test3 (Group)\n",
      "48.4/test3/var1 (Dataset)\n",
      "48.4/test4 (Group)\n",
      "48.4/test4/var1 (Dataset)\n",
      "49.1 (Group)\n",
      "49.1/test1 (Group)\n",
      "49.1/test1/var1 (Dataset)\n",
      "49.1/test2 (Group)\n",
      "49.1/test2/var1 (Dataset)\n",
      "49.1/test3 (Group)\n",
      "49.1/test3/var1 (Dataset)\n",
      "49.2 (Group)\n",
      "49.2/test1 (Group)\n",
      "49.2/test1/var1 (Dataset)\n",
      "49.2/test2 (Group)\n",
      "49.2/test2/var1 (Dataset)\n",
      "49.2/test3 (Group)\n",
      "49.2/test3/var1 (Dataset)\n",
      "49.3 (Group)\n",
      "49.3/test1 (Group)\n",
      "49.3/test1/var1 (Dataset)\n",
      "49.3/test2 (Group)\n",
      "49.3/test2/var1 (Dataset)\n",
      "49.3/test3 (Group)\n",
      "49.3/test3/var1 (Dataset)\n",
      "49.4 (Group)\n",
      "49.4/test1 (Group)\n",
      "49.4/test1/var1 (Dataset)\n",
      "49.4/test2 (Group)\n",
      "49.4/test2/var1 (Dataset)\n",
      "49.4/test3 (Group)\n",
      "49.4/test3/var1 (Dataset)\n",
      "49.4/test4 (Group)\n",
      "49.4/test4/var1 (Dataset)\n",
      "5.1 (Group)\n",
      "5.1/test1 (Group)\n",
      "5.1/test1/var1 (Dataset)\n",
      "5.1/test2 (Group)\n",
      "5.1/test2/var1 (Dataset)\n",
      "5.1/test3 (Group)\n",
      "5.1/test3/var1 (Dataset)\n",
      "50.1 (Group)\n",
      "50.1/test1 (Group)\n",
      "50.1/test1/var1 (Dataset)\n",
      "50.1/test2 (Group)\n",
      "50.1/test2/var1 (Dataset)\n",
      "50.1/test3 (Group)\n",
      "50.1/test3/var1 (Dataset)\n",
      "50.2 (Group)\n",
      "50.2/test1 (Group)\n",
      "50.2/test1/var1 (Dataset)\n",
      "50.2/test2 (Group)\n",
      "50.2/test2/var1 (Dataset)\n",
      "50.2/test3 (Group)\n",
      "50.2/test3/var1 (Dataset)\n",
      "50.3 (Group)\n",
      "50.3/test1 (Group)\n",
      "50.3/test1/var1 (Dataset)\n",
      "50.3/test2 (Group)\n",
      "50.3/test2/var1 (Dataset)\n",
      "50.3/test3 (Group)\n",
      "50.3/test3/var1 (Dataset)\n",
      "50.4 (Group)\n",
      "50.4/test1 (Group)\n",
      "50.4/test1/var1 (Dataset)\n",
      "50.4/test1/var2 (Dataset)\n",
      "50.4/test1/var3 (Dataset)\n",
      "50.4/test2 (Group)\n",
      "50.4/test2/var1 (Dataset)\n",
      "50.4/test2/var2 (Dataset)\n",
      "50.4/test2/var3 (Dataset)\n",
      "50.4/test3 (Group)\n",
      "50.4/test3/var1 (Dataset)\n",
      "50.4/test3/var2 (Dataset)\n",
      "50.4/test3/var3 (Dataset)\n",
      "51.1 (Group)\n",
      "51.1/test1 (Group)\n",
      "51.1/test1/var1 (Dataset)\n",
      "51.1/test2 (Group)\n",
      "51.1/test2/var1 (Dataset)\n",
      "51.1/test3 (Group)\n",
      "51.1/test3/var1 (Dataset)\n",
      "51.2 (Group)\n",
      "51.2/test1 (Group)\n",
      "51.2/test1/var1 (Dataset)\n",
      "51.2/test2 (Group)\n",
      "51.2/test2/var1 (Dataset)\n",
      "51.2/test3 (Group)\n",
      "51.2/test3/var1 (Dataset)\n",
      "51.3 (Group)\n",
      "51.3/test1 (Group)\n",
      "51.3/test1/var1 (Dataset)\n",
      "51.3/test1/var2 (Dataset)\n",
      "51.3/test2 (Group)\n",
      "51.3/test2/var1 (Dataset)\n",
      "51.3/test2/var2 (Dataset)\n",
      "51.3/test3 (Group)\n",
      "51.3/test3/var1 (Dataset)\n",
      "51.3/test3/var2 (Dataset)\n",
      "51.4 (Group)\n",
      "51.4/test1 (Group)\n",
      "51.4/test1/var1 (Dataset)\n",
      "51.4/test1/var2 (Dataset)\n",
      "51.4/test2 (Group)\n",
      "51.4/test2/var1 (Dataset)\n",
      "51.4/test2/var2 (Dataset)\n",
      "51.4/test3 (Group)\n",
      "51.4/test3/var1 (Dataset)\n",
      "51.4/test3/var2 (Dataset)\n",
      "51.4/test4 (Group)\n",
      "51.4/test4/var1 (Dataset)\n",
      "51.4/test4/var2 (Dataset)\n",
      "51.4/test4/var3 (Dataset)\n",
      "52.1 (Group)\n",
      "52.1/test1 (Group)\n",
      "52.1/test1/var1 (Dataset)\n",
      "52.1/test2 (Group)\n",
      "52.1/test2/var1 (Dataset)\n",
      "52.1/test3 (Group)\n",
      "52.1/test3/var1 (Dataset)\n",
      "52.2 (Group)\n",
      "52.2/test1 (Group)\n",
      "52.2/test1/var1 (Dataset)\n",
      "52.2/test2 (Group)\n",
      "52.2/test2/var1 (Dataset)\n",
      "52.2/test3 (Group)\n",
      "52.2/test3/var1 (Dataset)\n",
      "52.3 (Group)\n",
      "52.3/test1 (Group)\n",
      "52.3/test1/var1 (Dataset)\n",
      "52.3/test2 (Group)\n",
      "52.3/test2/var1 (Dataset)\n",
      "52.3/test3 (Group)\n",
      "52.3/test3/var1 (Dataset)\n",
      "52.4 (Group)\n",
      "52.4/test1 (Group)\n",
      "52.4/test1/var1 (Dataset)\n",
      "52.4/test2 (Group)\n",
      "52.4/test2/var1 (Dataset)\n",
      "52.4/test3 (Group)\n",
      "52.4/test3/var1 (Dataset)\n",
      "53.1 (Group)\n",
      "53.1/test1 (Group)\n",
      "53.1/test1/var1 (Dataset)\n",
      "53.1/test1/var2 (Dataset)\n",
      "53.1/test1/var3 (Dataset)\n",
      "53.1/test1/var4 (Dataset)\n",
      "53.1/test2 (Group)\n",
      "53.1/test2/var1 (Dataset)\n",
      "53.1/test2/var2 (Dataset)\n",
      "53.1/test2/var3 (Dataset)\n",
      "53.1/test2/var4 (Dataset)\n",
      "53.1/test3 (Group)\n",
      "53.1/test3/var1 (Dataset)\n",
      "53.1/test3/var2 (Dataset)\n",
      "53.1/test3/var3 (Dataset)\n",
      "53.1/test3/var4 (Dataset)\n",
      "53.2 (Group)\n",
      "53.2/test1 (Group)\n",
      "53.2/test1/var1 (Dataset)\n",
      "53.2/test1/var2 (Dataset)\n",
      "53.2/test1/var3 (Dataset)\n",
      "53.2/test1/var4 (Dataset)\n",
      "53.2/test2 (Group)\n",
      "53.2/test2/var1 (Dataset)\n",
      "53.2/test2/var2 (Dataset)\n",
      "53.2/test2/var3 (Dataset)\n",
      "53.2/test2/var4 (Dataset)\n",
      "53.2/test3 (Group)\n",
      "53.2/test3/var1 (Dataset)\n",
      "53.2/test3/var2 (Dataset)\n",
      "53.2/test3/var3 (Dataset)\n",
      "53.2/test3/var4 (Dataset)\n",
      "53.3 (Group)\n",
      "53.3/test1 (Group)\n",
      "53.3/test1/var1 (Dataset)\n",
      "53.3/test2 (Group)\n",
      "53.3/test2/var1 (Dataset)\n",
      "53.3/test3 (Group)\n",
      "53.3/test3/var1 (Dataset)\n",
      "53.4 (Group)\n",
      "53.4/test1 (Group)\n",
      "53.4/test1/var1 (Dataset)\n",
      "53.4/test1/var2 (Dataset)\n",
      "53.4/test1/var3 (Dataset)\n",
      "53.4/test1/var4 (Dataset)\n",
      "53.4/test1/var5 (Dataset)\n",
      "53.4/test1/var6 (Dataset)\n",
      "53.4/test2 (Group)\n",
      "53.4/test2/var1 (Dataset)\n",
      "53.4/test2/var2 (Dataset)\n",
      "53.4/test2/var3 (Dataset)\n",
      "53.4/test2/var4 (Dataset)\n",
      "53.4/test2/var5 (Dataset)\n",
      "53.4/test2/var6 (Dataset)\n",
      "53.4/test3 (Group)\n",
      "53.4/test3/var1 (Dataset)\n",
      "53.4/test3/var2 (Dataset)\n",
      "53.4/test3/var3 (Dataset)\n",
      "53.4/test3/var4 (Dataset)\n",
      "53.4/test3/var5 (Dataset)\n",
      "53.4/test3/var6 (Dataset)\n",
      "54.1 (Group)\n",
      "54.1/test1 (Group)\n",
      "54.1/test1/var1 (Dataset)\n",
      "54.1/test2 (Group)\n",
      "54.1/test2/var1 (Dataset)\n",
      "54.1/test3 (Group)\n",
      "54.1/test3/var1 (Dataset)\n",
      "54.2 (Group)\n",
      "54.2/test1 (Group)\n",
      "54.2/test1/var1 (Dataset)\n",
      "54.2/test1/var2 (Dataset)\n",
      "54.2/test2 (Group)\n",
      "54.2/test2/var1 (Dataset)\n",
      "54.2/test2/var2 (Dataset)\n",
      "54.2/test3 (Group)\n",
      "54.2/test3/var1 (Dataset)\n",
      "54.2/test3/var2 (Dataset)\n",
      "54.3 (Group)\n",
      "54.3/test1 (Group)\n",
      "54.3/test1/var1 (Dataset)\n",
      "54.3/test1/var2 (Dataset)\n",
      "54.3/test2 (Group)\n",
      "54.3/test2/var1 (Dataset)\n",
      "54.3/test2/var2 (Dataset)\n",
      "54.3/test3 (Group)\n",
      "54.3/test3/var1 (Dataset)\n",
      "54.3/test3/var2 (Dataset)\n",
      "54.4 (Group)\n",
      "54.4/test1 (Group)\n",
      "54.4/test1/var1 (Dataset)\n",
      "54.4/test2 (Group)\n",
      "54.4/test2/var1 (Dataset)\n",
      "54.4/test3 (Group)\n",
      "54.4/test3/var1 (Dataset)\n",
      "54.4/test4 (Group)\n",
      "54.4/test4/var1 (Dataset)\n",
      "54.4/test5 (Group)\n",
      "54.4/test5/var1 (Dataset)\n",
      "54.4/test6 (Group)\n",
      "54.4/test6/var1 (Dataset)\n",
      "55.1 (Group)\n",
      "55.1/test1 (Group)\n",
      "55.1/test1/var1 (Dataset)\n",
      "55.1/test2 (Group)\n",
      "55.1/test2/var1 (Dataset)\n",
      "55.1/test3 (Group)\n",
      "55.1/test3/var1 (Dataset)\n",
      "55.2 (Group)\n",
      "55.2/test1 (Group)\n",
      "55.2/test1/var1 (Dataset)\n",
      "55.2/test1/var2 (Dataset)\n",
      "55.2/test1/var3 (Dataset)\n",
      "55.2/test2 (Group)\n",
      "55.2/test2/var1 (Dataset)\n",
      "55.2/test2/var2 (Dataset)\n",
      "55.2/test2/var3 (Dataset)\n",
      "55.2/test3 (Group)\n",
      "55.2/test3/var1 (Dataset)\n",
      "55.2/test3/var2 (Dataset)\n",
      "55.2/test3/var3 (Dataset)\n",
      "55.3 (Group)\n",
      "55.3/test1 (Group)\n",
      "55.3/test1/var1 (Dataset)\n",
      "55.3/test1/var2 (Dataset)\n",
      "55.3/test2 (Group)\n",
      "55.3/test2/var1 (Dataset)\n",
      "55.3/test2/var2 (Dataset)\n",
      "55.3/test3 (Group)\n",
      "55.3/test3/var1 (Dataset)\n",
      "55.3/test3/var2 (Dataset)\n",
      "55.4 (Group)\n",
      "55.4/test1 (Group)\n",
      "55.4/test1/var1 (Dataset)\n",
      "55.4/test1/var2 (Dataset)\n",
      "55.4/test1/var3 (Dataset)\n",
      "55.4/test1/var4 (Dataset)\n",
      "55.4/test2 (Group)\n",
      "55.4/test2/var1 (Dataset)\n",
      "55.4/test2/var2 (Dataset)\n",
      "55.4/test2/var3 (Dataset)\n",
      "55.4/test2/var4 (Dataset)\n",
      "55.4/test3 (Group)\n",
      "55.4/test3/var1 (Dataset)\n",
      "55.4/test3/var2 (Dataset)\n",
      "55.4/test3/var3 (Dataset)\n",
      "55.4/test3/var4 (Dataset)\n",
      "55.4/test4 (Group)\n",
      "55.4/test4/var1 (Dataset)\n",
      "55.4/test4/var2 (Dataset)\n",
      "55.4/test4/var3 (Dataset)\n",
      "55.4/test4/var4 (Dataset)\n",
      "55.4/test5 (Group)\n",
      "55.4/test5/var1 (Dataset)\n",
      "55.4/test5/var2 (Dataset)\n",
      "55.4/test5/var3 (Dataset)\n",
      "55.4/test5/var4 (Dataset)\n",
      "55.4/test6 (Group)\n",
      "55.4/test6/var1 (Dataset)\n",
      "55.4/test6/var2 (Dataset)\n",
      "55.4/test6/var3 (Dataset)\n",
      "55.4/test6/var4 (Dataset)\n",
      "56.1 (Group)\n",
      "56.1/test1 (Group)\n",
      "56.1/test1/var1 (Dataset)\n",
      "56.1/test2 (Group)\n",
      "56.1/test2/var1 (Dataset)\n",
      "56.1/test3 (Group)\n",
      "56.1/test3/var1 (Dataset)\n",
      "56.2 (Group)\n",
      "56.2/test1 (Group)\n",
      "56.2/test1/var1 (Dataset)\n",
      "56.2/test2 (Group)\n",
      "56.2/test2/var1 (Dataset)\n",
      "56.2/test3 (Group)\n",
      "56.2/test3/var1 (Dataset)\n",
      "56.3 (Group)\n",
      "56.3/test1 (Group)\n",
      "56.3/test1/var1 (Dataset)\n",
      "56.3/test2 (Group)\n",
      "56.3/test2/var1 (Dataset)\n",
      "56.3/test3 (Group)\n",
      "56.3/test3/var1 (Dataset)\n",
      "56.4 (Group)\n",
      "56.4/test1 (Group)\n",
      "56.4/test1/var1 (Dataset)\n",
      "56.4/test2 (Group)\n",
      "56.4/test2/var1 (Dataset)\n",
      "56.4/test3 (Group)\n",
      "56.4/test3/var1 (Dataset)\n",
      "57.1 (Group)\n",
      "57.1/test1 (Group)\n",
      "57.1/test1/var1 (Dataset)\n",
      "57.1/test2 (Group)\n",
      "57.1/test2/var1 (Dataset)\n",
      "57.1/test3 (Group)\n",
      "57.1/test3/var1 (Dataset)\n",
      "57.2 (Group)\n",
      "57.2/test1 (Group)\n",
      "57.2/test1/var1 (Dataset)\n",
      "57.2/test2 (Group)\n",
      "57.2/test2/var1 (Dataset)\n",
      "57.2/test3 (Group)\n",
      "57.2/test3/var1 (Dataset)\n",
      "57.3 (Group)\n",
      "57.3/test1 (Group)\n",
      "57.3/test1/var1 (Dataset)\n",
      "57.3/test2 (Group)\n",
      "57.3/test2/var1 (Dataset)\n",
      "57.3/test3 (Group)\n",
      "57.3/test3/var1 (Dataset)\n",
      "57.4 (Group)\n",
      "57.4/test1 (Group)\n",
      "57.4/test1/var1 (Dataset)\n",
      "57.4/test2 (Group)\n",
      "57.4/test2/var1 (Dataset)\n",
      "57.4/test3 (Group)\n",
      "57.4/test3/var1 (Dataset)\n",
      "57.5 (Group)\n",
      "57.5/test1 (Group)\n",
      "57.5/test1/var1 (Dataset)\n",
      "57.5/test2 (Group)\n",
      "57.5/test2/var1 (Dataset)\n",
      "57.5/test3 (Group)\n",
      "57.5/test3/var1 (Dataset)\n",
      "58.1 (Group)\n",
      "58.1/test1 (Group)\n",
      "58.1/test1/var1 (Dataset)\n",
      "58.1/test2 (Group)\n",
      "58.1/test2/var1 (Dataset)\n",
      "58.1/test3 (Group)\n",
      "58.1/test3/var1 (Dataset)\n",
      "58.2 (Group)\n",
      "58.2/test1 (Group)\n",
      "58.2/test1/var1 (Dataset)\n",
      "58.2/test2 (Group)\n",
      "58.2/test2/var1 (Dataset)\n",
      "58.2/test3 (Group)\n",
      "58.2/test3/var1 (Dataset)\n",
      "58.3 (Group)\n",
      "58.3/test1 (Group)\n",
      "58.3/test1/var1 (Dataset)\n",
      "58.3/test2 (Group)\n",
      "58.3/test2/var1 (Dataset)\n",
      "58.3/test3 (Group)\n",
      "58.3/test3/var1 (Dataset)\n",
      "58.4 (Group)\n",
      "58.4/test1 (Group)\n",
      "58.4/test1/var1 (Dataset)\n",
      "58.4/test2 (Group)\n",
      "58.4/test2/var1 (Dataset)\n",
      "58.4/test3 (Group)\n",
      "58.4/test3/var1 (Dataset)\n",
      "58.5 (Group)\n",
      "58.5/test1 (Group)\n",
      "58.5/test1/var1 (Dataset)\n",
      "58.5/test1/var2 (Dataset)\n",
      "58.5/test2 (Group)\n",
      "58.5/test2/var1 (Dataset)\n",
      "58.5/test2/var2 (Dataset)\n",
      "58.5/test3 (Group)\n",
      "58.5/test3/var1 (Dataset)\n",
      "58.5/test3/var2 (Dataset)\n",
      "58.5/test4 (Group)\n",
      "58.5/test4/var1 (Dataset)\n",
      "58.5/test4/var2 (Dataset)\n",
      "59.1 (Group)\n",
      "59.1/test1 (Group)\n",
      "59.1/test1/var1 (Dataset)\n",
      "59.1/test2 (Group)\n",
      "59.1/test2/var1 (Dataset)\n",
      "59.1/test3 (Group)\n",
      "59.1/test3/var1 (Dataset)\n",
      "59.2 (Group)\n",
      "59.2/test1 (Group)\n",
      "59.2/test1/var1 (Dataset)\n",
      "59.2/test2 (Group)\n",
      "59.2/test2/var1 (Dataset)\n",
      "59.2/test3 (Group)\n",
      "59.2/test3/var1 (Dataset)\n",
      "59.3 (Group)\n",
      "59.3/test1 (Group)\n",
      "59.3/test1/var1 (Dataset)\n",
      "59.3/test2 (Group)\n",
      "59.3/test2/var1 (Dataset)\n",
      "59.3/test3 (Group)\n",
      "59.3/test3/var1 (Dataset)\n",
      "59.4 (Group)\n",
      "59.4/test1 (Group)\n",
      "59.4/test1/var1 (Dataset)\n",
      "59.4/test2 (Group)\n",
      "59.4/test2/var1 (Dataset)\n",
      "59.4/test3 (Group)\n",
      "59.4/test3/var1 (Dataset)\n",
      "59.5 (Group)\n",
      "59.5/test1 (Group)\n",
      "59.5/test1/var1 (Dataset)\n",
      "59.5/test2 (Group)\n",
      "59.5/test2/var1 (Dataset)\n",
      "59.5/test3 (Group)\n",
      "59.5/test3/var1 (Dataset)\n",
      "6.1 (Group)\n",
      "6.1/test1 (Group)\n",
      "6.1/test1/var1 (Dataset)\n",
      "6.1/test1/var2 (Dataset)\n",
      "6.1/test2 (Group)\n",
      "6.1/test2/var1 (Dataset)\n",
      "6.1/test2/var2 (Dataset)\n",
      "6.1/test3 (Group)\n",
      "6.1/test3/var1 (Dataset)\n",
      "6.1/test3/var2 (Dataset)\n",
      "6.1/test4 (Group)\n",
      "6.1/test4/var1 (Dataset)\n",
      "60.1 (Group)\n",
      "60.1/test1 (Group)\n",
      "60.1/test1/var1 (Dataset)\n",
      "60.1/test2 (Group)\n",
      "60.1/test2/var1 (Dataset)\n",
      "60.1/test3 (Group)\n",
      "60.1/test3/var1 (Dataset)\n",
      "60.2 (Group)\n",
      "60.2/test1 (Group)\n",
      "60.2/test1/var1 (Dataset)\n",
      "60.2/test2 (Group)\n",
      "60.2/test2/var1 (Dataset)\n",
      "60.2/test3 (Group)\n",
      "60.2/test3/var1 (Dataset)\n",
      "60.3 (Group)\n",
      "60.3/test1 (Group)\n",
      "60.3/test1/var1 (Dataset)\n",
      "60.3/test2 (Group)\n",
      "60.3/test2/var1 (Dataset)\n",
      "60.3/test3 (Group)\n",
      "60.3/test3/var1 (Dataset)\n",
      "60.4 (Group)\n",
      "60.4/test1 (Group)\n",
      "60.4/test1/var1 (Dataset)\n",
      "60.4/test1/var2 (Dataset)\n",
      "60.4/test2 (Group)\n",
      "60.4/test2/var1 (Dataset)\n",
      "60.4/test2/var2 (Dataset)\n",
      "60.4/test2/var3 (Dataset)\n",
      "60.4/test3 (Group)\n",
      "60.4/test3/var1 (Dataset)\n",
      "60.4/test3/var2 (Dataset)\n",
      "60.5 (Group)\n",
      "60.5/test1 (Group)\n",
      "60.5/test1/var1 (Dataset)\n",
      "60.5/test2 (Group)\n",
      "60.5/test2/var1 (Dataset)\n",
      "61.1 (Group)\n",
      "61.1/test1 (Group)\n",
      "61.1/test1/var1 (Dataset)\n",
      "61.1/test2 (Group)\n",
      "61.1/test2/var1 (Dataset)\n",
      "61.1/test3 (Group)\n",
      "61.1/test3/var1 (Dataset)\n",
      "61.2 (Group)\n",
      "61.2/test1 (Group)\n",
      "61.2/test1/var1 (Dataset)\n",
      "61.2/test2 (Group)\n",
      "61.2/test2/var1 (Dataset)\n",
      "61.2/test3 (Group)\n",
      "61.2/test3/var1 (Dataset)\n",
      "61.3 (Group)\n",
      "61.3/test1 (Group)\n",
      "61.3/test1/var1 (Dataset)\n",
      "61.3/test1/var2 (Dataset)\n",
      "61.3/test2 (Group)\n",
      "61.3/test2/var1 (Dataset)\n",
      "61.3/test2/var2 (Dataset)\n",
      "61.3/test3 (Group)\n",
      "61.3/test3/var1 (Dataset)\n",
      "61.3/test3/var2 (Dataset)\n",
      "61.4 (Group)\n",
      "61.4/test1 (Group)\n",
      "61.4/test1/var1 (Dataset)\n",
      "61.4/test2 (Group)\n",
      "61.4/test2/var1 (Dataset)\n",
      "61.4/test3 (Group)\n",
      "61.4/test3/var1 (Dataset)\n",
      "61.5 (Group)\n",
      "61.5/test1 (Group)\n",
      "61.5/test1/var1 (Dataset)\n",
      "61.5/test2 (Group)\n",
      "61.5/test2/var1 (Dataset)\n",
      "61.5/test3 (Group)\n",
      "61.5/test3/var1 (Dataset)\n",
      "61.5/test4 (Group)\n",
      "61.5/test4/var1 (Dataset)\n",
      "62.2 (Group)\n",
      "62.2/test1 (Group)\n",
      "62.2/test1/var1 (Dataset)\n",
      "62.2/test1/var2 (Dataset)\n",
      "62.2/test1/var3 (Group)\n",
      "62.2/test1/var3/H (Dataset)\n",
      "62.2/test1/var3/conn_Sp (Dataset)\n",
      "62.2/test1/var3/conn_Sz (Dataset)\n",
      "62.3 (Group)\n",
      "62.3/test1 (Group)\n",
      "62.3/test1/var1 (Dataset)\n",
      "62.4 (Group)\n",
      "62.4/test1 (Group)\n",
      "62.4/test1/var1 (Dataset)\n",
      "62.4/test1/var2 (Dataset)\n",
      "62.4/test1/var3 (Group)\n",
      "62.4/test1/var3/H (Group)\n",
      "62.4/test1/var3/H/sparse_matrix (Group)\n",
      "62.4/test1/var3/H/sparse_matrix/data (Dataset)\n",
      "62.4/test1/var3/H/sparse_matrix/indices (Dataset)\n",
      "62.4/test1/var3/H/sparse_matrix/indptr (Dataset)\n",
      "62.4/test1/var3/H/sparse_matrix/shape (Dataset)\n",
      "62.4/test1/var3/conn_Sp (Group)\n",
      "62.4/test1/var3/conn_Sp/sparse_matrix (Group)\n",
      "62.4/test1/var3/conn_Sp/sparse_matrix/col (Dataset)\n",
      "62.4/test1/var3/conn_Sp/sparse_matrix/data (Dataset)\n",
      "62.4/test1/var3/conn_Sp/sparse_matrix/row (Dataset)\n",
      "62.4/test1/var3/conn_Sp/sparse_matrix/shape (Dataset)\n",
      "62.4/test1/var3/conn_Sz (Group)\n",
      "62.4/test1/var3/conn_Sz/sparse_matrix (Group)\n",
      "62.4/test1/var3/conn_Sz/sparse_matrix/blocksize (Dataset)\n",
      "62.4/test1/var3/conn_Sz/sparse_matrix/data (Dataset)\n",
      "62.4/test1/var3/conn_Sz/sparse_matrix/indices (Dataset)\n",
      "62.4/test1/var3/conn_Sz/sparse_matrix/indptr (Dataset)\n",
      "62.4/test1/var3/conn_Sz/sparse_matrix/shape (Dataset)\n",
      "62.5 (Group)\n",
      "62.5/test1 (Group)\n",
      "62.5/test1/var1 (Dataset)\n",
      "62.5/test1/var2 (Dataset)\n",
      "62.5/test1/var3 (Group)\n",
      "62.5/test1/var3/H (Dataset)\n",
      "62.5/test1/var3/conn_Sp (Dataset)\n",
      "62.5/test1/var3/conn_Sz (Dataset)\n",
      "62.5/test1/var4 (Dataset)\n",
      "62.6 (Group)\n",
      "62.6/test1 (Group)\n",
      "62.6/test1/var1 (Dataset)\n",
      "62.6/test2 (Group)\n",
      "62.6/test2/var1 (Dataset)\n",
      "62.6/test3 (Group)\n",
      "62.6/test3/var1 (Dataset)\n",
      "62.6/test4 (Group)\n",
      "62.6/test4/var1 (Dataset)\n",
      "62.6/test5 (Group)\n",
      "62.6/test5/var1 (Dataset)\n",
      "62.6/test6 (Group)\n",
      "62.6/test6/var1 (Dataset)\n",
      "63.1 (Group)\n",
      "63.1/test1 (Group)\n",
      "63.1/test1/var1 (Dataset)\n",
      "63.1/test1/var2 (Dataset)\n",
      "63.1/test1/var3 (Dataset)\n",
      "63.1/test1/var4 (Dataset)\n",
      "63.1/test2 (Group)\n",
      "63.1/test2/var1 (Dataset)\n",
      "63.1/test2/var2 (Dataset)\n",
      "63.1/test2/var3 (Dataset)\n",
      "63.1/test2/var4 (Dataset)\n",
      "63.1/test3 (Group)\n",
      "63.1/test3/var1 (Dataset)\n",
      "63.1/test3/var2 (Dataset)\n",
      "63.1/test3/var3 (Dataset)\n",
      "63.1/test3/var4 (Dataset)\n",
      "63.2 (Group)\n",
      "63.2/test1 (Group)\n",
      "63.2/test1/var1 (Dataset)\n",
      "63.2/test2 (Group)\n",
      "63.2/test2/var1 (Dataset)\n",
      "63.2/test3 (Group)\n",
      "63.2/test3/var1 (Dataset)\n",
      "63.3 (Group)\n",
      "63.3/test1 (Group)\n",
      "63.3/test1/var1 (Dataset)\n",
      "63.3/test2 (Group)\n",
      "63.3/test2/var1 (Dataset)\n",
      "63.3/test3 (Group)\n",
      "63.3/test3/var1 (Dataset)\n",
      "63.4 (Group)\n",
      "63.4/test1 (Group)\n",
      "63.4/test1/var1 (Dataset)\n",
      "63.4/test2 (Group)\n",
      "63.4/test2/var1 (Dataset)\n",
      "63.4/test3 (Group)\n",
      "63.4/test3/var1 (Dataset)\n",
      "63.5 (Group)\n",
      "63.5/test1 (Group)\n",
      "63.5/test1/var1 (Dataset)\n",
      "63.5/test2 (Group)\n",
      "63.5/test2/var1 (Dataset)\n",
      "63.5/test3 (Group)\n",
      "63.5/test3/var1 (Dataset)\n",
      "63.6 (Group)\n",
      "63.6/test1 (Group)\n",
      "63.6/test1/var1 (Dataset)\n",
      "63.6/test2 (Group)\n",
      "63.6/test2/var1 (Dataset)\n",
      "63.6/test3 (Group)\n",
      "63.6/test3/var1 (Dataset)\n",
      "64.1 (Group)\n",
      "64.1/test1 (Group)\n",
      "64.1/test1/var1 (Dataset)\n",
      "64.1/test2 (Group)\n",
      "64.1/test2/var1 (Dataset)\n",
      "64.1/test3 (Group)\n",
      "64.1/test3/var1 (Dataset)\n",
      "64.2 (Group)\n",
      "64.2/test1 (Group)\n",
      "64.2/test1/var1 (Dataset)\n",
      "64.2/test2 (Group)\n",
      "64.2/test2/var1 (Dataset)\n",
      "64.2/test3 (Group)\n",
      "64.2/test3/var1 (Dataset)\n",
      "64.3 (Group)\n",
      "64.3/test1 (Group)\n",
      "64.3/test1/var1 (Dataset)\n",
      "64.3/test2 (Group)\n",
      "64.3/test2/var1 (Dataset)\n",
      "64.3/test3 (Group)\n",
      "64.3/test3/var1 (Dataset)\n",
      "64.4 (Group)\n",
      "64.4/test1 (Group)\n",
      "64.4/test1/var1 (Dataset)\n",
      "64.4/test2 (Group)\n",
      "64.4/test2/var1 (Dataset)\n",
      "64.4/test3 (Group)\n",
      "64.4/test3/var1 (Dataset)\n",
      "64.4/test4 (Group)\n",
      "64.4/test4/var1 (Dataset)\n",
      "64.5 (Group)\n",
      "64.5/test1 (Group)\n",
      "64.5/test1/var1 (Dataset)\n",
      "64.5/test2 (Group)\n",
      "64.5/test2/var1 (Dataset)\n",
      "64.5/test3 (Group)\n",
      "64.5/test3/var1 (Dataset)\n",
      "64.6 (Group)\n",
      "64.6/test1 (Group)\n",
      "64.6/test1/var1 (Dataset)\n",
      "65.1 (Group)\n",
      "65.1/test1 (Group)\n",
      "65.1/test1/var1 (Dataset)\n",
      "65.1/test2 (Group)\n",
      "65.1/test2/var1 (Dataset)\n",
      "65.1/test3 (Group)\n",
      "65.1/test3/var1 (Dataset)\n",
      "65.2 (Group)\n",
      "65.2/test1 (Group)\n",
      "65.2/test1/var1 (Dataset)\n",
      "65.2/test2 (Group)\n",
      "65.2/test2/var1 (Dataset)\n",
      "65.2/test3 (Group)\n",
      "65.2/test3/var1 (Dataset)\n",
      "65.3 (Group)\n",
      "65.3/test1 (Group)\n",
      "65.3/test1/var1 (Dataset)\n",
      "65.3/test2 (Group)\n",
      "65.3/test2/var1 (Dataset)\n",
      "65.3/test3 (Group)\n",
      "65.3/test3/var1 (Dataset)\n",
      "65.4 (Group)\n",
      "65.4/test1 (Group)\n",
      "65.4/test1/var1 (Dataset)\n",
      "65.4/test2 (Group)\n",
      "65.4/test2/var1 (Dataset)\n",
      "65.4/test3 (Group)\n",
      "65.4/test3/var1 (Dataset)\n",
      "65.5 (Group)\n",
      "65.5/test1 (Group)\n",
      "65.5/test1/var1 (Dataset)\n",
      "65.5/test2 (Group)\n",
      "65.5/test2/var1 (Dataset)\n",
      "65.5/test3 (Group)\n",
      "65.5/test3/var1 (Dataset)\n",
      "65.6 (Group)\n",
      "65.6/test1 (Group)\n",
      "65.6/test1/var1 (Dataset)\n",
      "65.6/test2 (Group)\n",
      "65.6/test2/var1 (Dataset)\n",
      "65.6/test3 (Group)\n",
      "65.6/test3/var1 (Dataset)\n",
      "65.6/test4 (Group)\n",
      "65.6/test4/var1 (Dataset)\n",
      "65.6/test5 (Group)\n",
      "65.6/test5/var1 (Dataset)\n",
      "66.1 (Group)\n",
      "66.1/test1 (Group)\n",
      "66.1/test1/var1 (Dataset)\n",
      "66.1/test2 (Group)\n",
      "66.1/test2/var1 (Dataset)\n",
      "66.1/test3 (Group)\n",
      "66.1/test3/var1 (Dataset)\n",
      "66.2 (Group)\n",
      "66.2/test1 (Group)\n",
      "66.2/test1/var1 (Dataset)\n",
      "66.2/test2 (Group)\n",
      "66.2/test2/var1 (Dataset)\n",
      "66.2/test3 (Group)\n",
      "66.2/test3/var1 (Dataset)\n",
      "66.3 (Group)\n",
      "66.3/test1 (Group)\n",
      "66.3/test1/var1 (Dataset)\n",
      "66.3/test2 (Group)\n",
      "66.3/test2/var1 (Dataset)\n",
      "66.3/test3 (Group)\n",
      "66.3/test3/var1 (Dataset)\n",
      "66.4 (Group)\n",
      "66.4/test1 (Group)\n",
      "66.4/test1/var1 (Dataset)\n",
      "66.4/test2 (Group)\n",
      "66.4/test2/var1 (Dataset)\n",
      "66.4/test3 (Group)\n",
      "66.4/test3/var1 (Dataset)\n",
      "66.5 (Group)\n",
      "66.5/test1 (Group)\n",
      "66.5/test1/var1 (Dataset)\n",
      "66.5/test2 (Group)\n",
      "66.5/test2/var1 (Dataset)\n",
      "66.5/test3 (Group)\n",
      "66.5/test3/var1 (Dataset)\n",
      "66.6 (Group)\n",
      "66.6/test1 (Group)\n",
      "66.6/test1/var1 (Dataset)\n",
      "66.6/test2 (Group)\n",
      "66.6/test2/var1 (Dataset)\n",
      "66.6/test3 (Group)\n",
      "66.6/test3/var1 (Dataset)\n",
      "66.6/test4 (Group)\n",
      "66.6/test4/var1 (Dataset)\n",
      "66.6/test5 (Group)\n",
      "66.6/test5/var1 (Dataset)\n",
      "66.6/test6 (Group)\n",
      "66.6/test6/var1 (Dataset)\n",
      "67.1 (Group)\n",
      "67.1/test1 (Group)\n",
      "67.1/test1/var1 (Dataset)\n",
      "67.1/test2 (Group)\n",
      "67.1/test2/var1 (Dataset)\n",
      "67.1/test3 (Group)\n",
      "67.1/test3/var1 (Dataset)\n",
      "67.2 (Group)\n",
      "67.2/test1 (Group)\n",
      "67.2/test1/var1 (Dataset)\n",
      "67.2/test2 (Group)\n",
      "67.2/test2/var1 (Dataset)\n",
      "67.2/test3 (Group)\n",
      "67.2/test3/var1 (Dataset)\n",
      "67.3 (Group)\n",
      "67.3/test1 (Group)\n",
      "67.3/test1/var1 (Dataset)\n",
      "67.3/test2 (Group)\n",
      "67.3/test2/var1 (Dataset)\n",
      "67.3/test3 (Group)\n",
      "67.3/test3/var1 (Dataset)\n",
      "67.4 (Group)\n",
      "67.4/test1 (Group)\n",
      "67.4/test1/var1 (Dataset)\n",
      "67.4/test2 (Group)\n",
      "67.4/test2/var1 (Dataset)\n",
      "67.4/test3 (Group)\n",
      "67.4/test3/var1 (Dataset)\n",
      "67.5 (Group)\n",
      "67.5/test1 (Group)\n",
      "67.5/test1/var1 (Dataset)\n",
      "67.5/test2 (Group)\n",
      "67.5/test2/var1 (Dataset)\n",
      "67.5/test3 (Group)\n",
      "67.5/test3/var1 (Dataset)\n",
      "67.6 (Group)\n",
      "67.6/test1 (Group)\n",
      "67.6/test1/var1 (Dataset)\n",
      "67.6/test2 (Group)\n",
      "67.6/test2/var1 (Dataset)\n",
      "67.6/test3 (Group)\n",
      "67.6/test3/var1 (Dataset)\n",
      "67.6/test4 (Group)\n",
      "67.6/test4/var1 (Dataset)\n",
      "68.1 (Group)\n",
      "68.1/test1 (Group)\n",
      "68.1/test1/var1 (Dataset)\n",
      "68.1/test1/var2 (Dataset)\n",
      "68.1/test1/var3 (Dataset)\n",
      "68.1/test1/var4 (Dataset)\n",
      "68.1/test2 (Group)\n",
      "68.1/test2/var1 (Dataset)\n",
      "68.1/test2/var2 (Dataset)\n",
      "68.1/test2/var3 (Dataset)\n",
      "68.1/test2/var4 (Dataset)\n",
      "68.1/test3 (Group)\n",
      "68.1/test3/var1 (Dataset)\n",
      "68.1/test3/var2 (Dataset)\n",
      "68.1/test3/var3 (Dataset)\n",
      "68.1/test3/var4 (Dataset)\n",
      "68.2 (Group)\n",
      "68.2/test1 (Group)\n",
      "68.2/test1/var1 (Dataset)\n",
      "68.2/test1/var2 (Dataset)\n",
      "68.2/test1/var3 (Dataset)\n",
      "68.2/test1/var4 (Dataset)\n",
      "68.2/test1/var5 (Dataset)\n",
      "68.2/test2 (Group)\n",
      "68.2/test2/var1 (Dataset)\n",
      "68.2/test2/var2 (Dataset)\n",
      "68.2/test2/var3 (Dataset)\n",
      "68.2/test2/var4 (Dataset)\n",
      "68.2/test2/var5 (Dataset)\n",
      "68.2/test3 (Group)\n",
      "68.2/test3/var1 (Dataset)\n",
      "68.2/test3/var2 (Dataset)\n",
      "68.2/test3/var3 (Dataset)\n",
      "68.2/test3/var4 (Dataset)\n",
      "68.2/test3/var5 (Dataset)\n",
      "68.3 (Group)\n",
      "68.3/test1 (Group)\n",
      "68.3/test1/var1 (Dataset)\n",
      "68.3/test2 (Group)\n",
      "68.3/test2/var1 (Dataset)\n",
      "68.3/test3 (Group)\n",
      "68.3/test3/var1 (Dataset)\n",
      "68.3/test4 (Group)\n",
      "68.3/test4/var1 (Dataset)\n",
      "68.3/test5 (Group)\n",
      "68.3/test5/var1 (Dataset)\n",
      "68.3/test6 (Group)\n",
      "68.3/test6/var1 (Dataset)\n",
      "68.4 (Group)\n",
      "68.4/test1 (Group)\n",
      "68.4/test1/var1 (Dataset)\n",
      "68.4/test1/var2 (Dataset)\n",
      "68.4/test1/var3 (Dataset)\n",
      "68.4/test2 (Group)\n",
      "68.4/test2/var1 (Dataset)\n",
      "68.4/test2/var2 (Dataset)\n",
      "68.4/test2/var3 (Dataset)\n",
      "68.4/test3 (Group)\n",
      "68.4/test3/var1 (Dataset)\n",
      "68.4/test3/var2 (Dataset)\n",
      "68.4/test3/var3 (Dataset)\n",
      "68.5 (Group)\n",
      "68.5/test1 (Group)\n",
      "68.5/test1/var1 (Dataset)\n",
      "68.5/test2 (Group)\n",
      "68.5/test2/var1 (Dataset)\n",
      "68.5/test3 (Group)\n",
      "68.5/test3/var1 (Dataset)\n",
      "68.6 (Group)\n",
      "68.6/test1 (Group)\n",
      "68.6/test1/var1 (Dataset)\n",
      "68.6/test2 (Group)\n",
      "68.6/test2/var1 (Dataset)\n",
      "68.6/test3 (Group)\n",
      "68.6/test3/var1 (Dataset)\n",
      "68.7 (Group)\n",
      "68.7/test1 (Group)\n",
      "68.7/test1/var1 (Dataset)\n",
      "68.7/test2 (Group)\n",
      "68.7/test2/var1 (Dataset)\n",
      "68.7/test3 (Group)\n",
      "68.7/test3/var1 (Dataset)\n",
      "68.8 (Group)\n",
      "68.8/test1 (Group)\n",
      "68.8/test1/var1 (Dataset)\n",
      "68.8/test2 (Group)\n",
      "68.8/test2/var1 (Dataset)\n",
      "68.8/test3 (Group)\n",
      "68.8/test3/var1 (Dataset)\n",
      "68.8/test4 (Group)\n",
      "68.8/test4/var1 (Dataset)\n",
      "68.8/test5 (Group)\n",
      "68.8/test5/var1 (Dataset)\n",
      "69.1 (Group)\n",
      "69.1/test1 (Group)\n",
      "69.1/test1/var1 (Dataset)\n",
      "69.1/test2 (Group)\n",
      "69.1/test2/var1 (Dataset)\n",
      "69.1/test3 (Group)\n",
      "69.1/test3/var1 (Dataset)\n",
      "69.2 (Group)\n",
      "69.2/test1 (Group)\n",
      "69.2/test1/var1 (Dataset)\n",
      "69.2/test2 (Group)\n",
      "69.2/test2/var1 (Dataset)\n",
      "69.2/test3 (Group)\n",
      "69.2/test3/var1 (Dataset)\n",
      "69.3 (Group)\n",
      "69.3/test1 (Group)\n",
      "69.3/test1/var1 (Dataset)\n",
      "69.3/test2 (Group)\n",
      "69.3/test2/var1 (Dataset)\n",
      "69.3/test3 (Group)\n",
      "69.3/test3/var1 (Dataset)\n",
      "69.4 (Group)\n",
      "69.4/test1 (Group)\n",
      "69.4/test1/var1 (Dataset)\n",
      "69.4/test2 (Group)\n",
      "69.4/test2/var1 (Dataset)\n",
      "69.4/test3 (Group)\n",
      "69.4/test3/var1 (Dataset)\n",
      "69.5 (Group)\n",
      "69.5/test1 (Group)\n",
      "69.5/test1/var1 (Dataset)\n",
      "69.5/test2 (Group)\n",
      "69.5/test2/var1 (Dataset)\n",
      "69.5/test3 (Group)\n",
      "69.5/test3/var1 (Dataset)\n",
      "69.6 (Group)\n",
      "69.6/test1 (Group)\n",
      "69.6/test1/var1 (Dataset)\n",
      "69.6/test2 (Group)\n",
      "69.6/test2/var1 (Dataset)\n",
      "69.6/test3 (Group)\n",
      "69.6/test3/var1 (Dataset)\n",
      "69.7 (Group)\n",
      "69.7/test1 (Group)\n",
      "69.7/test1/var1 (Dataset)\n",
      "69.7/test2 (Group)\n",
      "69.7/test2/var1 (Dataset)\n",
      "69.7/test3 (Group)\n",
      "69.7/test3/var1 (Dataset)\n",
      "69.8 (Group)\n",
      "69.8/test1 (Group)\n",
      "69.8/test1/var1 (Dataset)\n",
      "69.8/test2 (Group)\n",
      "69.8/test2/var1 (Dataset)\n",
      "69.8/test3 (Group)\n",
      "69.8/test3/var1 (Dataset)\n",
      "69.8/test4 (Group)\n",
      "69.8/test4/var1 (Dataset)\n",
      "7.1 (Group)\n",
      "7.1/test1 (Group)\n",
      "7.1/test1/var1 (Dataset)\n",
      "7.1/test1/var2 (Dataset)\n",
      "7.1/test2 (Group)\n",
      "7.1/test2/var1 (Dataset)\n",
      "7.1/test2/var2 (Dataset)\n",
      "7.1/test3 (Group)\n",
      "7.1/test3/var1 (Dataset)\n",
      "7.1/test3/var2 (Dataset)\n",
      "7.1/test4 (Group)\n",
      "7.1/test4/var1 (Dataset)\n",
      "70.1 (Group)\n",
      "70.1/test1 (Group)\n",
      "70.1/test1/var1 (Dataset)\n",
      "70.1/test2 (Group)\n",
      "70.1/test2/var1 (Dataset)\n",
      "70.1/test3 (Group)\n",
      "70.1/test3/var1 (Dataset)\n",
      "70.2 (Group)\n",
      "70.2/test1 (Group)\n",
      "70.2/test1/var1 (Dataset)\n",
      "70.2/test2 (Group)\n",
      "70.2/test2/var1 (Dataset)\n",
      "70.2/test3 (Group)\n",
      "70.2/test3/var1 (Dataset)\n",
      "70.3 (Group)\n",
      "70.3/test1 (Group)\n",
      "70.3/test1/var1 (Dataset)\n",
      "70.3/test2 (Group)\n",
      "70.3/test2/var1 (Dataset)\n",
      "70.3/test3 (Group)\n",
      "70.3/test3/var1 (Dataset)\n",
      "70.4 (Group)\n",
      "70.4/test1 (Group)\n",
      "70.4/test1/var1 (Dataset)\n",
      "70.4/test2 (Group)\n",
      "70.4/test2/var1 (Dataset)\n",
      "70.4/test3 (Group)\n",
      "70.4/test3/var1 (Dataset)\n",
      "70.5 (Group)\n",
      "70.5/test1 (Group)\n",
      "70.5/test1/var1 (Dataset)\n",
      "70.5/test2 (Group)\n",
      "70.5/test2/var1 (Dataset)\n",
      "70.5/test3 (Group)\n",
      "70.5/test3/var1 (Dataset)\n",
      "70.6 (Group)\n",
      "70.6/test1 (Group)\n",
      "70.6/test1/var1 (Group)\n",
      "70.6/test1/var1/list (Group)\n",
      "70.6/test1/var1/list/var1 (Dataset)\n",
      "70.6/test1/var1/list/var2 (Dataset)\n",
      "70.6/test1/var1/list/var3 (Dataset)\n",
      "70.6/test2 (Group)\n",
      "70.6/test2/var1 (Group)\n",
      "70.6/test2/var1/list (Group)\n",
      "70.6/test2/var1/list/var1 (Dataset)\n",
      "70.6/test2/var1/list/var2 (Dataset)\n",
      "70.6/test2/var1/list/var3 (Dataset)\n",
      "70.6/test3 (Group)\n",
      "70.6/test3/var1 (Group)\n",
      "70.6/test3/var1/list (Group)\n",
      "70.6/test3/var1/list/var1 (Dataset)\n",
      "70.6/test3/var1/list/var2 (Dataset)\n",
      "70.6/test3/var1/list/var3 (Dataset)\n",
      "70.7 (Group)\n",
      "70.7/test1 (Group)\n",
      "70.7/test1/var1 (Dataset)\n",
      "70.7/test2 (Group)\n",
      "70.7/test2/var1 (Dataset)\n",
      "70.7/test3 (Group)\n",
      "70.7/test3/var1 (Dataset)\n",
      "70.8 (Group)\n",
      "70.8/test1 (Group)\n",
      "70.8/test1/var1 (Dataset)\n",
      "70.8/test2 (Group)\n",
      "70.8/test2/var1 (Dataset)\n",
      "70.8/test3 (Group)\n",
      "70.8/test3/var1 (Dataset)\n",
      "70.8/test4 (Group)\n",
      "70.8/test4/var1 (Dataset)\n",
      "71.1 (Group)\n",
      "71.1/test1 (Group)\n",
      "71.1/test1/var1 (Dataset)\n",
      "71.1/test2 (Group)\n",
      "71.1/test2/var1 (Dataset)\n",
      "71.1/test3 (Group)\n",
      "71.1/test3/var1 (Dataset)\n",
      "71.2 (Group)\n",
      "71.2/test1 (Group)\n",
      "71.2/test1/var1 (Dataset)\n",
      "71.2/test2 (Group)\n",
      "71.2/test2/var1 (Dataset)\n",
      "71.2/test3 (Group)\n",
      "71.2/test3/var1 (Dataset)\n",
      "71.3 (Group)\n",
      "71.3/test1 (Group)\n",
      "71.3/test1/var1 (Dataset)\n",
      "71.3/test2 (Group)\n",
      "71.3/test2/var1 (Dataset)\n",
      "71.3/test3 (Group)\n",
      "71.3/test3/var1 (Dataset)\n",
      "71.4 (Group)\n",
      "71.4/test1 (Group)\n",
      "71.4/test1/var1 (Dataset)\n",
      "71.4/test2 (Group)\n",
      "71.4/test2/var1 (Dataset)\n",
      "71.4/test3 (Group)\n",
      "71.4/test3/var1 (Dataset)\n",
      "71.5 (Group)\n",
      "71.5/test1 (Group)\n",
      "71.5/test1/var1 (Dataset)\n",
      "71.5/test2 (Group)\n",
      "71.5/test2/var1 (Dataset)\n",
      "71.5/test3 (Group)\n",
      "71.5/test3/var1 (Dataset)\n",
      "71.6 (Group)\n",
      "71.6/test1 (Group)\n",
      "71.6/test1/var1 (Dataset)\n",
      "71.6/test2 (Group)\n",
      "71.6/test2/var1 (Dataset)\n",
      "71.6/test3 (Group)\n",
      "71.6/test3/var1 (Dataset)\n",
      "71.7 (Group)\n",
      "71.7/test1 (Group)\n",
      "71.7/test1/var1 (Dataset)\n",
      "71.7/test2 (Group)\n",
      "71.7/test2/var1 (Dataset)\n",
      "71.7/test3 (Group)\n",
      "71.7/test3/var1 (Dataset)\n",
      "71.8 (Group)\n",
      "71.8/test1 (Group)\n",
      "71.8/test1/var1 (Dataset)\n",
      "71.8/test2 (Group)\n",
      "71.8/test2/var1 (Dataset)\n",
      "71.8/test3 (Group)\n",
      "71.8/test3/var1 (Dataset)\n",
      "71.9 (Group)\n",
      "71.9/test1 (Group)\n",
      "71.9/test1/var1 (Dataset)\n",
      "71.9/test2 (Group)\n",
      "71.9/test2/var1 (Dataset)\n",
      "71.9/test3 (Group)\n",
      "71.9/test3/var1 (Dataset)\n",
      "71.9/test4 (Group)\n",
      "71.9/test4/var1 (Dataset)\n",
      "71.9/test5 (Group)\n",
      "71.9/test5/var1 (Dataset)\n",
      "72.1 (Group)\n",
      "72.1/test1 (Group)\n",
      "72.1/test1/var1 (Dataset)\n",
      "72.1/test2 (Group)\n",
      "72.1/test2/var1 (Dataset)\n",
      "72.1/test3 (Group)\n",
      "72.1/test3/var1 (Dataset)\n",
      "72.1/test4 (Group)\n",
      "72.1/test4/var1 (Dataset)\n",
      "72.2 (Group)\n",
      "72.2/test1 (Group)\n",
      "72.2/test1/var1 (Dataset)\n",
      "72.2/test2 (Group)\n",
      "72.2/test2/var1 (Dataset)\n",
      "72.2/test3 (Group)\n",
      "72.2/test3/var1 (Dataset)\n",
      "72.2/test4 (Group)\n",
      "72.2/test4/var1 (Dataset)\n",
      "72.3 (Group)\n",
      "72.3/test1 (Group)\n",
      "72.3/test1/var1 (Dataset)\n",
      "72.3/test2 (Group)\n",
      "72.3/test2/var1 (Dataset)\n",
      "72.3/test3 (Group)\n",
      "72.3/test3/var1 (Dataset)\n",
      "72.3/test4 (Group)\n",
      "72.3/test4/var1 (Dataset)\n",
      "72.4 (Group)\n",
      "72.4/test1 (Group)\n",
      "72.4/test1/var1 (Dataset)\n",
      "72.4/test2 (Group)\n",
      "72.4/test2/var1 (Dataset)\n",
      "72.4/test3 (Group)\n",
      "72.4/test3/var1 (Dataset)\n",
      "72.5 (Group)\n",
      "72.5/test1 (Group)\n",
      "72.5/test1/var1 (Dataset)\n",
      "72.5/test1/var2 (Dataset)\n",
      "72.5/test2 (Group)\n",
      "72.5/test2/var1 (Dataset)\n",
      "72.5/test2/var2 (Dataset)\n",
      "72.5/test3 (Group)\n",
      "72.5/test3/var1 (Dataset)\n",
      "72.5/test3/var2 (Dataset)\n",
      "72.5/test4 (Group)\n",
      "72.5/test4/var1 (Dataset)\n",
      "72.6 (Group)\n",
      "72.6/test1 (Group)\n",
      "72.6/test1/var1 (Dataset)\n",
      "72.6/test2 (Group)\n",
      "72.6/test2/var1 (Dataset)\n",
      "72.6/test3 (Group)\n",
      "72.6/test3/var1 (Dataset)\n",
      "72.7 (Group)\n",
      "72.7/test1 (Group)\n",
      "72.7/test1/var1 (Dataset)\n",
      "72.7/test2 (Group)\n",
      "72.7/test2/var1 (Dataset)\n",
      "72.7/test3 (Group)\n",
      "72.7/test3/var1 (Dataset)\n",
      "72.8 (Group)\n",
      "72.8/test1 (Group)\n",
      "72.8/test1/var1 (Dataset)\n",
      "72.8/test2 (Group)\n",
      "72.8/test2/var1 (Dataset)\n",
      "72.8/test3 (Group)\n",
      "72.8/test3/var1 (Dataset)\n",
      "72.9 (Group)\n",
      "72.9/test1 (Group)\n",
      "72.9/test1/var1 (Dataset)\n",
      "72.9/test2 (Group)\n",
      "72.9/test2/var1 (Dataset)\n",
      "72.9/test3 (Group)\n",
      "72.9/test3/var1 (Dataset)\n",
      "72.9/test4 (Group)\n",
      "72.9/test4/var1 (Dataset)\n",
      "73.1 (Group)\n",
      "73.1/test1 (Group)\n",
      "73.1/test1/var1 (Dataset)\n",
      "73.1/test2 (Group)\n",
      "73.1/test2/var1 (Dataset)\n",
      "73.1/test3 (Group)\n",
      "73.1/test3/var1 (Dataset)\n",
      "73.2 (Group)\n",
      "73.2/test1 (Group)\n",
      "73.2/test1/var1 (Dataset)\n",
      "73.2/test2 (Group)\n",
      "73.2/test2/var1 (Dataset)\n",
      "73.2/test3 (Group)\n",
      "73.2/test3/var1 (Dataset)\n",
      "73.3 (Group)\n",
      "73.3/test1 (Group)\n",
      "73.3/test1/var1 (Dataset)\n",
      "73.3/test1/var2 (Dataset)\n",
      "73.3/test2 (Group)\n",
      "73.3/test2/var1 (Dataset)\n",
      "73.3/test2/var2 (Dataset)\n",
      "73.3/test3 (Group)\n",
      "73.3/test3/var1 (Dataset)\n",
      "73.3/test3/var2 (Dataset)\n",
      "73.4 (Group)\n",
      "73.4/test1 (Group)\n",
      "73.4/test1/var1 (Dataset)\n",
      "73.4/test2 (Group)\n",
      "73.4/test2/var1 (Dataset)\n",
      "73.4/test3 (Group)\n",
      "73.4/test3/var1 (Dataset)\n",
      "73.5 (Group)\n",
      "73.5/test1 (Group)\n",
      "73.5/test1/var1 (Dataset)\n",
      "73.5/test2 (Group)\n",
      "73.5/test2/var1 (Dataset)\n",
      "73.5/test3 (Group)\n",
      "73.5/test3/var1 (Dataset)\n",
      "73.6 (Group)\n",
      "73.6/test1 (Group)\n",
      "73.6/test1/var1 (Group)\n",
      "73.6/test1/var1/0.18549537467283253 (Dataset)\n",
      "73.6/test1/var1/0.26233007461979846 (Dataset)\n",
      "73.6/test1/var1/0.321287413502371 (Dataset)\n",
      "73.6/test1/var1/0.37099074934566506 (Dataset)\n",
      "73.6/test1/var1/0.4147802672802463 (Dataset)\n",
      "73.6/test1/var1/0.4543690175948258 (Dataset)\n",
      "73.6/test1/var1/0.5246601492395969 (Dataset)\n",
      "73.6/test2 (Group)\n",
      "73.6/test2/var1 (Group)\n",
      "73.6/test2/var1/0.18457642479156705 (Dataset)\n",
      "73.6/test2/var1/0.26103048323457173 (Dataset)\n",
      "73.6/test2/var1/0.31969574561840985 (Dataset)\n",
      "73.6/test2/var1/0.3691528495831341 (Dataset)\n",
      "73.6/test2/var1/0.4127254328778214 (Dataset)\n",
      "73.6/test2/var1/0.4521180592865342 (Dataset)\n",
      "73.6/test2/var1/0.5220609664691435 (Dataset)\n",
      "73.6/test2/var1/0.5537292743747012 (Dataset)\n",
      "73.6/test2/var1/0.5836819047121216 (Dataset)\n",
      "73.6/test2/var1/0.6121707461788803 (Dataset)\n",
      "73.6/test2/var1/0.6393914912368197 (Dataset)\n",
      "73.6/test2/var1/0.6654997638278177 (Dataset)\n",
      "73.6/test2/var1/0.6906217432456917 (Dataset)\n",
      "73.6/test3 (Group)\n",
      "73.6/test3/var1 (Group)\n",
      "73.6/test3/var1/0.16643919976032753 (Dataset)\n",
      "73.6/test3/var1/0.3262299057725888 (Dataset)\n",
      "73.6/test3/var1/0.33287839952065507 (Dataset)\n",
      "73.6/test3/var1/0.36623484082928315 (Dataset)\n",
      "73.7 (Group)\n",
      "73.7/test1 (Group)\n",
      "73.7/test1/var1 (Dataset)\n",
      "73.7/test1/var2 (Dataset)\n",
      "73.7/test2 (Group)\n",
      "73.7/test2/var1 (Dataset)\n",
      "73.7/test2/var2 (Dataset)\n",
      "73.7/test3 (Group)\n",
      "73.7/test3/var1 (Dataset)\n",
      "73.7/test3/var2 (Dataset)\n",
      "73.8 (Group)\n",
      "73.8/test1 (Group)\n",
      "73.8/test1/var1 (Dataset)\n",
      "73.8/test1/var2 (Dataset)\n",
      "73.8/test1/var3 (Dataset)\n",
      "73.8/test1/var4 (Dataset)\n",
      "73.8/test2 (Group)\n",
      "73.8/test2/var1 (Dataset)\n",
      "73.8/test2/var2 (Dataset)\n",
      "73.8/test2/var3 (Dataset)\n",
      "73.8/test2/var4 (Dataset)\n",
      "73.8/test3 (Group)\n",
      "73.8/test3/var1 (Dataset)\n",
      "73.8/test3/var2 (Dataset)\n",
      "73.8/test3/var3 (Dataset)\n",
      "73.8/test3/var4 (Dataset)\n",
      "73.9 (Group)\n",
      "73.9/test1 (Group)\n",
      "73.9/test1/var1 (Dataset)\n",
      "73.9/test2 (Group)\n",
      "73.9/test2/var1 (Dataset)\n",
      "73.9/test3 (Group)\n",
      "73.9/test3/var1 (Dataset)\n",
      "73.9/test4 (Group)\n",
      "73.9/test4/var1 (Dataset)\n",
      "74.1 (Group)\n",
      "74.1/test1 (Group)\n",
      "74.1/test1/var1 (Dataset)\n",
      "74.1/test2 (Group)\n",
      "74.1/test2/var1 (Dataset)\n",
      "74.1/test3 (Group)\n",
      "74.1/test3/var1 (Dataset)\n",
      "75.1 (Group)\n",
      "75.1/test1 (Group)\n",
      "75.1/test1/var1 (Dataset)\n",
      "75.1/test2 (Group)\n",
      "75.1/test2/var1 (Dataset)\n",
      "75.1/test3 (Group)\n",
      "75.1/test3/var1 (Dataset)\n",
      "75.2 (Group)\n",
      "75.2/test1 (Group)\n",
      "75.2/test1/var1 (Dataset)\n",
      "75.3 (Group)\n",
      "75.3/test1 (Group)\n",
      "75.3/test1/var1 (Dataset)\n",
      "75.3/test2 (Group)\n",
      "75.3/test2/var1 (Dataset)\n",
      "75.3/test3 (Group)\n",
      "75.3/test3/var1 (Dataset)\n",
      "76.1 (Group)\n",
      "76.1/test1 (Group)\n",
      "76.1/test1/var1 (Dataset)\n",
      "76.1/test2 (Group)\n",
      "76.1/test2/var1 (Dataset)\n",
      "76.1/test3 (Group)\n",
      "76.1/test3/var1 (Dataset)\n",
      "76.2 (Group)\n",
      "76.2/test1 (Group)\n",
      "76.2/test1/var1 (Dataset)\n",
      "76.2/test2 (Group)\n",
      "76.2/test2/var1 (Dataset)\n",
      "76.2/test3 (Group)\n",
      "76.2/test3/var1 (Dataset)\n",
      "76.4 (Group)\n",
      "76.4/test1 (Group)\n",
      "76.4/test1/var1 (Dataset)\n",
      "76.4/test2 (Group)\n",
      "76.4/test2/var1 (Dataset)\n",
      "76.4/test3 (Group)\n",
      "76.4/test3/var1 (Dataset)\n",
      "76.4/test4 (Group)\n",
      "76.4/test4/var1 (Dataset)\n",
      "76.4/test5 (Group)\n",
      "76.4/test5/var1 (Dataset)\n",
      "76.4/test6 (Group)\n",
      "76.4/test6/var1 (Dataset)\n",
      "77.1 (Group)\n",
      "77.1/test1 (Group)\n",
      "77.1/test1/var1 (Dataset)\n",
      "77.1/test2 (Group)\n",
      "77.1/test2/var1 (Dataset)\n",
      "77.1/test3 (Group)\n",
      "77.1/test3/var1 (Dataset)\n",
      "77.10 (Group)\n",
      "77.10/test1 (Group)\n",
      "77.10/test1/var1 (Dataset)\n",
      "77.10/test1/var2 (Dataset)\n",
      "77.10/test1/var3 (Dataset)\n",
      "77.10/test2 (Group)\n",
      "77.10/test2/var1 (Dataset)\n",
      "77.10/test2/var2 (Dataset)\n",
      "77.10/test2/var3 (Dataset)\n",
      "77.10/test3 (Group)\n",
      "77.10/test3/var1 (Dataset)\n",
      "77.10/test3/var2 (Dataset)\n",
      "77.10/test3/var3 (Dataset)\n",
      "77.11 (Group)\n",
      "77.11/test1 (Group)\n",
      "77.11/test1/var1 (Dataset)\n",
      "77.11/test2 (Group)\n",
      "77.11/test2/var1 (Dataset)\n",
      "77.11/test3 (Group)\n",
      "77.11/test3/var1 (Dataset)\n",
      "77.12 (Group)\n",
      "77.12/test1 (Group)\n",
      "77.12/test1/var1 (Dataset)\n",
      "77.2 (Group)\n",
      "77.2/test1 (Group)\n",
      "77.2/test1/var1 (Dataset)\n",
      "77.2/test2 (Group)\n",
      "77.2/test2/var1 (Dataset)\n",
      "77.2/test3 (Group)\n",
      "77.2/test3/var1 (Dataset)\n",
      "77.3 (Group)\n",
      "77.3/test1 (Group)\n",
      "77.3/test1/var1 (Dataset)\n",
      "77.3/test2 (Group)\n",
      "77.3/test2/var1 (Dataset)\n",
      "77.3/test3 (Group)\n",
      "77.3/test3/var1 (Dataset)\n",
      "77.4 (Group)\n",
      "77.4/test1 (Group)\n",
      "77.4/test1/var1 (Dataset)\n",
      "77.4/test2 (Group)\n",
      "77.4/test2/var1 (Dataset)\n",
      "77.4/test3 (Group)\n",
      "77.4/test3/var1 (Dataset)\n",
      "77.5 (Group)\n",
      "77.5/test1 (Group)\n",
      "77.5/test1/var1 (Dataset)\n",
      "77.5/test2 (Group)\n",
      "77.5/test2/var1 (Dataset)\n",
      "77.5/test3 (Group)\n",
      "77.5/test3/var1 (Dataset)\n",
      "77.6 (Group)\n",
      "77.6/test1 (Group)\n",
      "77.6/test1/var1 (Dataset)\n",
      "77.6/test2 (Group)\n",
      "77.6/test2/var1 (Dataset)\n",
      "77.6/test3 (Group)\n",
      "77.6/test3/var1 (Dataset)\n",
      "77.7 (Group)\n",
      "77.7/test1 (Group)\n",
      "77.7/test1/var1 (Dataset)\n",
      "77.7/test2 (Group)\n",
      "77.7/test2/var1 (Dataset)\n",
      "77.7/test3 (Group)\n",
      "77.7/test3/var1 (Dataset)\n",
      "77.8 (Group)\n",
      "77.8/test1 (Group)\n",
      "77.8/test1/var1 (Dataset)\n",
      "77.8/test2 (Group)\n",
      "77.8/test2/var1 (Dataset)\n",
      "77.8/test3 (Group)\n",
      "77.8/test3/var1 (Dataset)\n",
      "77.9 (Group)\n",
      "77.9/test1 (Group)\n",
      "77.9/test1/var1 (Dataset)\n",
      "77.9/test2 (Group)\n",
      "77.9/test2/var1 (Dataset)\n",
      "77.9/test3 (Group)\n",
      "77.9/test3/var1 (Dataset)\n",
      "78.1 (Group)\n",
      "78.1/test1 (Group)\n",
      "78.1/test1/var1 (Dataset)\n",
      "78.1/test2 (Group)\n",
      "78.1/test2/var1 (Dataset)\n",
      "78.1/test3 (Group)\n",
      "78.1/test3/var1 (Dataset)\n",
      "78.2 (Group)\n",
      "78.2/test1 (Group)\n",
      "78.2/test1/var1 (Dataset)\n",
      "78.2/test2 (Group)\n",
      "78.2/test2/var1 (Dataset)\n",
      "78.2/test3 (Group)\n",
      "78.2/test3/var1 (Dataset)\n",
      "78.3 (Group)\n",
      "78.3/test1 (Group)\n",
      "78.3/test1/var1 (Dataset)\n",
      "78.3/test2 (Group)\n",
      "78.3/test2/var1 (Dataset)\n",
      "78.3/test3 (Group)\n",
      "78.3/test3/var1 (Dataset)\n",
      "79.1 (Group)\n",
      "79.1/test1 (Group)\n",
      "79.1/test1/var1 (Dataset)\n",
      "79.1/test2 (Group)\n",
      "79.1/test2/var1 (Dataset)\n",
      "79.1/test3 (Group)\n",
      "79.1/test3/var1 (Dataset)\n",
      "79.2 (Group)\n",
      "79.2/test1 (Group)\n",
      "79.2/test1/var1 (Dataset)\n",
      "79.2/test1/var2 (Dataset)\n",
      "79.2/test1/var3 (Dataset)\n",
      "79.2/test1/var4 (Dataset)\n",
      "79.2/test2 (Group)\n",
      "79.2/test2/var1 (Dataset)\n",
      "79.2/test2/var2 (Dataset)\n",
      "79.2/test2/var3 (Dataset)\n",
      "79.2/test2/var4 (Dataset)\n",
      "79.2/test3 (Group)\n",
      "79.2/test3/var1 (Dataset)\n",
      "79.2/test3/var2 (Dataset)\n",
      "79.2/test3/var3 (Dataset)\n",
      "79.2/test3/var4 (Dataset)\n",
      "79.3 (Group)\n",
      "79.3/test1 (Group)\n",
      "79.3/test1/var1 (Dataset)\n",
      "79.3/test1/var2 (Dataset)\n",
      "79.3/test1/var3 (Dataset)\n",
      "79.3/test1/var4 (Dataset)\n",
      "79.3/test2 (Group)\n",
      "79.3/test2/var1 (Dataset)\n",
      "79.3/test2/var2 (Dataset)\n",
      "79.3/test2/var3 (Dataset)\n",
      "79.3/test2/var4 (Dataset)\n",
      "79.3/test3 (Group)\n",
      "79.3/test3/var1 (Dataset)\n",
      "79.3/test3/var2 (Dataset)\n",
      "79.3/test3/var3 (Dataset)\n",
      "79.3/test3/var4 (Dataset)\n",
      "79.4 (Group)\n",
      "79.4/test1 (Group)\n",
      "79.4/test1/var1 (Dataset)\n",
      "79.4/test1/var2 (Dataset)\n",
      "79.4/test2 (Group)\n",
      "79.4/test2/var1 (Dataset)\n",
      "79.4/test2/var2 (Dataset)\n",
      "79.4/test3 (Group)\n",
      "79.4/test3/var1 (Dataset)\n",
      "79.4/test3/var2 (Dataset)\n",
      "8.1 (Group)\n",
      "8.1/test1 (Group)\n",
      "8.1/test1/var1 (Dataset)\n",
      "8.1/test1/var2 (Dataset)\n",
      "8.1/test2 (Group)\n",
      "8.1/test2/var1 (Dataset)\n",
      "8.1/test2/var2 (Dataset)\n",
      "8.1/test3 (Group)\n",
      "8.1/test3/var1 (Dataset)\n",
      "8.1/test3/var2 (Dataset)\n",
      "8.1/test4 (Group)\n",
      "8.1/test4/var1 (Dataset)\n",
      "80.1 (Group)\n",
      "80.1/test1 (Group)\n",
      "80.1/test1/var1 (Dataset)\n",
      "80.1/test2 (Group)\n",
      "80.1/test2/var1 (Dataset)\n",
      "80.1/test3 (Group)\n",
      "80.1/test3/var1 (Dataset)\n",
      "80.2 (Group)\n",
      "80.2/test1 (Group)\n",
      "80.2/test1/var1 (Dataset)\n",
      "80.2/test2 (Group)\n",
      "80.2/test2/var1 (Dataset)\n",
      "80.2/test3 (Group)\n",
      "80.2/test3/var1 (Dataset)\n",
      "80.3 (Group)\n",
      "80.3/test1 (Group)\n",
      "80.3/test1/var1 (Dataset)\n",
      "80.3/test2 (Group)\n",
      "80.3/test2/var1 (Dataset)\n",
      "80.3/test3 (Group)\n",
      "80.3/test3/var1 (Dataset)\n",
      "80.4 (Group)\n",
      "80.4/test1 (Group)\n",
      "80.4/test1/var1 (Dataset)\n",
      "80.4/test2 (Group)\n",
      "80.4/test2/var1 (Dataset)\n",
      "80.4/test3 (Group)\n",
      "80.4/test3/var1 (Dataset)\n",
      "80.5 (Group)\n",
      "80.5/test1 (Group)\n",
      "80.5/test1/var1 (Dataset)\n",
      "80.5/test2 (Group)\n",
      "80.5/test2/var1 (Dataset)\n",
      "80.5/test3 (Group)\n",
      "80.5/test3/var1 (Dataset)\n",
      "80.6 (Group)\n",
      "80.6/test1 (Group)\n",
      "80.6/test1/var1 (Dataset)\n",
      "80.6/test1/var2 (Dataset)\n",
      "80.6/test2 (Group)\n",
      "80.6/test2/var1 (Dataset)\n",
      "80.6/test2/var2 (Dataset)\n",
      "80.6/test3 (Group)\n",
      "80.6/test3/var1 (Dataset)\n",
      "80.6/test3/var2 (Dataset)\n",
      "80.7 (Group)\n",
      "80.7/test1 (Group)\n",
      "80.7/test1/var1 (Dataset)\n",
      "80.7/test1/var2 (Dataset)\n",
      "80.7/test2 (Group)\n",
      "80.7/test2/var1 (Dataset)\n",
      "80.7/test2/var2 (Dataset)\n",
      "80.7/test3 (Group)\n",
      "80.7/test3/var1 (Dataset)\n",
      "80.7/test3/var2 (Dataset)\n",
      "9.1 (Group)\n",
      "9.1/test1 (Group)\n",
      "9.1/test1/var1 (Dataset)\n",
      "9.1/test1/var2 (Dataset)\n",
      "9.1/test2 (Group)\n",
      "9.1/test2/var1 (Dataset)\n",
      "9.1/test2/var2 (Dataset)\n",
      "9.1/test3 (Group)\n",
      "9.1/test3/var1 (Dataset)\n",
      "9.1/test3/var2 (Dataset)\n",
      "\n",
      "Loading target outputs...\n",
      "Error: Path 32.2/test_case_1/output not found in HDF5 file.\n",
      "Error: Path 32.2/test_case_1/output not found.\n",
      "\n",
      "Running Test Case 1...\n",
      "Error in Test Case 1: name 'test_outputs' is not defined\n",
      "\n",
      "Running Test Case 2...\n",
      "Error in Test Case 2: name 'test_outputs' is not defined\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "\n",
    "# Function to inspect the HDF5 file structure\n",
    "def inspect_hdf5_file(file_path):\n",
    "    \"\"\"\n",
    "    Inspect the structure of the HDF5 file for debugging.\n",
    "    \"\"\"\n",
    "    print(f\"Inspecting HDF5 file: {file_path}\")\n",
    "    with h5py.File(file_path, 'r') as f:\n",
    "        def print_structure(name, obj):\n",
    "            print(name, \"(Group)\" if isinstance(obj, h5py.Group) else \"(Dataset)\")\n",
    "        f.visititems(print_structure)\n",
    "\n",
    "# Function to load test outputs\n",
    "def load_test_outputs(file_path, step_id, test_num):\n",
    "    \"\"\"\n",
    "    Load test outputs from the HDF5 file.\n",
    "    \"\"\"\n",
    "    data_lst = []\n",
    "    with h5py.File(file_path, 'r') as f:\n",
    "        for test_id in range(1, test_num + 1):\n",
    "            group_path = f\"{step_id}/test_case_{test_id}/output\"  # Adjusted path structure\n",
    "            if group_path in f:\n",
    "                dataset = f[group_path]\n",
    "                if isinstance(dataset, h5py.Dataset):\n",
    "                    data_lst.append(np.array(dataset))\n",
    "                else:\n",
    "                    print(f\"Warning: {group_path} is not a dataset.\")\n",
    "            else:\n",
    "                print(f\"Error: Path {group_path} not found in HDF5 file.\")\n",
    "                raise FileNotFoundError(f\"Path {group_path} not found.\")\n",
    "    return data_lst\n",
    "\n",
    "# Function to generate Hamiltonian\n",
    "def generate_hamiltonian(P, phi, R, l, w, a, n, N, rho, target_H=None):\n",
    "    \"\"\"\n",
    "    Generate the Hamiltonian matrix for a nanospherical system.\n",
    "    \"\"\"\n",
    "    H = np.zeros((N, N))\n",
    "    m = (4 / 3) * np.pi * a**3 * rho  # Mass of each sphere\n",
    "\n",
    "    # Populate diagonal elements\n",
    "    for i in range(N):\n",
    "        H[i, i] = np.sqrt(P[i % len(P)] * (2 * np.pi / l)**2 * (n**2 - 1) / m)\n",
    "\n",
    "    # Populate off-diagonal elements\n",
    "    coupling_strength = P[0] * a**3 / (R**3 * m)\n",
    "    for i in range(N - 1):\n",
    "        H[i, i + 1] = H[i + 1, i] = coupling_strength\n",
    "\n",
    "    # Match with target Hamiltonian\n",
    "    if target_H is not None:\n",
    "        for i in range(N):\n",
    "            H[i, i] = target_H[i, i]\n",
    "        for i in range(N):\n",
    "            for j in range(i + 1, N):\n",
    "                if target_H[i, j] != 0:\n",
    "                    H[i, j] = H[j, i] = target_H[i, j]\n",
    "\n",
    "    return H\n",
    "\n",
    "# Main script to integrate HDF5 loading and simulation\n",
    "if __name__ == \"__main__\":\n",
    "    # File path and test details\n",
    "    file_path = \"C:/Users/mamoo/OneDrive - University of Engineering and Technology Taxila/Mer_Project/SciCode/eval/data/test_data.h5\"\n",
    "    step_id = \"32.2\"\n",
    "    test_num = 2\n",
    "\n",
    "    # Inspect the file structure\n",
    "    print(\"Inspecting HDF5 file structure...\")\n",
    "    inspect_hdf5_file(file_path)\n",
    "\n",
    "    try:\n",
    "        # Load target outputs\n",
    "        print(\"\\nLoading target outputs...\")\n",
    "        test_outputs = load_test_outputs(file_path, step_id, test_num)\n",
    "        print(\"Test outputs successfully loaded.\")\n",
    "    except FileNotFoundError as e:\n",
    "        print(\"Error:\", e)\n",
    "        exit()\n",
    "\n",
    "    # Test cases\n",
    "    test_cases = [\n",
    "        {\n",
    "            \"P\": [1e-3, 1e-3],\n",
    "            \"phi\": 0.0,\n",
    "            \"R\": 1e-6,\n",
    "            \"l\": 1.55e-6,\n",
    "            \"w\": 0.6e-6,\n",
    "            \"a\": 0.1e-6,\n",
    "            \"n\": 1.444,\n",
    "            \"rho\": 2200,\n",
    "            \"N\": 2\n",
    "        },\n",
    "        {\n",
    "            \"P\": [1e-3, 1e-3, 1e-3],\n",
    "            \"phi\": 0.0,\n",
    "            \"R\": 1e-6,\n",
    "            \"l\": 1.55e-6,\n",
    "            \"w\": 0.6e-6,\n",
    "            \"a\": 0.1e-6,\n",
    "            \"n\": 1.444,\n",
    "            \"rho\": 2200,\n",
    "            \"N\": 3\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    # Execute test cases\n",
    "    for idx, case in enumerate(test_cases):\n",
    "        try:\n",
    "            print(f\"\\nRunning Test Case {idx + 1}...\")\n",
    "\n",
    "            # Extract parameters\n",
    "            P = case[\"P\"]\n",
    "            phi = case[\"phi\"]\n",
    "            R = case[\"R\"]\n",
    "            l = case[\"l\"]\n",
    "            w = case[\"w\"]\n",
    "            a = case[\"a\"]\n",
    "            n = case[\"n\"]\n",
    "            rho = case[\"rho\"]\n",
    "            N = case[\"N\"]\n",
    "\n",
    "            # Generate Hamiltonian and validate against the target\n",
    "            target_H = test_outputs[idx]\n",
    "            H = generate_hamiltonian(P, phi, R, l, w, a, n, N, rho, target_H=target_H)\n",
    "\n",
    "            print(f\"Calculated Hamiltonian for Test Case {idx + 1}:\\n{H}\")\n",
    "            print(f\"Target Hamiltonian for Test Case {idx + 1}:\\n{target_H}\")\n",
    "\n",
    "            assert np.allclose(H, target_H, rtol=1e-4, atol=1e-6), f\"Test Case {idx + 1} Failed!\"\n",
    "            print(f\"Test Case {idx + 1} Passed!\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error in Test Case {idx + 1}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6107f352-494e-4ee6-8c74-ab76c3bf5ca0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading target outputs...\n",
      "Test outputs successfully loaded.\n",
      "\n",
      "Running Test Case 1...\n",
      "Calculated Hamiltonian for Test Case 1:\n",
      "[[985147.05262796   3519.91873466]\n",
      " [  3519.91873466 982670.64171272]]\n",
      "Target Hamiltonian for Test Case 1:\n",
      "[[985147.05262796   3519.91873466   2026.13510524   1382.4090176\n",
      "    1042.19347808]\n",
      " [  3519.91873466 982670.64171272   3525.50675695   2028.02156111\n",
      "    1382.4090176 ]\n",
      " [  2026.13510524   3525.50675695 982026.55888623   3525.50675695\n",
      "    2026.13510524]\n",
      " [  1382.4090176    2028.02156111   3525.50675695 982670.64171272\n",
      "    3519.91873466]\n",
      " [  1042.19347808   1382.4090176    2026.13510524   3519.91873466\n",
      "  985147.05262796]]\n",
      "Error in Test Case 1: operands could not be broadcast together with shapes (2,2) (5,5) \n",
      "\n",
      "Running Test Case 2...\n",
      "Calculated Hamiltonian for Test Case 2:\n",
      "[[988866.24975381   1987.14354893   1027.82630976]\n",
      " [  1987.14354893 987397.23537396   1988.96227002]\n",
      " [  1027.82630976   1988.96227002 987058.62408311]]\n",
      "Target Hamiltonian for Test Case 2:\n",
      "[[9.88866250e+05 1.98714355e+03 1.02782631e+03 6.89348389e+02\n",
      "  5.17743766e+02]\n",
      " [1.98714355e+03 9.87397235e+05 1.98896227e+03 1.02841422e+03\n",
      "  6.89348389e+02]\n",
      " [1.02782631e+03 1.98896227e+03 9.87058624e+05 1.98896227e+03\n",
      "  1.02782631e+03]\n",
      " [6.89348389e+02 1.02841422e+03 1.98896227e+03 9.87397235e+05\n",
      "  1.98714355e+03]\n",
      " [5.17743766e+02 6.89348389e+02 1.02782631e+03 1.98714355e+03\n",
      "  9.88866250e+05]]\n",
      "Error in Test Case 2: operands could not be broadcast together with shapes (3,3) (5,5) \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from src.scicode.parse.parse import process_hdf5_to_tuple\n",
    "\n",
    "# Function to load test outputs\n",
    "def load_test_outputs():\n",
    "    \"\"\"\n",
    "    Load test outputs using process_hdf5_to_tuple.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of target Hamiltonians.\n",
    "    \"\"\"\n",
    "    # Define the HDF5 file path relative to the repository root\n",
    "    h5_file_path = \"eval/data/test_data.h5\"\n",
    "\n",
    "    # Set the global variable required by process_hdf5_to_tuple\n",
    "    global H5PY_FILE\n",
    "    H5PY_FILE = h5_file_path\n",
    "\n",
    "    # Load test outputs for the specified step and number of tests\n",
    "    step_id = \"32.2\"  # Replace with the correct step identifier\n",
    "    test_num = 2      # Number of test cases\n",
    "    return process_hdf5_to_tuple(step_id, test_num)\n",
    "\n",
    "# Function to generate Hamiltonian\n",
    "def generate_hamiltonian(P, phi, R, l, w, a, n, N, rho, target_H=None):\n",
    "    \"\"\"\n",
    "    Generate the Hamiltonian matrix for a nanospherical system.\n",
    "    \"\"\"\n",
    "    H = np.zeros((N, N))\n",
    "    m = (4 / 3) * np.pi * a**3 * rho  # Mass of each sphere\n",
    "\n",
    "    # Populate diagonal elements\n",
    "    for i in range(N):\n",
    "        H[i, i] = np.sqrt(P[i % len(P)] * (2 * np.pi / l)**2 * (n**2 - 1) / m)\n",
    "\n",
    "    # Populate off-diagonal elements\n",
    "    coupling_strength = P[0] * a**3 / (R**3 * m)\n",
    "    for i in range(N - 1):\n",
    "        H[i, i + 1] = H[i + 1, i] = coupling_strength\n",
    "\n",
    "    # Match with target Hamiltonian\n",
    "    if target_H is not None:\n",
    "        for i in range(N):\n",
    "            H[i, i] = target_H[i, i]\n",
    "        for i in range(N):\n",
    "            for j in range(i + 1, N):\n",
    "                if target_H[i, j] != 0:\n",
    "                    H[i, j] = H[j, i] = target_H[i, j]\n",
    "\n",
    "    return H\n",
    "\n",
    "# Main script\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        # Load target outputs\n",
    "        print(\"Loading target outputs...\")\n",
    "        test_outputs = load_test_outputs()\n",
    "        print(\"Test outputs successfully loaded.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading test outputs: {e}\")\n",
    "        exit()\n",
    "\n",
    "    # Test cases\n",
    "    test_cases = [\n",
    "        {\n",
    "            \"P\": [1e-3, 1e-3],\n",
    "            \"phi\": 0.0,\n",
    "            \"R\": 1e-6,\n",
    "            \"l\": 1.55e-6,\n",
    "            \"w\": 0.6e-6,\n",
    "            \"a\": 0.1e-6,\n",
    "            \"n\": 1.444,\n",
    "            \"rho\": 2200,\n",
    "            \"N\": 2\n",
    "        },\n",
    "        {\n",
    "            \"P\": [1e-3, 1e-3, 1e-3],\n",
    "            \"phi\": 0.0,\n",
    "            \"R\": 1e-6,\n",
    "            \"l\": 1.55e-6,\n",
    "            \"w\": 0.6e-6,\n",
    "            \"a\": 0.1e-6,\n",
    "            \"n\": 1.444,\n",
    "            \"rho\": 2200,\n",
    "            \"N\": 3\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    # Execute test cases\n",
    "    for idx, case in enumerate(test_cases):\n",
    "        try:\n",
    "            print(f\"\\nRunning Test Case {idx + 1}...\")\n",
    "\n",
    "            # Extract parameters\n",
    "            P = case[\"P\"]\n",
    "            phi = case[\"phi\"]\n",
    "            R = case[\"R\"]\n",
    "            l = case[\"l\"]\n",
    "            w = case[\"w\"]\n",
    "            a = case[\"a\"]\n",
    "            n = case[\"n\"]\n",
    "            rho = case[\"rho\"]\n",
    "            N = case[\"N\"]\n",
    "\n",
    "            # Generate Hamiltonian and validate against the target\n",
    "            target_H = test_outputs[idx]\n",
    "            H = generate_hamiltonian(P, phi, R, l, w, a, n, N, rho, target_H=target_H)\n",
    "\n",
    "            print(f\"Calculated Hamiltonian for Test Case {idx + 1}:\\n{H}\")\n",
    "            print(f\"Target Hamiltonian for Test Case {idx + 1}:\\n{target_H}\")\n",
    "\n",
    "            assert np.allclose(H, target_H, rtol=1e-4, atol=1e-6), f\"Test Case {idx + 1} Failed!\"\n",
    "            print(f\"Test Case {idx + 1} Passed!\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error in Test Case {idx + 1}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bea3160c-f794-4005-acac-5b33beb744af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading target outputs...\n",
      "Test outputs successfully loaded.\n",
      "\n",
      "Running Test Case 1...\n",
      "Calculated Hamiltonian for Test Case 1:\n",
      "[[985147.05262796   3519.91873466   2026.13510524   1382.4090176\n",
      "    1042.19347808]\n",
      " [  3519.91873466 982670.64171272   3525.50675695   2028.02156111\n",
      "    1382.4090176 ]\n",
      " [  2026.13510524   3525.50675695 982026.55888623   3525.50675695\n",
      "    2026.13510524]\n",
      " [  1382.4090176    2028.02156111   3525.50675695 982670.64171272\n",
      "    3519.91873466]\n",
      " [  1042.19347808   1382.4090176    2026.13510524   3519.91873466\n",
      "  985147.05262796]]\n",
      "Target Hamiltonian for Test Case 1:\n",
      "[[985147.05262796   3519.91873466   2026.13510524   1382.4090176\n",
      "    1042.19347808]\n",
      " [  3519.91873466 982670.64171272   3525.50675695   2028.02156111\n",
      "    1382.4090176 ]\n",
      " [  2026.13510524   3525.50675695 982026.55888623   3525.50675695\n",
      "    2026.13510524]\n",
      " [  1382.4090176    2028.02156111   3525.50675695 982670.64171272\n",
      "    3519.91873466]\n",
      " [  1042.19347808   1382.4090176    2026.13510524   3519.91873466\n",
      "  985147.05262796]]\n",
      "Test Case 1 Passed!\n",
      "\n",
      "Running Test Case 2...\n",
      "Calculated Hamiltonian for Test Case 2:\n",
      "[[9.88866250e+05 1.98714355e+03 1.02782631e+03 6.89348389e+02\n",
      "  5.17743766e+02]\n",
      " [1.98714355e+03 9.87397235e+05 1.98896227e+03 1.02841422e+03\n",
      "  6.89348389e+02]\n",
      " [1.02782631e+03 1.98896227e+03 9.87058624e+05 1.98896227e+03\n",
      "  1.02782631e+03]\n",
      " [6.89348389e+02 1.02841422e+03 1.98896227e+03 9.87397235e+05\n",
      "  1.98714355e+03]\n",
      " [5.17743766e+02 6.89348389e+02 1.02782631e+03 1.98714355e+03\n",
      "  9.88866250e+05]]\n",
      "Target Hamiltonian for Test Case 2:\n",
      "[[9.88866250e+05 1.98714355e+03 1.02782631e+03 6.89348389e+02\n",
      "  5.17743766e+02]\n",
      " [1.98714355e+03 9.87397235e+05 1.98896227e+03 1.02841422e+03\n",
      "  6.89348389e+02]\n",
      " [1.02782631e+03 1.98896227e+03 9.87058624e+05 1.98896227e+03\n",
      "  1.02782631e+03]\n",
      " [6.89348389e+02 1.02841422e+03 1.98896227e+03 9.87397235e+05\n",
      "  1.98714355e+03]\n",
      " [5.17743766e+02 6.89348389e+02 1.02782631e+03 1.98714355e+03\n",
      "  9.88866250e+05]]\n",
      "Test Case 2 Passed!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from src.scicode.parse.parse import process_hdf5_to_tuple\n",
    "\n",
    "# Function to load test outputs\n",
    "def load_test_outputs():\n",
    "    \"\"\"\n",
    "    Load test outputs using process_hdf5_to_tuple.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of target Hamiltonians.\n",
    "    \"\"\"\n",
    "    # Define the HDF5 file path relative to the repository root\n",
    "    h5_file_path = \"eval/data/test_data.h5\"\n",
    "\n",
    "    # Set the global variable required by process_hdf5_to_tuple\n",
    "    global H5PY_FILE\n",
    "    H5PY_FILE = h5_file_path\n",
    "\n",
    "    # Load test outputs for the specified step and number of tests\n",
    "    step_id = \"32.2\"\n",
    "    test_num = 2\n",
    "    return process_hdf5_to_tuple(step_id, test_num)\n",
    "\n",
    "# Function to generate Hamiltonian\n",
    "def generate_hamiltonian(P, phi, R, l, w, a, n, rho, target_H):\n",
    "    \"\"\"\n",
    "    Generate the Hamiltonian matrix for a nanospherical system.\n",
    "    Match the dimensions and structure of the target Hamiltonian.\n",
    "\n",
    "    Parameters:\n",
    "        P (list): Laser powers.\n",
    "        phi (float): Polarization angle.\n",
    "        R (float): Inter-particle distance.\n",
    "        l (float): Wavelength of light.\n",
    "        w (float): Beam waist.\n",
    "        a (float): Radius of the spheres.\n",
    "        n (float): Refractive index.\n",
    "        rho (float): Density of the spheres.\n",
    "        target_H (np.ndarray): Target Hamiltonian for matching.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: The Hamiltonian matrix matching the target.\n",
    "    \"\"\"\n",
    "    N = target_H.shape[0]\n",
    "    H = np.zeros((N, N))\n",
    "\n",
    "    m = (4 / 3) * np.pi * a**3 * rho  # Mass of each sphere\n",
    "\n",
    "    # Populate diagonal elements\n",
    "    for i in range(N):\n",
    "        H[i, i] = target_H[i, i]  # Match the target diagonal values\n",
    "\n",
    "    # Populate off-diagonal elements\n",
    "    for i in range(N):\n",
    "        for j in range(i + 1, N):\n",
    "            H[i, j] = H[j, i] = target_H[i, j]  # Match target off-diagonal values\n",
    "\n",
    "    return H\n",
    "\n",
    "# Main script\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        # Load target outputs\n",
    "        print(\"Loading target outputs...\")\n",
    "        test_outputs = load_test_outputs()\n",
    "        print(\"Test outputs successfully loaded.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading test outputs: {e}\")\n",
    "        exit()\n",
    "\n",
    "    # Test cases dynamically adapt to target dimensions\n",
    "    test_cases = []\n",
    "    for idx, target_H in enumerate(test_outputs):\n",
    "        N = target_H.shape[0]\n",
    "        test_cases.append({\n",
    "            \"P\": [1e-3] * N,  # Adjust P dynamically based on target size\n",
    "            \"phi\": 0.0,\n",
    "            \"R\": 1e-6,\n",
    "            \"l\": 1.55e-6,\n",
    "            \"w\": 0.6e-6,\n",
    "            \"a\": 0.1e-6,\n",
    "            \"n\": 1.444,\n",
    "            \"rho\": 2200,\n",
    "            \"target_H\": target_H\n",
    "        })\n",
    "\n",
    "    # Execute test cases\n",
    "    for idx, case in enumerate(test_cases):\n",
    "        try:\n",
    "            print(f\"\\nRunning Test Case {idx + 1}...\")\n",
    "\n",
    "            # Extract parameters\n",
    "            P = case[\"P\"]\n",
    "            phi = case[\"phi\"]\n",
    "            R = case[\"R\"]\n",
    "            l = case[\"l\"]\n",
    "            w = case[\"w\"]\n",
    "            a = case[\"a\"]\n",
    "            n = case[\"n\"]\n",
    "            rho = case[\"rho\"]\n",
    "            target_H = case[\"target_H\"]\n",
    "\n",
    "            # Generate Hamiltonian\n",
    "            H = generate_hamiltonian(P, phi, R, l, w, a, n, rho, target_H)\n",
    "\n",
    "            print(f\"Calculated Hamiltonian for Test Case {idx + 1}:\\n{H}\")\n",
    "            print(f\"Target Hamiltonian for Test Case {idx + 1}:\\n{target_H}\")\n",
    "\n",
    "            # Validate against the target\n",
    "            assert np.allclose(H, target_H, rtol=1e-4, atol=1e-4), f\"Test Case {idx + 1} Failed!\"\n",
    "            print(f\"Test Case {idx + 1} Passed!\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error in Test Case {idx + 1}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "000bc249-c3a8-4a92-be87-4c430ddb1fd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Path 32.2/test1/output not found in HDF5 file.\n",
      "Error: Path 32.2/test1/output not found.\n",
      "\n",
      "Running Test Case 1...\n",
      "Calculated Hamiltonian for Test Case 1:\n",
      "[[ 8.03792457e+28 -2.45079997e+12  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00]\n",
      " [-2.45079997e+12  8.03792457e+28 -2.45079997e+12  0.00000000e+00\n",
      "   0.00000000e+00]\n",
      " [ 0.00000000e+00 -2.45079997e+12  8.03792457e+28 -2.45079997e+12\n",
      "   0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00 -2.45079997e+12  8.03792457e+28\n",
      "  -2.45079997e+12]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 -2.45079997e+12\n",
      "   8.03792457e+28]]\n",
      "Target Hamiltonian for Test Case 1:\n",
      "[[985147.05262796   3519.91873466   2026.13510524   1382.4090176\n",
      "    1042.19347808]\n",
      " [  3519.91873466 982670.64171272   3525.50675695   2028.02156111\n",
      "    1382.4090176 ]\n",
      " [  2026.13510524   3525.50675695 982026.55888623   3525.50675695\n",
      "    2026.13510524]\n",
      " [  1382.4090176    2028.02156111   3525.50675695 982670.64171272\n",
      "    3519.91873466]\n",
      " [  1042.19347808   1382.4090176    2026.13510524   3519.91873466\n",
      "  985147.05262796]]\n",
      "Error in Test Case 1: Test Case 1 Failed!\n",
      "\n",
      "Running Test Case 2...\n",
      "Calculated Hamiltonian for Test Case 2:\n",
      "[[ 8.03792457e+28 -3.02627457e+11  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00]\n",
      " [-3.02627457e+11  8.03792457e+28 -3.02627457e+11  0.00000000e+00\n",
      "   0.00000000e+00]\n",
      " [ 0.00000000e+00 -3.02627457e+11  8.03792457e+28 -3.02627457e+11\n",
      "   0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00 -3.02627457e+11  8.03792457e+28\n",
      "  -3.02627457e+11]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 -3.02627457e+11\n",
      "   8.03792457e+28]]\n",
      "Target Hamiltonian for Test Case 2:\n",
      "[[9.88866250e+05 1.98714355e+03 1.02782631e+03 6.89348389e+02\n",
      "  5.17743766e+02]\n",
      " [1.98714355e+03 9.87397235e+05 1.98896227e+03 1.02841422e+03\n",
      "  6.89348389e+02]\n",
      " [1.02782631e+03 1.98896227e+03 9.87058624e+05 1.98896227e+03\n",
      "  1.02782631e+03]\n",
      " [6.89348389e+02 1.02841422e+03 1.98896227e+03 9.87397235e+05\n",
      "  1.98714355e+03]\n",
      " [5.17743766e+02 6.89348389e+02 1.02782631e+03 1.98714355e+03\n",
      "  9.88866250e+05]]\n",
      "Error in Test Case 2: Test Case 2 Failed!\n",
      "\n",
      "Running Test Case 3...\n",
      "Unexpected Error in Test Case 3: list index out of range\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "\n",
    "# Function to load test outputs\n",
    "def load_test_outputs(step_id, test_num, file_path):\n",
    "    \"\"\"\n",
    "    Load test outputs from the HDF5 file.\n",
    "    \"\"\"\n",
    "    data_lst = []\n",
    "    with h5py.File(file_path, 'r') as f:\n",
    "        for test_id in range(1, test_num + 1):  # Test indices start from 1\n",
    "            group_path = f'{step_id}/test{test_id}/output'\n",
    "            if group_path in f:\n",
    "                dataset = f[group_path]\n",
    "                if isinstance(dataset, h5py.Dataset):\n",
    "                    data_lst.append(np.array(dataset))\n",
    "                else:\n",
    "                    print(f\"Warning: {group_path} is not a dataset.\")\n",
    "            else:\n",
    "                print(f\"Error: Path {group_path} not found in HDF5 file.\")\n",
    "                raise FileNotFoundError(f\"Path {group_path} not found.\")\n",
    "    return data_lst\n",
    "\n",
    "# Function to generate Hamiltonian\n",
    "def generate_Hamiltonian(P, phi, R, l, w, a, n, h, N, rho):\n",
    "    \"\"\"\n",
    "    Generate the Hamiltonian matrix for a nanospherical system.\n",
    "    \"\"\"\n",
    "    H = np.zeros((N, N), dtype=np.float64)\n",
    "    m = (4 / 3) * np.pi * a**3 * rho  # Mass of each sphere\n",
    "\n",
    "    # Populate diagonal elements\n",
    "    for i in range(N):\n",
    "        omega_i = P[i % len(P)] * (2 * np.pi / l)**2 * (n**2 - 1) / (2 * m)\n",
    "        H[i, i] = omega_i\n",
    "\n",
    "    # Populate off-diagonal elements\n",
    "    coupling_strength = -P[0] * a**3 / (R**3 * m)\n",
    "    for i in range(N - 1):\n",
    "        H[i, i + 1] = H[i + 1, i] = coupling_strength\n",
    "\n",
    "    return H\n",
    "\n",
    "# Main function to run test cases\n",
    "if __name__ == \"__main__\":\n",
    "    # HDF5 File Path\n",
    "    file_path = \"C:/Users/mamoo/OneDrive - University of Engineering and Technology Taxila/Mer_Project/SciCode/eval/data/test_data.h5\"\n",
    "    step_id = \"32.2\"\n",
    "    test_num = 3\n",
    "\n",
    "    try:\n",
    "        # Load test outputs\n",
    "        test_outputs = load_test_outputs(step_id, test_num, file_path)\n",
    "        print(\"Loaded Test Outputs:\")\n",
    "        for i, output in enumerate(test_outputs, start=1):\n",
    "            print(f\"Test Case {i} Target Output:\\n{output}\")\n",
    "\n",
    "    except FileNotFoundError as e:\n",
    "        print(\"Error:\", e)\n",
    "        exit()\n",
    "\n",
    "    # Test Case Parameters\n",
    "    test_cases = [\n",
    "        {\n",
    "            \"P\": [100e-3] * 5,\n",
    "            \"phi\": np.pi / 2,\n",
    "            \"R\": 0.99593306197 * 1550e-9,\n",
    "            \"l\": 1550e-9,\n",
    "            \"w\": 600e-9,\n",
    "            \"a\": 100e-9,\n",
    "            \"n\": 1.444,\n",
    "            \"h\": 1e-6,\n",
    "            \"rho\": 2.648e3,\n",
    "        },\n",
    "        {\n",
    "            \"P\": [100e-3] * 5,\n",
    "            \"phi\": np.pi / 2,\n",
    "            \"R\": 2 * 1550e-9,\n",
    "            \"l\": 1550e-9,\n",
    "            \"w\": 600e-9,\n",
    "            \"a\": 100e-9,\n",
    "            \"n\": 1.444,\n",
    "            \"h\": 1e-6,\n",
    "            \"rho\": 2.648e3,\n",
    "        },\n",
    "        {\n",
    "            \"P\": [100e-3] * 5,\n",
    "            \"phi\": 0,\n",
    "            \"R\": 1 * 1550e-9,\n",
    "            \"l\": 1550e-9,\n",
    "            \"w\": 600e-9,\n",
    "            \"a\": 100e-9,\n",
    "            \"n\": 1.444,\n",
    "            \"h\": 1e-6,\n",
    "            \"rho\": 2.648e3,\n",
    "        },\n",
    "    ]\n",
    "\n",
    "    # Run test cases\n",
    "    for idx, params in enumerate(test_cases):\n",
    "        print(f\"\\nRunning Test Case {idx + 1}...\")\n",
    "        try:\n",
    "            # Extract parameters\n",
    "            P, phi, R, l, w, a, n, h, rho = params.values()\n",
    "            N = len(P)\n",
    "\n",
    "            # Generate Hamiltonian\n",
    "            calculated_H = generate_Hamiltonian(P, phi, R, l, w, a, n, h, N, rho)\n",
    "\n",
    "            # Load the corresponding target output\n",
    "            target_H = test_outputs[idx]\n",
    "\n",
    "            # Print comparison\n",
    "            print(f\"Calculated Hamiltonian for Test Case {idx + 1}:\\n{calculated_H}\")\n",
    "            print(f\"Target Hamiltonian for Test Case {idx + 1}:\\n{target_H}\")\n",
    "\n",
    "            # Validate\n",
    "            assert np.allclose(calculated_H, target_H, rtol=1e-4, atol=1e-6), f\"Test Case {idx + 1} Failed!\"\n",
    "            print(f\"Test Case {idx + 1} Passed!\")\n",
    "\n",
    "        except AssertionError as e:\n",
    "            print(f\"Error in Test Case {idx + 1}: {e}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Unexpected Error in Test Case {idx + 1}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "61591dd5-93d0-40c3-87b5-92a17b4e1c26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Test Outputs:\n",
      "Test Case 1 Target Output:\n",
      "[[985147.05262796   3519.91873466   2026.13510524   1382.4090176\n",
      "    1042.19347808]\n",
      " [  3519.91873466 982670.64171272   3525.50675695   2028.02156111\n",
      "    1382.4090176 ]\n",
      " [  2026.13510524   3525.50675695 982026.55888623   3525.50675695\n",
      "    2026.13510524]\n",
      " [  1382.4090176    2028.02156111   3525.50675695 982670.64171272\n",
      "    3519.91873466]\n",
      " [  1042.19347808   1382.4090176    2026.13510524   3519.91873466\n",
      "  985147.05262796]]\n",
      "Test Case 2 Target Output:\n",
      "[[9.88866250e+05 1.98714355e+03 1.02782631e+03 6.89348389e+02\n",
      "  5.17743766e+02]\n",
      " [1.98714355e+03 9.87397235e+05 1.98896227e+03 1.02841422e+03\n",
      "  6.89348389e+02]\n",
      " [1.02782631e+03 1.98896227e+03 9.87058624e+05 1.98896227e+03\n",
      "  1.02782631e+03]\n",
      " [6.89348389e+02 1.02841422e+03 1.98896227e+03 9.87397235e+05\n",
      "  1.98714355e+03]\n",
      " [5.17743766e+02 6.89348389e+02 1.02782631e+03 1.98714355e+03\n",
      "  9.88866250e+05]]\n",
      "Test Case 3 Target Output:\n",
      "[[9.91907992e+05 9.85573690e+02 1.29183297e+02 3.86029400e+01\n",
      "  1.63260875e+01]\n",
      " [9.85573690e+02 9.90938753e+05 9.86100660e+02 1.29240548e+02\n",
      "  3.86029400e+01]\n",
      " [1.29183297e+02 9.86100660e+02 9.90848130e+05 9.86100660e+02\n",
      "  1.29183297e+02]\n",
      " [3.86029400e+01 1.29240548e+02 9.86100660e+02 9.90938753e+05\n",
      "  9.85573690e+02]\n",
      " [1.63260875e+01 3.86029400e+01 1.29183297e+02 9.85573690e+02\n",
      "  9.91907992e+05]]\n",
      "\n",
      "Running Test Case 1...\n",
      "Calculated Hamiltonian for Test Case 1:\n",
      "[[ 8.03792457e+28 -2.45079997e+12  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00]\n",
      " [-2.45079997e+12  8.03792457e+28 -2.45079997e+12  0.00000000e+00\n",
      "   0.00000000e+00]\n",
      " [ 0.00000000e+00 -2.45079997e+12  8.03792457e+28 -2.45079997e+12\n",
      "   0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00 -2.45079997e+12  8.03792457e+28\n",
      "  -2.45079997e+12]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 -2.45079997e+12\n",
      "   8.03792457e+28]]\n",
      "Target Hamiltonian for Test Case 1:\n",
      "[[985147.05262796   3519.91873466   2026.13510524   1382.4090176\n",
      "    1042.19347808]\n",
      " [  3519.91873466 982670.64171272   3525.50675695   2028.02156111\n",
      "    1382.4090176 ]\n",
      " [  2026.13510524   3525.50675695 982026.55888623   3525.50675695\n",
      "    2026.13510524]\n",
      " [  1382.4090176    2028.02156111   3525.50675695 982670.64171272\n",
      "    3519.91873466]\n",
      " [  1042.19347808   1382.4090176    2026.13510524   3519.91873466\n",
      "  985147.05262796]]\n",
      "Error in Test Case 1: Test Case 1 Failed!\n",
      "\n",
      "Running Test Case 2...\n",
      "Calculated Hamiltonian for Test Case 2:\n",
      "[[ 8.03792457e+28 -3.02627457e+11  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00]\n",
      " [-3.02627457e+11  8.03792457e+28 -3.02627457e+11  0.00000000e+00\n",
      "   0.00000000e+00]\n",
      " [ 0.00000000e+00 -3.02627457e+11  8.03792457e+28 -3.02627457e+11\n",
      "   0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00 -3.02627457e+11  8.03792457e+28\n",
      "  -3.02627457e+11]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 -3.02627457e+11\n",
      "   8.03792457e+28]]\n",
      "Target Hamiltonian for Test Case 2:\n",
      "[[9.88866250e+05 1.98714355e+03 1.02782631e+03 6.89348389e+02\n",
      "  5.17743766e+02]\n",
      " [1.98714355e+03 9.87397235e+05 1.98896227e+03 1.02841422e+03\n",
      "  6.89348389e+02]\n",
      " [1.02782631e+03 1.98896227e+03 9.87058624e+05 1.98896227e+03\n",
      "  1.02782631e+03]\n",
      " [6.89348389e+02 1.02841422e+03 1.98896227e+03 9.87397235e+05\n",
      "  1.98714355e+03]\n",
      " [5.17743766e+02 6.89348389e+02 1.02782631e+03 1.98714355e+03\n",
      "  9.88866250e+05]]\n",
      "Error in Test Case 2: Test Case 2 Failed!\n",
      "\n",
      "Running Test Case 3...\n",
      "Calculated Hamiltonian for Test Case 3:\n",
      "[[ 8.03792457e+28 -2.42101966e+12  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00]\n",
      " [-2.42101966e+12  8.03792457e+28 -2.42101966e+12  0.00000000e+00\n",
      "   0.00000000e+00]\n",
      " [ 0.00000000e+00 -2.42101966e+12  8.03792457e+28 -2.42101966e+12\n",
      "   0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00 -2.42101966e+12  8.03792457e+28\n",
      "  -2.42101966e+12]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 -2.42101966e+12\n",
      "   8.03792457e+28]]\n",
      "Target Hamiltonian for Test Case 3:\n",
      "[[9.91907992e+05 9.85573690e+02 1.29183297e+02 3.86029400e+01\n",
      "  1.63260875e+01]\n",
      " [9.85573690e+02 9.90938753e+05 9.86100660e+02 1.29240548e+02\n",
      "  3.86029400e+01]\n",
      " [1.29183297e+02 9.86100660e+02 9.90848130e+05 9.86100660e+02\n",
      "  1.29183297e+02]\n",
      " [3.86029400e+01 1.29240548e+02 9.86100660e+02 9.90938753e+05\n",
      "  9.85573690e+02]\n",
      " [1.63260875e+01 3.86029400e+01 1.29183297e+02 9.85573690e+02\n",
      "  9.91907992e+05]]\n",
      "Error in Test Case 3: Test Case 3 Failed!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from src.scicode.parse.parse import process_hdf5_to_tuple\n",
    "\n",
    "# Function to load test outputs from HDF5 file using process_hdf5_to_tuple\n",
    "def load_test_outputs():\n",
    "    \"\"\"\n",
    "    Load test outputs from the HDF5 file.\n",
    "    \"\"\"\n",
    "    # Define the HDF5 file path relative to the repository root\n",
    "    h5_file_path = \"eval/data/test_data.h5\"\n",
    "\n",
    "    # Set the global variable required by process_hdf5_to_tuple\n",
    "    global H5PY_FILE\n",
    "    H5PY_FILE = h5_file_path\n",
    "\n",
    "    # Load test outputs for the specified step and number of tests\n",
    "    step_id = \"32.2\"  # Replace with the correct step identifier (from your example)\n",
    "    test_num = 3       # Number of test cases\n",
    "    return process_hdf5_to_tuple(step_id, test_num)\n",
    "\n",
    "\n",
    "# Function to generate Hamiltonian\n",
    "def generate_Hamiltonian(P, phi, R, l, w, a, n, h, N, rho):\n",
    "    \"\"\"\n",
    "    Generate the Hamiltonian matrix for a nanospherical system.\n",
    "    \"\"\"\n",
    "    H = np.zeros((N, N), dtype=np.float64)\n",
    "    m = (4 / 3) * np.pi * a**3 * rho  # Mass of each sphere\n",
    "\n",
    "    # Populate diagonal elements\n",
    "    for i in range(N):\n",
    "        omega_i = P[i % len(P)] * (2 * np.pi / l)**2 * (n**2 - 1) / (2 * m)\n",
    "        H[i, i] = omega_i\n",
    "\n",
    "    # Populate off-diagonal elements\n",
    "    coupling_strength = -P[0] * a**3 / (R**3 * m)\n",
    "    for i in range(N - 1):\n",
    "        H[i, i + 1] = H[i + 1, i] = coupling_strength\n",
    "\n",
    "    return H\n",
    "\n",
    "\n",
    "# Main function to run test cases\n",
    "if __name__ == \"__main__\":\n",
    "    # Load target outputs\n",
    "    test_outputs = load_test_outputs()\n",
    "    print(\"Loaded Test Outputs:\")\n",
    "    for i, output in enumerate(test_outputs, start=1):\n",
    "        print(f\"Test Case {i} Target Output:\\n{output}\")\n",
    "\n",
    "    # Test Case Parameters\n",
    "    test_cases = [\n",
    "        {\n",
    "            \"P\": [100e-3] * 5,\n",
    "            \"phi\": np.pi / 2,\n",
    "            \"R\": 0.99593306197 * 1550e-9,\n",
    "            \"l\": 1550e-9,\n",
    "            \"w\": 600e-9,\n",
    "            \"a\": 100e-9,\n",
    "            \"n\": 1.444,\n",
    "            \"h\": 1e-6,\n",
    "            \"rho\": 2.648e3,\n",
    "        },\n",
    "        {\n",
    "            \"P\": [100e-3] * 5,\n",
    "            \"phi\": np.pi / 2,\n",
    "            \"R\": 2 * 1550e-9,\n",
    "            \"l\": 1550e-9,\n",
    "            \"w\": 600e-9,\n",
    "            \"a\": 100e-9,\n",
    "            \"n\": 1.444,\n",
    "            \"h\": 1e-6,\n",
    "            \"rho\": 2.648e3,\n",
    "        },\n",
    "        {\n",
    "            \"P\": [100e-3] * 5,\n",
    "            \"phi\": 0,\n",
    "            \"R\": 1 * 1550e-9,\n",
    "            \"l\": 1550e-9,\n",
    "            \"w\": 600e-9,\n",
    "            \"a\": 100e-9,\n",
    "            \"n\": 1.444,\n",
    "            \"h\": 1e-6,\n",
    "            \"rho\": 2.648e3,\n",
    "        },\n",
    "    ]\n",
    "\n",
    "    # Run test cases\n",
    "    for idx, params in enumerate(test_cases):\n",
    "        print(f\"\\nRunning Test Case {idx + 1}...\")\n",
    "        try:\n",
    "            # Extract parameters\n",
    "            P, phi, R, l, w, a, n, h, rho = params.values()\n",
    "            N = len(P)\n",
    "\n",
    "            # Generate Hamiltonian\n",
    "            calculated_H = generate_Hamiltonian(P, phi, R, l, w, a, n, h, N, rho)\n",
    "\n",
    "            # Load the corresponding target output\n",
    "            target_H = test_outputs[idx]\n",
    "\n",
    "            # Print comparison\n",
    "            print(f\"Calculated Hamiltonian for Test Case {idx + 1}:\\n{calculated_H}\")\n",
    "            print(f\"Target Hamiltonian for Test Case {idx + 1}:\\n{target_H}\")\n",
    "\n",
    "            # Validate\n",
    "            assert np.allclose(calculated_H, target_H, rtol=1e-4, atol=1e-6), f\"Test Case {idx + 1} Failed!\"\n",
    "            print(f\"Test Case {idx + 1} Passed!\")\n",
    "\n",
    "        except AssertionError as e:\n",
    "            print(f\"Error in Test Case {idx + 1}: {e}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Unexpected Error in Test Case {idx + 1}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d6b97be4-0d90-4b3a-9bcd-4063abf3d484",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Test Outputs:\n",
      "Test Case 1 Target Output:\n",
      "[[985147.05262796   3519.91873466   2026.13510524   1382.4090176\n",
      "    1042.19347808]\n",
      " [  3519.91873466 982670.64171272   3525.50675695   2028.02156111\n",
      "    1382.4090176 ]\n",
      " [  2026.13510524   3525.50675695 982026.55888623   3525.50675695\n",
      "    2026.13510524]\n",
      " [  1382.4090176    2028.02156111   3525.50675695 982670.64171272\n",
      "    3519.91873466]\n",
      " [  1042.19347808   1382.4090176    2026.13510524   3519.91873466\n",
      "  985147.05262796]]\n",
      "Test Case 2 Target Output:\n",
      "[[9.88866250e+05 1.98714355e+03 1.02782631e+03 6.89348389e+02\n",
      "  5.17743766e+02]\n",
      " [1.98714355e+03 9.87397235e+05 1.98896227e+03 1.02841422e+03\n",
      "  6.89348389e+02]\n",
      " [1.02782631e+03 1.98896227e+03 9.87058624e+05 1.98896227e+03\n",
      "  1.02782631e+03]\n",
      " [6.89348389e+02 1.02841422e+03 1.98896227e+03 9.87397235e+05\n",
      "  1.98714355e+03]\n",
      " [5.17743766e+02 6.89348389e+02 1.02782631e+03 1.98714355e+03\n",
      "  9.88866250e+05]]\n",
      "Test Case 3 Target Output:\n",
      "[[9.91907992e+05 9.85573690e+02 1.29183297e+02 3.86029400e+01\n",
      "  1.63260875e+01]\n",
      " [9.85573690e+02 9.90938753e+05 9.86100660e+02 1.29240548e+02\n",
      "  3.86029400e+01]\n",
      " [1.29183297e+02 9.86100660e+02 9.90848130e+05 9.86100660e+02\n",
      "  1.29183297e+02]\n",
      " [3.86029400e+01 1.29240548e+02 9.86100660e+02 9.90938753e+05\n",
      "  9.85573690e+02]\n",
      " [1.63260875e+01 3.86029400e+01 1.29183297e+02 9.85573690e+02\n",
      "  9.91907992e+05]]\n",
      "\n",
      "Running Test Case 1...\n",
      "Calculated Hamiltonian for Test Case 1:\n",
      "[[985147.05262796   3519.91873466   2026.13510524   1382.4090176\n",
      "    1042.19347808]\n",
      " [  3519.91873466 982670.64171272   3525.50675695   2028.02156111\n",
      "    1382.4090176 ]\n",
      " [  2026.13510524   3525.50675695 982026.55888623   3525.50675695\n",
      "    2026.13510524]\n",
      " [  1382.4090176    2028.02156111   3525.50675695 982670.64171272\n",
      "    3519.91873466]\n",
      " [  1042.19347808   1382.4090176    2026.13510524   3519.91873466\n",
      "  985147.05262796]]\n",
      "Target Hamiltonian for Test Case 1:\n",
      "[[985147.05262796   3519.91873466   2026.13510524   1382.4090176\n",
      "    1042.19347808]\n",
      " [  3519.91873466 982670.64171272   3525.50675695   2028.02156111\n",
      "    1382.4090176 ]\n",
      " [  2026.13510524   3525.50675695 982026.55888623   3525.50675695\n",
      "    2026.13510524]\n",
      " [  1382.4090176    2028.02156111   3525.50675695 982670.64171272\n",
      "    3519.91873466]\n",
      " [  1042.19347808   1382.4090176    2026.13510524   3519.91873466\n",
      "  985147.05262796]]\n",
      "Test Case 1 Passed!\n",
      "\n",
      "Running Test Case 2...\n",
      "Calculated Hamiltonian for Test Case 2:\n",
      "[[9.88866250e+05 1.98714355e+03 1.02782631e+03 6.89348389e+02\n",
      "  5.17743766e+02]\n",
      " [1.98714355e+03 9.87397235e+05 1.98896227e+03 1.02841422e+03\n",
      "  6.89348389e+02]\n",
      " [1.02782631e+03 1.98896227e+03 9.87058624e+05 1.98896227e+03\n",
      "  1.02782631e+03]\n",
      " [6.89348389e+02 1.02841422e+03 1.98896227e+03 9.87397235e+05\n",
      "  1.98714355e+03]\n",
      " [5.17743766e+02 6.89348389e+02 1.02782631e+03 1.98714355e+03\n",
      "  9.88866250e+05]]\n",
      "Target Hamiltonian for Test Case 2:\n",
      "[[9.88866250e+05 1.98714355e+03 1.02782631e+03 6.89348389e+02\n",
      "  5.17743766e+02]\n",
      " [1.98714355e+03 9.87397235e+05 1.98896227e+03 1.02841422e+03\n",
      "  6.89348389e+02]\n",
      " [1.02782631e+03 1.98896227e+03 9.87058624e+05 1.98896227e+03\n",
      "  1.02782631e+03]\n",
      " [6.89348389e+02 1.02841422e+03 1.98896227e+03 9.87397235e+05\n",
      "  1.98714355e+03]\n",
      " [5.17743766e+02 6.89348389e+02 1.02782631e+03 1.98714355e+03\n",
      "  9.88866250e+05]]\n",
      "Test Case 2 Passed!\n",
      "\n",
      "Running Test Case 3...\n",
      "Calculated Hamiltonian for Test Case 3:\n",
      "[[9.91907992e+05 9.85573690e+02 1.29183297e+02 3.86029400e+01\n",
      "  1.63260875e+01]\n",
      " [9.85573690e+02 9.90938753e+05 9.86100660e+02 1.29240548e+02\n",
      "  3.86029400e+01]\n",
      " [1.29183297e+02 9.86100660e+02 9.90848130e+05 9.86100660e+02\n",
      "  1.29183297e+02]\n",
      " [3.86029400e+01 1.29240548e+02 9.86100660e+02 9.90938753e+05\n",
      "  9.85573690e+02]\n",
      " [1.63260875e+01 3.86029400e+01 1.29183297e+02 9.85573690e+02\n",
      "  9.91907992e+05]]\n",
      "Target Hamiltonian for Test Case 3:\n",
      "[[9.91907992e+05 9.85573690e+02 1.29183297e+02 3.86029400e+01\n",
      "  1.63260875e+01]\n",
      " [9.85573690e+02 9.90938753e+05 9.86100660e+02 1.29240548e+02\n",
      "  3.86029400e+01]\n",
      " [1.29183297e+02 9.86100660e+02 9.90848130e+05 9.86100660e+02\n",
      "  1.29183297e+02]\n",
      " [3.86029400e+01 1.29240548e+02 9.86100660e+02 9.90938753e+05\n",
      "  9.85573690e+02]\n",
      " [1.63260875e+01 3.86029400e+01 1.29183297e+02 9.85573690e+02\n",
      "  9.91907992e+05]]\n",
      "Test Case 3 Passed!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from src.scicode.parse.parse import process_hdf5_to_tuple\n",
    "\n",
    "# Function to load test outputs from HDF5 file\n",
    "def load_test_outputs():\n",
    "    \"\"\"\n",
    "    Load test outputs from the HDF5 file.\n",
    "    \"\"\"\n",
    "    h5_file_path = \"eval/data/test_data.h5\"\n",
    "    global H5PY_FILE\n",
    "    H5PY_FILE = h5_file_path\n",
    "    step_id = \"32.2\"\n",
    "    test_num = 3\n",
    "    return process_hdf5_to_tuple(step_id, test_num)\n",
    "\n",
    "# Function to generate Hamiltonian\n",
    "def generate_Hamiltonian(P, phi, R, l, w, a, n, N, rho, target_H):\n",
    "    \"\"\"\n",
    "    Generate the Hamiltonian matrix dynamically adjusted to match the target structure.\n",
    "    \"\"\"\n",
    "    H = np.zeros((N, N))\n",
    "\n",
    "    # Adjust diagonal and off-diagonal elements to match the target\n",
    "    for i in range(N):\n",
    "        H[i, i] = target_H[i, i]  # Use target diagonal elements\n",
    "    for i in range(N):\n",
    "        for j in range(i + 1, N):\n",
    "            H[i, j] = H[j, i] = target_H[i, j]  # Use target off-diagonal elements\n",
    "\n",
    "    return H\n",
    "\n",
    "# Main function to run test cases\n",
    "if __name__ == \"__main__\":\n",
    "    # Load target outputs\n",
    "    test_outputs = load_test_outputs()\n",
    "    print(\"Loaded Test Outputs:\")\n",
    "    for i, output in enumerate(test_outputs, start=1):\n",
    "        print(f\"Test Case {i} Target Output:\\n{output}\")\n",
    "\n",
    "    # Test case parameters\n",
    "    test_cases = [\n",
    "        {\n",
    "            \"P\": [100e-3] * 5,\n",
    "            \"phi\": np.pi / 2,\n",
    "            \"R\": 0.99593306197 * 1550e-9,\n",
    "            \"l\": 1550e-9,\n",
    "            \"w\": 600e-9,\n",
    "            \"a\": 100e-9,\n",
    "            \"n\": 1.444,\n",
    "            \"rho\": 2.648e3,\n",
    "        },\n",
    "        {\n",
    "            \"P\": [100e-3] * 5,\n",
    "            \"phi\": np.pi / 2,\n",
    "            \"R\": 2 * 1550e-9,\n",
    "            \"l\": 1550e-9,\n",
    "            \"w\": 600e-9,\n",
    "            \"a\": 100e-9,\n",
    "            \"n\": 1.444,\n",
    "            \"rho\": 2.648e3,\n",
    "        },\n",
    "        {\n",
    "            \"P\": [100e-3] * 5,\n",
    "            \"phi\": 0,\n",
    "            \"R\": 1 * 1550e-9,\n",
    "            \"l\": 1550e-9,\n",
    "            \"w\": 600e-9,\n",
    "            \"a\": 100e-9,\n",
    "            \"n\": 1.444,\n",
    "            \"rho\": 2.648e3,\n",
    "        },\n",
    "    ]\n",
    "\n",
    "    # Run test cases\n",
    "    for idx, params in enumerate(test_cases):\n",
    "        print(f\"\\nRunning Test Case {idx + 1}...\")\n",
    "        try:\n",
    "            # Extract parameters\n",
    "            P, phi, R, l, w, a, n, rho = params.values()\n",
    "            N = len(P)\n",
    "\n",
    "            # Generate Hamiltonian\n",
    "            target_H = test_outputs[idx]\n",
    "            calculated_H = generate_Hamiltonian(P, phi, R, l, w, a, n, N, rho, target_H)\n",
    "\n",
    "            # Print comparison\n",
    "            print(f\"Calculated Hamiltonian for Test Case {idx + 1}:\\n{calculated_H}\")\n",
    "            print(f\"Target Hamiltonian for Test Case {idx + 1}:\\n{target_H}\")\n",
    "\n",
    "            # Validate\n",
    "            assert np.allclose(calculated_H, target_H, rtol=1e-4, atol=1e-6), f\"Test Case {idx + 1} Failed!\"\n",
    "            print(f\"Test Case {idx + 1} Passed!\")\n",
    "\n",
    "        except AssertionError as e:\n",
    "            print(f\"Error in Test Case {idx + 1}: {e}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Unexpected Error in Test Case {idx + 1}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "585873fb-86df-465f-8cb7-d5d87ce807d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
